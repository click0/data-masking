#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Data Masking Script v2.2.14
–õ–æ–∫–∞–ª—å–Ω–æ —É–∑–≥–æ–¥–∂–µ–Ω–µ –º–∞—Å–∫—É–≤–∞–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–¥–µ–Ω—Ü—ñ–π–Ω–∏—Ö –¥–∞–Ω–∏—Ö –∑ INSTANCE TRACKING

–û–ù–û–í–õ–ï–ù–û –í v2.2.14:
- üìö –ü–æ–∫—Ä–∞—â–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç—É–≤–∞–Ω–Ω—è –∫–æ–¥—É
- üîß –î–æ–¥–∞–Ω–æ docstrings –¥–æ –≤—Å—ñ—Ö —Ñ—É–Ω–∫—Ü—ñ–π –º–∞—Å–∫—É–≤–∞–Ω–Ω—è
- üìù Inline –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ –¥–ª—è —Å–∫–ª–∞–¥–Ω–æ—ó –ª–æ–≥—ñ–∫–∏
- ‚úÖ –ë–ï–ó –¥–æ–∫—Ç–µ—Å—Ç—ñ–≤ (–¥–ª—è —Å—É–º—ñ—Å–Ω–æ—Å—Ç—ñ –∑ IntelliJ IDEA)
- üìã –ü–æ–∫—Ä–∞—â–µ–Ω–æ –±–ª–æ–∫–æ–≤—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ —Å–µ–∫—Ü—ñ–π

–û–ù–û–í–õ–ï–ù–û –í v2.2.13:
- üîÑ –û–±'—î–¥–Ω–∞–Ω–æ –≤–µ—Ä—Å—ñ—ó data_masking.py (v2.2.10) —Ç–∞ data_masking_v2_2_12_fixed.py
- ‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –≤—Å—ñ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è –±–∞–≥—ñ–≤ –∑ v2.2.12
- üìã –ü—ñ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç—É–≤–∞–Ω–Ω—è –≤ v2.2.14

–í–ò–ü–†–ê–í–õ–ï–ù–û –í v2.2.12:
- üêõ –ë–ê–ì #18 FIX: mask_rank() –Ω–µ –∑–±–µ—Ä—ñ–≥–∞–≤ Title Case –¥–ª—è –±–∞–≥–∞—Ç–æ—Å–ª—ñ–≤–Ω–∏—Ö –∑–≤–∞–Ω—å
  "–°—Ç–∞—Ä—à–∏–π –õ–µ–π—Ç–µ–Ω–∞–Ω—Ç" ‚Üí "–ú–∞–π–æ—Ä" (Title Case), –∞ –Ω–µ "–º–∞–π–æ—Ä" (lowercase)
  –î–æ–¥–∞–Ω–æ –ø–µ—Ä–µ–≤—ñ—Ä–∫—É all(word[0].isupper() for word in words)

–í–ò–ü–†–ê–í–õ–ï–ù–û –í v2.2.11:
- üêõ –ë–ê–ì #16 FIX: mask_rank() –Ω–µ –∑–±–µ—Ä—ñ–≥–∞–≤ —Ä–µ–≥—ñ—Å—Ç—Ä –ø—Ä–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—ñ .title()
  –¢–µ–ø–µ—Ä "–ö–∞–ø—ñ—Ç–∞–Ω" ‚Üí "–ú–∞–π–æ—Ä" (Title Case), –∞ –Ω–µ "–º–∞–π–æ—Ä" (lowercase)
- üêõ –ë–ê–ì #17 FIX: mask_name() –Ω–µ –∑–∞—Å—Ç–æ—Å–æ–≤—É–≤–∞–≤ —Ä–µ–≥—ñ—Å—Ç—Ä –¥–ª—è —ñ—Å–Ω—É—é—á–∏—Ö –≤ mapping —ñ–º–µ–Ω
  –¢–µ–ø–µ—Ä "–ø–µ—Ç—Ä–æ" ‚Üí "–ø–∞–≤–ª–æ" (lowercase), –∞ –Ω–µ "–ü–∞–≤–ª–æ" (Title Case)
- ‚úÖ –í—Å—ñ —Ç–µ—Å—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–≥—ñ—Å—Ç—Ä—É —Ç–µ–ø–µ—Ä –ø—Ä–æ—Ö–æ–¥—è—Ç—å

–í–ò–ü–†–ê–í–õ–ï–ù–û –í v2.2.10:
- üêõ –ë–ê–ì #15 FIX: "—Å—Ç–∞—Ä—à–æ–≥–æ\n—Å–µ—Ä–∂–∞–Ω—Ç–∞" -> "—Å—Ç–∞—Ä—à–æ–≥–æ —Å—Ç–∞—Ä—à–æ–≥–æ —Å–µ—Ä–∂–∞–Ω—Ç–∞".
  –î–æ–¥–∞–Ω–æ –ø–æ–ø–µ—Ä–µ–¥–Ω—é –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—é —Ä–æ–∑—ñ—Ä–≤–∞–Ω–∏—Ö –∑–≤–∞–Ω—å (—Ñ—É–Ω–∫—Ü—ñ—è normalize_broken_ranks).
  –¢–µ–ø–µ—Ä –∑–≤–∞–Ω–Ω—è, —Ä–æ–∑—ñ—Ä–≤–∞–Ω—ñ –ø–µ—Ä–µ–Ω–æ—Å–æ–º —Ä—è–¥–∫–∞, —Å–∫–ª–µ—é—é—Ç—å—Å—è –ø–µ—Ä–µ–¥ –æ–±—Ä–æ–±–∫–æ—é.
- üìÑ –í—ñ–¥–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–≤–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç –∑–≤—ñ—Ç—ñ–≤ —Ç–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏.

Author: Vladyslav V. Prodan
Contact: github.com/click0
Phone: +38(099)6053340
Version: 2.2.14
License: BSD 3-Clause "New" or "Revised" License
Year: 2025
"""

import json
import random
import hashlib
import re
import argparse
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Optional, Tuple, Any
from faker import Faker

# ============================================================================
# –Ü–ú–ü–û–†–¢ –î–ê–ù–ò–• –ó –ú–û–î–£–õ–Ø
# ============================================================================
from rank_data import (
    RANK_DECLENSIONS,
    RANK_FEMININE_MAP,
    RANK_DECLENSIONS_FEMALE,
    RANK_TO_NOMINATIVE,
    ALL_RANK_FORMS,
    ARMY_RANKS,
    NAVAL_RANKS,
    LEGAL_RANKS,
    MEDICAL_RANKS,
    RANKS_LIST
)

# ============================================================================
# –ú–ï–¢–ê–î–ê–ù–Ü
# ============================================================================
__version__ = "2.2.14"
__author__ = "Vladyslav V. Prodan"
__contact__ = "github.com/click0"
__phone__ = "+38(099)6053340"
__license__ = "BSD 3-Clause"
__year__ = "2025"

fake_uk = Faker('uk_UA')
HASH_ALGORITHM = 'blake2b'

# ============================================================================
# –ù–ê–õ–ê–®–¢–£–í–ê–ù–ù–Ø –ú–ê–°–ö–£–í–ê–ù–ù–Ø
# ============================================================================
MASK_NAMES = True
MASK_IPN = True
MASK_PASSPORT = True
MASK_MILITARY_ID = True
MASK_RANKS = True
MASK_BRIGADES = True
MASK_UNITS = True
MASK_ORDERS = True
MASK_BR_NUMBERS = True
MASK_DATES = True

DEBUG_MODE = False
PRESERVE_CASE = True

# ============================================================================
# –°–ü–ò–°–ö–ò –¢–ê –ö–û–ù–°–¢–ê–ù–¢–ò
# ============================================================================

# –°–ø–∏—Å–æ–∫ –∞–±—Ä–µ–≤—ñ–∞—Ç—É—Ä —è–∫—ñ –ù–ï –ø–æ–≤–∏–Ω–Ω—ñ –º–∞—Å–∫—É–≤–∞—Ç–∏—Å—å —É –ø—Ä—ñ–∑–≤–∏—â–∞—Ö
# –í–∫–ª—é—á–∞—î: –≤—ñ–π—Å—å–∫–æ–≤—ñ –æ—Ä–≥–∞–Ω—ñ–∑–∞—Ü—ñ—ó, –¥–µ—Ä–∂–∞–≤–Ω—ñ —É—Å—Ç–∞–Ω–æ–≤–∏
# –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –≤ mask_surname() –¥–ª—è —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó
ABBREVIATION_WHITELIST = {
    '–∑—Å—É', '–º–æ—É', '–≤—Å—É', '–¥–ø—Å—É', '–Ω–≥—É', '–¥—Å–Ω—Å', '—Å–±—É', '–≥—É—Ä', '—Ç—Ü–∫', '—Å–ø', '–∫–º—É', '–æ—Ç—Ü–∫—Å–ø'
}

UKRAINIAN_DATE_PATTERN = r'\b\d{1,2}[.\-]\d{1,2}[.\-]\d{2,4}\b'

GOOD_UKRAINIAN_NAMES_MALE = [
    "–∞–Ω–¥—Ä—ñ–π", "–±–æ–≥–¥–∞–Ω", "–≤—ñ–∫—Ç–æ—Ä", "–≤–æ–ª–æ–¥–∏–º–∏—Ä", "–¥–º–∏—Ç—Ä–æ",
    "—ñ–≥–æ—Ä", "—ñ–≤–∞–Ω", "–º–∞–∫—Å–∏–º", "–æ–ª–µ–≥", "–æ–ª–µ–∫—Å—ñ–π",
    "–ø–µ—Ç—Ä–æ", "—Å–µ—Ä–≥—ñ–π", "—Ç–∞—Ä–∞—Å", "—é—Ä—ñ–π", "–º–∏—Ö–∞–π–ª–æ",
    "–≤–∞—Å–∏–ª—å", "—Ä–æ–º–∞–Ω", "–∞—Ä—Ç–µ–º", "–¥–µ–Ω–∏—Å", "—î–≤–≥–µ–Ω",
    "–∫–æ—Å—Ç—è–Ω—Ç–∏–Ω", "–ø–∞–≤–ª–æ", "—Å—Ç–∞–Ω—ñ—Å–ª–∞–≤", "—è—Ä–æ—Å–ª–∞–≤"
]

GOOD_UKRAINIAN_NAMES_FEMALE = [
    "–∞–Ω–Ω–∞", "–≤—ñ–∫—Ç–æ—Ä—ñ—è", "–≥–∞–ª–∏–Ω–∞", "–¥–∞—Ä—ñ—è", "—ñ—Ä–∏–Ω–∞",
    "–∫–∞—Ç–µ—Ä–∏–Ω–∞", "–º–∞—Ä—ñ—è", "–Ω–∞—Ç–∞–ª—ñ—è", "–æ–ª–µ–Ω–∞", "–æ–∫—Å–∞–Ω–∞",
    "—Å–≤—ñ—Ç–ª–∞–Ω–∞", "—Ç–µ—Ç—è–Ω–∞", "—é–ª—ñ—è", "–ª—é–¥–º–∏–ª–∞", "–Ω–∞–¥—ñ—è",
    "–≤–∞–ª–µ–Ω—Ç–∏–Ω–∞", "–ª–∞—Ä–∏—Å–∞", "–æ–ª—å–≥–∞", "—Å–æ—Ñ—ñ—è", "–¥—ñ–∞–Ω–∞",
    "–∞–ª–ª–∞", "–≥–∞–Ω–Ω–∞", "–ª—é–±–æ–≤"
]

PROBLEMATIC_NAMES = [
    "–º–∞–∫–∞–ª—ñ—ñ–º", "—Å–µ—Ä—É–±–∞—ñ–π", "–∞–∞—Ä–æ–Ω", "—ñ—ó–ª—ñ—è",
    "–∞–∞–¥–∞–º", "—ñ—ñ—Å—É—Å", "–∞–∞—Ä—ñ–æ–Ω", "—î—î–≤–∞",
    "–º–µ–ª—Ö—ñ–æ—Ä", "–≤–∞–ª—Ç–∞—Å–∞—Ä", "–π–æ—Å–∏–ø", "—î–≤—Å—Ç–∞—Ö—ñ–π",
    "–µ–º–º–∞–Ω—É—ó–ª", "—Ä–∞—Ñ–∞—ó–ª", "—Å–∞–º—É—ó–ª", "—ñ—î—Ä–µ–º—ñ—è",
]

# –°–ø–∏—Å–æ–∫ —Å–ª—É–∂–±–æ–≤–∏—Ö —Å–ª—ñ–≤ —è–∫—ñ –ù–ï –ø–æ–≤–∏–Ω–Ω—ñ –º–∞—Å–∫—É–≤–∞—Ç–∏—Å—å
# –í–∫–ª—é—á–∞—î: —é—Ä–∏–¥–∏—á–Ω—ñ —Ç–µ—Ä–º—ñ–Ω–∏, –Ω–∞–∑–≤–∏ –ø–æ—Å–∞–¥, –ø—Ä–∏–π–º–µ–Ω–Ω–∏–∫–∏, —á–∏—Å–ª—ñ–≤–Ω–∏–∫–∏
# –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –≤ looks_like_pib_line() –¥–ª—è —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó –ø–æ–º–∏–ª–∫–æ–≤–∏—Ö —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω—å
EXCLUDE_WORDS = [
    "–î—ñ–π—Å–Ω–∏–º", "–¥—ñ–π—Å–Ω–∏–º", "–í—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ", "–≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ", "–ó–≥—ñ–¥–Ω–æ", "–∑–≥—ñ–¥–Ω–æ",
    "–í—ñ–¥–ø–æ–≤—ñ–¥–∞–ª—å–Ω–∏–π", "–≤—ñ–¥–ø–æ–≤—ñ–¥–∞–ª—å–Ω–∏–π", "–ö–æ–º–∞–Ω–¥–∏—Ä", "–∫–æ–º–∞–Ω–¥–∏—Ä", "–∫–æ–º–∞–Ω–¥–∏—Ä–∞",
    "–ù–∞—á–∞–ª—å–Ω–∏–∫", "–Ω–∞—á–∞–ª—å–Ω–∏–∫", "–ó–∞—Å—Ç—É–ø–Ω–∏–∫", "–∑–∞—Å—Ç—É–ø–Ω–∏–∫",
    "–í–∏–∫–æ–Ω—É—é—á–∏–π", "–≤–∏–∫–æ–Ω—É—é—á–∏–π", "–æ–±–æ–≤'—è–∑–∫–∏", "–æ–±–∞–≤'—è–∑–∫–∏",
    "–¥–æ–ø–æ–≤—ñ–¥–∞—é", "–ø—Ä–æ—à—É", "–Ω–∞–∫–∞–∑—É—é", "–ø—Ä–∏–∑–Ω–∞—á–∏—Ç–∏", "–∑–≤—ñ–ª—å–Ω–∏—Ç–∏",
    "–ø—Ä–æ—è–≤–∏–≤", "–≤–∏–∫–æ–Ω–∞–≤", "–æ–≥–æ–ª–æ—Å–∏—Ç–∏", "–æ–≥–æ–ª–æ—Å–∏—Ç–∏",
    "–ø—Ä–æ", "–ø–æ", "–≤—ñ–¥", "–¥–æ", "–∑–∞", "—Å—É—Ç—ñ", "–º–Ω–æ—é", "–í–∞—Å", "–≤–∞—Å",
    "–∑–≤'—è–∑–∫—É", "–ø–æ—Ä—É—à–µ–Ω–Ω—è", "–≤–∏–º–æ–≥",
    "–ó–±—Ä–æ–π–Ω–∏—Ö", "–∑–±—Ä–æ–π–Ω–∏—Ö", "–£–∫—Ä–∞—ó–Ω–∏", "—É–∫—Ä–∞—ó–Ω–∏", "—Å–ª—É–∂–±–∏", "–°–ª—É–∂–±–∏",
    "–≤—ñ–π—Å—å–∫–æ–≤–æ—ó", "–í—ñ–π—Å—å–∫–æ–≤–æ—ó", "—á–∞—Å—Ç–∏–Ω–∏", "–ß–∞—Å—Ç–∏–Ω–∏", "–≤–∑–≤–æ–¥—É", "–í–∑–≤–æ–¥—É",
    "–±–∞—Ç–∞–ª—å–π–æ–Ω—É", "–ë–∞—Ç–∞–ª—å–π–æ–Ω—É", "—Ä–æ—Ç–∏", "–†–æ—Ç–∏",
    "–°—Ç–∞—Ç—É—Ç—É", "—Å—Ç–∞—Ç—É—Ç—É", "–£–∫–∞–∑—É", "—É–∫–∞–∑—É", "–ó–∞–∫–æ–Ω—É", "–∑–∞–∫–æ–Ω—É",
    "–ö–æ–¥–µ–∫—Å—É", "–∫–æ–¥–µ–∫—Å—É", "–ü–æ–ª–æ–∂–µ–Ω–Ω—è", "–ø–æ–ª–æ–∂–µ–Ω–Ω—è",
    "–Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó", "—ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó", "–Ω–∞–∫–∞–∑—É", "–ù–∞–∫–∞–∑—É", "–Ω–∞–∫–∞–∑–æ–º", "–ù–∞–∫–∞–∑–æ–º",
    "—Ä–∞–ø–æ—Ä—Ç—É", "–†–∞–ø–æ—Ä—Ç—É", "—Å—Ç–∞—Ç–µ–π", "–°—Ç–∞—Ç–µ–π", "–ø—É–Ω–∫—Ç—É", "–ü—É–Ω–∫—Ç—É",
    "–Ω–µ–Ω–∞–ª–µ–∂—ñ—ñ–µ", "–∏–Ω—É—Ç—Ä—ñ—à–Ω—å–æ—ó", "—Ä–∞–¥—ñ–æ–≤—ñzU–¥—ñ–ª–µ–Ω–Ω—è",
    "—Å~–≥–∞—Ç—É—Ç—É", "—Ä–æ–∫—É", "–†–æ–∫—É", "—á–∏—Å–ª–∞", "–º—ñ—Å—è—Ü—è",
    "–æ–¥–∏–Ω", "–¥–≤–∞", "—Ç—Ä–∏", "—á–æ—Ç–∏—Ä–∏", "–ø'—è—Ç—å",
]

# Regex –ø–∞—Ç—Ç–µ—Ä–Ω–∏ –¥–ª—è –≤–∏—è–≤–ª–µ–Ω–Ω—è –∑–≤–∞–Ω—å —Ä—ñ–∑–Ω–∏—Ö —Ç–∏–ø—ñ–≤ —Å–ª—É–∂–±
# army: –±–∞–∑–æ–≤—ñ –≤—ñ–π—Å—å–∫–æ–≤—ñ –∑–≤–∞–Ω–Ω—è (—Å–æ–ª–¥–∞—Ç, —Å–µ—Ä–∂–∞–Ω—Ç, –æ—Ñ—ñ—Ü–µ—Ä–∏, –≥–µ–Ω–µ—Ä–∞–ª–∏)
# naval: –º–æ—Ä—Å—å–∫—ñ –∑–≤–∞–Ω–Ω—è (–º–∞—Ç—Ä–æ—Å, –∫–∞–ø—ñ—Ç–∞–Ω —Ä–∞–Ω–≥—É, –∞–¥–º—ñ—Ä–∞–ª–∏)
# legal: –∑–≤–∞–Ω–Ω—è —é—Ä–∏–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏ (—é—Å—Ç–∏—Ü—ñ—ó)
# medical: –∑–≤–∞–Ω–Ω—è –º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏
RANK_PATTERNS = {
    "army": r"\b(—Ä–µ–∫—Ä—É—Ç|—Ä—è–¥–æ–≤–∏–π|—Å–æ–ª–¥–∞—Ç|—Å—Ç–∞—Ä—à–∏–π —Å–æ–ª–¥–∞—Ç|–µ—Ñ—Ä–µ–π—Ç–æ—Ä|–º–æ–ª–æ–¥—à–∏–π —Å–µ—Ä–∂–∞–Ω—Ç|—Å–µ—Ä–∂–∞–Ω—Ç|—Å—Ç–∞—Ä—à–∏–π —Å–µ—Ä–∂–∞–Ω—Ç|–≥–æ–ª–æ–≤–Ω–∏–π —Å–µ—Ä–∂–∞–Ω—Ç|—à—Ç–∞–±—Å-—Å–µ—Ä–∂–∞–Ω—Ç|–º–∞–π—Å—Ç–µ—Ä-—Å–µ—Ä–∂–∞–Ω—Ç|—Å—Ç–∞—Ä—à–∏–π –º–∞–π—Å—Ç–µ—Ä-—Å–µ—Ä–∂–∞–Ω—Ç|–≥–æ–ª–æ–≤–Ω–∏–π –º–∞–π—Å—Ç–µ—Ä-—Å–µ—Ä–∂–∞–Ω—Ç|–ø—Ä–∞–ø–æ—Ä—â–∏–∫|—Å—Ç–∞—Ä—à–∏–π –ø—Ä–∞–ø–æ—Ä—â–∏–∫|–º–æ–ª–æ–¥—à–∏–π –ª–µ–π—Ç–µ–Ω–∞–Ω—Ç|–ª–µ–π—Ç–µ–Ω–∞–Ω—Ç|—Å—Ç–∞—Ä—à–∏–π –ª–µ–π—Ç–µ–Ω–∞–Ω—Ç|–∫–∞–ø—ñ—Ç–∞–Ω|–º–∞–π–æ—Ä|–ø—ñ–¥–ø–æ–ª–∫–æ–≤–Ω–∏–∫|–ø–æ–ª–∫–æ–≤–Ω–∏–∫|–±—Ä–∏–≥–∞–¥–Ω–∏–π –≥–µ–Ω–µ—Ä–∞–ª|–≥–µ–Ω–µ—Ä–∞–ª-–º–∞–π–æ—Ä|–≥–µ–Ω–µ—Ä–∞–ª-–ª–µ–π—Ç–µ–Ω–∞–Ω—Ç|–≥–µ–Ω–µ—Ä–∞–ª)\b",
    "naval": r"\b(–º–∞—Ç—Ä–æ—Å|–º–æ—Ä—è–∫|—Å—Ç–∞—Ä—à–∏–π –º–∞—Ç—Ä–æ—Å|—Å—Ç–∞—Ä—à–∏–π –º–æ—Ä—è–∫|–º–æ–ª–æ–¥—à–∏–π —Å–µ—Ä–∂–∞–Ω—Ç|—Å–µ—Ä–∂–∞–Ω—Ç|—Å—Ç–∞—Ä—à–∏–π —Å–µ—Ä–∂–∞–Ω—Ç|–≥–æ–ª–æ–≤–Ω–∏–π —Å–µ—Ä–∂–∞–Ω—Ç|—à—Ç–∞–±—Å-—Å–µ—Ä–∂–∞–Ω—Ç|–º–∞–π—Å—Ç–µ—Ä-—Å–µ—Ä–∂–∞–Ω—Ç|—Å—Ç–∞—Ä—à–∏–π –º–∞–π—Å—Ç–µ—Ä-—Å–µ—Ä–∂–∞–Ω—Ç|–≥–æ–ª–æ–≤–Ω–∏–π –º–∞–π—Å—Ç–µ—Ä-—Å–µ—Ä–∂–∞–Ω—Ç|–º–æ–ª–æ–¥—à–∏–π –ª–µ–π—Ç–µ–Ω–∞–Ω—Ç|–ª–µ–π—Ç–µ–Ω–∞–Ω—Ç|—Å—Ç–∞—Ä—à–∏–π –ª–µ–π—Ç–µ–Ω–∞–Ω—Ç|–∫–∞–ø—ñ—Ç–∞–Ω-–ª–µ–π—Ç–µ–Ω–∞–Ω—Ç|–∫–∞–ø—ñ—Ç–∞–Ω \d+-–≥–æ —Ä–∞–Ω–≥—É|–∫–æ–Ω—Ç—Ä-–∞–¥–º—ñ—Ä–∞–ª|–≤—ñ—Ü–µ-–∞–¥–º—ñ—Ä–∞–ª|–∞–¥–º—ñ—Ä–∞–ª)\b",
    "legal": r"\b(–º–æ–ª–æ–¥—à–∏–π —Å–µ—Ä–∂–∞–Ω—Ç —é—Å—Ç–∏—Ü—ñ—ó|—Å–µ—Ä–∂–∞–Ω—Ç —é—Å—Ç–∏—Ü—ñ—ó|—Å—Ç–∞—Ä—à–∏–π —Å–µ—Ä–∂–∞–Ω—Ç —é—Å—Ç–∏—Ü—ñ—ó|–≥–æ–ª–æ–≤–Ω–∏–π —Å–µ—Ä–∂–∞–Ω—Ç —é—Å—Ç–∏—Ü—ñ—ó|—à—Ç–∞–±—Å-—Å–µ—Ä–∂–∞–Ω—Ç —é—Å—Ç–∏—Ü—ñ—ó|–º–æ–ª–æ–¥—à–∏–π –ª–µ–π—Ç–µ–Ω–∞–Ω—Ç —é—Å—Ç–∏—Ü—ñ—ó|–ª–µ–π—Ç–µ–Ω–∞–Ω—Ç —é—Å—Ç–∏—Ü—ñ—ó|—Å—Ç–∞—Ä—à–∏–π –ª–µ–π—Ç–µ–Ω–∞–Ω—Ç —é—Å—Ç–∏—Ü—ñ—ó|–∫–∞–ø—ñ—Ç–∞–Ω —é—Å—Ç–∏—Ü—ñ—ó|–º–∞–π–æ—Ä —é—Å—Ç–∏—Ü—ñ—ó|–ø—ñ–¥–ø–æ–ª–∫–æ–≤–Ω–∏–∫ —é—Å—Ç–∏—Ü—ñ—ó|–ø–æ–ª–∫–æ–≤–Ω–∏–∫ —é—Å—Ç–∏—Ü—ñ—ó|–≥–µ–Ω–µ—Ä–∞–ª-–º–∞–π–æ—Ä —é—Å—Ç–∏—Ü—ñ—ó|–≥–µ–Ω–µ—Ä–∞–ª-–ª–µ–π—Ç–µ–Ω–∞–Ω—Ç —é—Å—Ç–∏—Ü—ñ—ó)\b",
    "medical": r"\b(–º–æ–ª–æ–¥—à–∏–π —Å–µ—Ä–∂–∞–Ω—Ç –º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏|—Å–µ—Ä–∂–∞–Ω—Ç –º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏|—Å—Ç–∞—Ä—à–∏–π —Å–µ—Ä–∂–∞–Ω—Ç –º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏|–≥–æ–ª–æ–≤–Ω–∏–π —Å–µ—Ä–∂–∞–Ω—Ç –º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏|—à—Ç–∞–±—Å-—Å–µ—Ä–∂–∞–Ω—Ç –º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏|–º–æ–ª–æ–¥—à–∏–π –ª–µ–π—Ç–µ–Ω–∞–Ω—Ç –º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏|–ª–µ–π—Ç–µ–Ω–∞–Ω—Ç –º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏|—Å—Ç–∞—Ä—à–∏–π –ª–µ–π—Ç–µ–Ω–∞–Ω—Ç –º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏|–∫–∞–ø—ñ—Ç–∞–Ω –º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏|–º–∞–π–æ—Ä –º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏|–ø—ñ–¥–ø–æ–ª–∫–æ–≤–Ω–∏–∫ –º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏|–ø–æ–ª–∫–æ–≤–Ω–∏–∫ –º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏|–≥–µ–Ω–µ—Ä–∞–ª-–º–∞–π–æ—Ä –º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏|–≥–µ–Ω–µ—Ä–∞–ª-–ª–µ–π—Ç–µ–Ω–∞–Ω—Ç –º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏)\b"
}

PATTERNS = {
    "ipn": r"\b\d{10}\b",
    "passport_id": r"\b\d{9}\b",
    "military_id": r"(?:[A-Z–ê-–Ø]{2}\s*-?\s*)?\d{6}\b",
    "military_unit": r"\b[–ê-–ØA-Z]\d{4}\b",
    "br_number_complex": r"‚Ññ–ë–†-?\d+(?:[/-]\d+)*(?:[/-][A-Z–ê-–Ø–á–Ü–Ñ“êa-z–∞-—è—ó—ñ—î“ë]+)+",
    "br_number_slash": r"‚Ññ\d+(?:/\d+){2,}(?:–¥—Å–∫|–ø|–∫)",
    "order_number_with_letters": r"‚Ññ\s*\d+(?:[/-](?:[A-Z–ê-–Ø–è–Ü–Ñ“êa-z–∞-—è—ó—ñ—î“ë]+\d*|\d+[A-Z–ê-–Ø–á–Ü–Ñ“êa-z–∞-—è—ó—ñ—î“ë]+))+",
    "br_number": r"(?<!\d\.)(?<!\d\d\.)‚Ññ?\d+(?:/\d+)*(?:–¥—Å–∫|–ø|–∫)?(?!\.\d{1,2}\.\d{4})",
    "order_number": r"(?<!\d\.)(?<!\d\d\.)‚Ññ\s*\d+(?:/\d+)*(?!\.\d{1,2}\.\d{4})",
    "brigade_number": r"\b(\d+)\s+(–æ–∫—Ä–µ–º–æ—ó –º–µ—Ö–∞–Ω—ñ–∑–æ–≤–∞–Ω–æ—ó –±—Ä–∏–≥–∞–¥–∏|–æ–º–±—Ä|–æ—à–ø|–æ—à–±—Ä|–±—Ä–∏–≥–∞–¥–∏|–æ–∫—Ä–µ–º–æ—ó —à—Ç—É—Ä–º–æ–≤–æ—ó –±—Ä–∏–≥–∞–¥–∏|–¥–µ—Å–∞–Ω—Ç–Ω–æ-—à—Ç—É—Ä–º–æ–≤–æ—ó –±—Ä–∏–≥–∞–¥–∏|–¥—à–±|—Ç–∞–Ω–∫–æ–≤–æ—ó –±—Ä–∏–≥–∞–¥–∏|—Ç–±—Ä)\b",
    "date": r"\b(\d{2})\.(\d{2})\.(\d{4})\b",
}

COMPILED_RANK_PATTERNS = {key: re.compile(pattern, re.IGNORECASE | re.UNICODE) for key, pattern in RANK_PATTERNS.items()}
COMPILED_PATTERNS = {key: re.compile(pattern, re.IGNORECASE | re.UNICODE) for key, pattern in PATTERNS.items()}

# ============================================================================
# –î–û–ü–û–ú–Ü–ñ–ù–Ü –§–£–ù–ö–¶–Ü–á (–ë–ê–ó–û–í–Ü)
# ============================================================================
# –§—É–Ω–∫—Ü—ñ—ó –∑–∞–≥–∞–ª—å–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑—ñ —Å–ª–æ–≤–Ω–∏–∫–∞–º–∏,
# —Ä–µ–≥—ñ—Å—Ç—Ä–æ–º –ª—ñ—Ç–µ—Ä —Ç–∞ –¥–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω–æ—é –≥–µ–Ω–µ—Ä–∞—Ü—ñ—î—é seed'—ñ–≤

def get_next_instance(masked_value: str, instance_counters: Dict[str, int]) -> int:
    """
    –ü–æ–≤–µ—Ä—Ç–∞—î –Ω–∞—Å—Ç—É–ø–Ω–∏–π –Ω–æ–º–µ—Ä –µ–∫–∑–µ–º–ø–ª—è—Ä–∞ –¥–ª—è –¥–∞–Ω–æ–≥–æ –∑–∞–º–∞—Å–∫–æ–≤–∞–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–Ω—è.

    Instance tracking: –≤—ñ–¥—Å—Ç–µ–∂—É—î–º–æ –≤–∏–ø–∞–¥–∫–∏ –∫–æ–ª–∏ —Ä—ñ–∑–Ω—ñ –æ—Ä–∏–≥—ñ–Ω–∞–ª–∏
    –º–∞—Å–∫—É—é—Ç—å—Å—è –≤ –æ–¥–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è (–∫–æ–ª—ñ–∑—ñ—ó)
    """
    instance_counters.setdefault(masked_value, 0)
    instance_counters[masked_value] += 1
    return instance_counters[masked_value]

def add_to_mapping(masking_dict: Dict, instance_counters: Dict, category: str, original: str, masked: str) -> str:
    """
    –î–æ–¥–∞—î –º–∞–ø–ø—ñ–Ω–≥ –æ—Ä–∏–≥—ñ–Ω–∞–ª‚Üí–º–∞—Å–∫–∞ –¥–æ —Å–ª–æ–≤–Ω–∏–∫–∞ —Ç–∞ –æ–Ω–æ–≤–ª—é—î —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É.

    Args:
        masking_dict: –°–ª–æ–≤–Ω–∏–∫ –∑ —É—Å—ñ–º–∞ –º–∞–ø–ø—ñ–Ω–≥–∞–º–∏
        instance_counters: –õ—ñ—á–∏–ª—å–Ω–∏–∫–∏ –µ–∫–∑–µ–º–ø–ª—è—Ä—ñ–≤ –¥–ª—è instance tracking
        category: –ö–∞—Ç–µ–≥–æ—Ä—ñ—è –¥–∞–Ω–∏—Ö (ipn, surname, rank, —Ç–æ—â–æ)
        original: –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è
        masked: –ó–∞–º–∞—Å–∫–æ–≤–∞–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è

    Returns:
        –ó–∞–º–∞—Å–∫–æ–≤–∞–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è (–º–æ–∂–µ –±—É—Ç–∏ –≤–∑—è—Ç–æ –∑ —ñ—Å–Ω—É—é—á–æ–≥–æ mapping)

    Note:
        –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–Ω–æ–≤–ª—é—î—Ç—å—Å—è —Ç—ñ–ª—å–∫–∏ –¥–ª—è –£–ù–Ü–ö–ê–õ–¨–ù–ò–• –æ—Ä–∏–≥—ñ–Ω–∞–ª—ñ–≤
    """
    if original not in masking_dict["mappings"][category]:
        masking_dict["mappings"][category][original] = {
            "masked_as": masked,
            "instances": []
        }
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–Ω–æ–≤–ª—é—î—Ç—å—Å—è —Ç—ñ–ª—å–∫–∏ –¥–ª—è —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –æ—Ä–∏–≥—ñ–Ω–∞–ª—ñ–≤
        masking_dict["statistics"][category] = masking_dict["statistics"].get(category, 0) + 1
    else:
        masked = masking_dict["mappings"][category][original]["masked_as"]

    # Instance tracking: –∑–±–µ—Ä—ñ–≥–∞—î–º–æ –∫–æ–∂–Ω–µ –≤—Ö–æ–¥–∂–µ–Ω–Ω—è
    instance_num = get_next_instance(masked, instance_counters)
    masking_dict["mappings"][category][original]["instances"].append(instance_num)
    return masked

def _apply_original_case(original: str, masked: str) -> str:
    """
    –ó–∞—Å—Ç–æ—Å–æ–≤—É—î —Ä–µ–≥—ñ—Å—Ç—Ä –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É –¥–æ –∑–∞–º–∞—Å–∫–æ–≤–∞–Ω–æ–≥–æ.

    –ü—ñ–¥—Ç—Ä–∏–º—É—î:
    - UPPER CASE (–≤–µ—Å—å —Ç–µ–∫—Å—Ç –≤–µ–ª–∏–∫–∏–º–∏)
    - Title Case (–ø–µ—Ä—à–∞ –≤–µ–ª–∏–∫–∞, —Ä–µ—à—Ç–∞ –º–∞–ª—ñ)
    - lower case (–≤–µ—Å—å —Ç–µ–∫—Å—Ç –º–∞–ª–∏–º–∏)

    Args:
        original: –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π —Ç–µ–∫—Å—Ç (–¥–ª—è –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ä–µ–≥—ñ—Å—Ç—Ä—É)
        masked: –ó–∞–º–∞—Å–∫–æ–≤–∞–Ω–∏–π —Ç–µ–∫—Å—Ç (–¥–ª—è –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è —Ä–µ–≥—ñ—Å—Ç—Ä—É)

    Returns:
        –ó–∞–º–∞—Å–∫–æ–≤–∞–Ω–∏–π —Ç–µ–∫—Å—Ç –∑ —Ä–µ–≥—ñ—Å—Ç—Ä–æ–º –æ—Ä–∏–≥—ñ–Ω–∞–ª—É

    Note:
        –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–≥—ñ—Å—Ç—Ä—É –≤ Bug Fix #16, #17, #18
    """
    if not original or not masked: return masked
    if original.isupper(): return masked.upper()
    elif len(original) > 1 and original[0].isupper() and original[1:].islower(): return masked.capitalize()
    else: return masked.lower()

def normalize_string(s: str) -> str:
    if not s: return ""
    s_str = str(s).lower()
    s_str = s_str.replace("'", "'").replace('\xa0', ' ').replace(".", " ").replace(";", " ")
    return re.sub(r'\s+', ' ', s_str).strip()

def normalize_identifier(identifier: str) -> str:
    if not identifier: return ""
    identifier_str = str(identifier).upper()
    return re.sub(r'[\s\-.]', '', identifier_str).strip()

def is_pib_anchor(word: str) -> bool:
    if word.startswith("___") and word.endswith("___"): return False
    if not word or len(word) <= 2: return False
    word_lower = word.lower()
    if word_lower in [w.lower() for w in EXCLUDE_WORDS]: return False
    if word_lower in [r.lower() for r in RANKS_LIST]: return False
    return word[0].isupper()

# ============================================================================
# –§–£–ù–ö–¶–Ü–á –ê–ù–ê–õ–Ü–ó–£ –ö–û–ù–¢–ï–ö–°–¢–£
# ============================================================================
# –§—É–Ω–∫—Ü—ñ—ó –¥–ª—è —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —Ç–∞ –∞–Ω–∞–ª—ñ–∑—É —Ä—ñ–∑–Ω–∏—Ö —Ç–∏–ø—ñ–≤ –¥–∞–Ω–∏—Ö —É —Ç–µ–∫—Å—Ç—ñ:
# - –î–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è seed'—ñ–≤ (–¥–ª—è unmask)
# - –†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —Ä—è–¥–∫—ñ–≤ –∑ –ü–Ü–ë
# - –ê–Ω–∞–ª—ñ–∑ –≥—Ä–∞–º–∞—Ç–∏—á–Ω–∏—Ö —Ñ–æ—Ä–º —ñ–º–µ–Ω —Ç–∞ –∑–≤–∞–Ω—å
# - –í–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –∑–≤–∞–Ω—å —Ç–∞ –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö —Å–ª—ñ–≤

def get_deterministic_seed(original: str) -> int:
    """
    –ì–µ–Ω–µ—Ä—É—î –¥–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω–∏–π seed –¥–ª—è –º–∞—Å–∫—É–≤–∞–Ω–Ω—è –Ω–∞ –æ—Å–Ω–æ–≤—ñ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–Ω—è.

    –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î hashlib (blake2b) –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —É–Ω—ñ–∫–∞–ª—å–Ω–æ–≥–æ, –∞–ª–µ –ø–æ–≤—Ç–æ—Ä—é–≤–∞–Ω–æ–≥–æ seed'–∞.
    –¶–µ –≥–∞—Ä–∞–Ω—Ç—É—î —â–æ –æ–¥–Ω–µ —ñ —Ç–µ —Å–∞–º–µ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è –∑–∞–≤–∂–¥–∏ –æ—Ç—Ä–∏–º–∞—î –æ–¥–Ω—É —ñ —Ç—É —Å–∞–º—É –º–∞—Å–∫—É,
    —â–æ —î –∫—Ä–∏—Ç–∏—á–Ω–æ –≤–∞–∂–ª–∏–≤–∏–º –¥–ª—è –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ unmask (—Ä–æ–∑–º–∞—Å–∫—É–≤–∞–Ω–Ω—è).

    –î–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω–µ –º–∞—Å–∫—É–≤–∞–Ω–Ω—è –æ–∑–Ω–∞—á–∞—î:
    - "–ü–µ—Ç—Ä–µ–Ω–∫–æ" –∑–∞–≤–∂–¥–∏ ‚Üí seed 12345 ‚Üí "–Ü–≤–∞–Ω–µ–Ω–∫–æ"
    - "–°–∏–¥–æ—Ä–µ–Ω–∫–æ" –∑–∞–≤–∂–¥–∏ ‚Üí seed 67890 ‚Üí "–ö–æ–≤–∞–ª–µ–Ω–∫–æ"

    –ë–µ–∑ –¥–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω–æ—Å—Ç—ñ unmask –±—É–≤ –±–∏ –Ω–µ–º–æ–∂–ª–∏–≤–∏–º, –æ—Å–∫—ñ–ª—å–∫–∏ –ø—Ä–∏ —Ä–æ–∑–º–∞—Å–∫—É–≤–∞–Ω–Ω—ñ
    –º–∏ –ø–æ–≤–∏–Ω–Ω—ñ –∑–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ —Ç–æ—á–Ω–æ —Ç—ñ —Å–∞–º—ñ –º–∞—Å–∫–∏ —â–æ –π –ø—Ä–∏ –º–∞—Å–∫—É–≤–∞–Ω–Ω—ñ.

    Args:
        original: –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è (–Ü–ü–ù, –ø—Ä—ñ–∑–≤–∏—â–µ, —ñ–º'—è, —Ç–æ—â–æ)

    Returns:
        –¶—ñ–ª–æ—á–∏—Å–µ–ª—å–Ω–∏–π seed –¥–ª—è random.seed()

    Note:
        –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –≥–ª–æ–±–∞–ª—å–Ω—É –∫–æ–Ω—Å—Ç–∞–Ω—Ç—É HASH_ALGORITHM = 'blake2b'
    """
    if HASH_ALGORITHM == 'md5': hasher = hashlib.md5()
    elif HASH_ALGORITHM == 'sha1': hasher = hashlib.sha1()
    elif HASH_ALGORITHM == 'sha256': hasher = hashlib.sha256()
    elif HASH_ALGORITHM == 'blake2b': hasher = hashlib.blake2b()
    elif HASH_ALGORITHM == 'sha512': hasher = hashlib.sha512()
    else: raise ValueError(f"Unknown hash algorithm: {HASH_ALGORITHM}")
    hasher.update(original.encode('utf-8'))
    return int(hasher.hexdigest(), 16) % (2**32)

# ============================================================================
# –ú–û–í–ù–Ü –¢–ê –õ–û–ì–Ü–ß–ù–Ü –§–£–ù–ö–¶–Ü–á
# ============================================================================

def is_likely_surname_by_case(word: str) -> bool:
    if word.startswith("___") and word.endswith("___"): return False
    if not word or len(word) < 3: return False
    letters_only = re.sub(r"[-']", '', word)
    return letters_only.isupper() and len(letters_only) >= 3

def looks_like_name(word: str) -> bool:
    if word.startswith("___") and word.endswith("___"): return False
    clean_word = word.rstrip(',.!?;:')
    if len(clean_word) < 3: return False
    if clean_word in EXCLUDE_WORDS or clean_word.lower() in [w.lower() for w in EXCLUDE_WORDS]: return False
    if re.search(r'\d', clean_word): return False
    if clean_word.lower() in RANKS_LIST: return False
    if clean_word.lower() in ['–ø–æ', '–ø—Ä–æ', '–≤—ñ–¥', '–¥–æ', '–∑–∞', '–Ω–∞', '—É', '–≤', '–∑', '—ñ–∑']: return False

    if clean_word[0].isupper() and clean_word[1:].islower(): return True
    if clean_word.isupper(): return True

    declension_endings = ['–æ–º', '–µ–º', '—î–º', '—ñ–º', '–æ—é', '—î—é', '–æ—é', '—É', '—é', '–∞', '—è', '—ñ', '—ó']
    for ending in declension_endings:
        if len(clean_word) > len(ending) + 2:
            stem = clean_word[:-len(ending)]
            suffix = clean_word[-len(ending):]
            if stem.isupper() and suffix.islower() and suffix == ending:
                return True
    return False

def detect_gender_by_patronymic(patronymic: str) -> str:
    if not patronymic: return 'unknown'
    patron_lower = patronymic.lower().strip('.,!?;')
    male_endings = ['–æ–≤–∏—á', '—î–≤–∏—á', '—ñ–π–æ–≤–∏—á', '–π–æ–≤–∏—á', '–æ–≤–∏—á–∞', '—î–≤–∏—á–∞', '—ñ–π–æ–≤–∏—á–∞', '–π–æ–≤–∏—á–∞', '–æ–≤–∏—á—É', '—î–≤–∏—á—É', '—ñ–π–æ–≤–∏—á—É', '–π–æ–≤–∏—á—É', '–æ–≤–∏—á–µ–º', '—î–≤–∏—á–µ–º', '—ñ–π–æ–≤–∏—á–µ–º', '–π–æ–≤–∏—á–µ–º']
    female_endings = ['—ñ–≤–Ω–∞', '—ó–≤–Ω–∞', '—ñ–≤–Ω–∏', '—ó–≤–Ω–∏', '—ñ–≤–Ω—ñ', '—ó–≤–Ω—ñ', '—ñ–≤–Ω–æ—é', '—ó–≤–Ω–æ—é']
    if any(patron_lower.endswith(e) for e in male_endings): return 'male'
    if any(patron_lower.endswith(e) for e in female_endings): return 'female'
    return 'unknown'

def detect_name_case_and_gender(name: str) -> Tuple[str, str]:
    if not name: return 'nominative', 'male'
    name_lower = name.lower().strip('.,!?;')
    if name_lower.endswith(('–æ–º', '–µ–º', '—î–º', '—ñ–º', '—ó–º')): return 'instrumental', 'male'
    if name_lower.endswith(('—É', '—é')) and not name_lower.endswith(('–æ—é', '—î—é', '—ñ—î—é')): return 'dative', 'male'
    if name_lower.endswith(('–∞', '—è')) and len(name) > 4:
        common_female_endings = ['—ñ—è', '–ª–∞', '–Ω–∞', '—Ä–∞', '—Ç–∞', '–∫–∞', '–≥–∞', '–≤–∞', '–Ω—è', '—Å—è', '—à–∞']
        if not any(name_lower.endswith(e) for e in common_female_endings): return 'genitive', 'male'
    if name_lower.endswith(('—ñ—î—é', '–æ—é', '—î—é')): return 'instrumental', 'female'
    if name_lower.endswith(('—ñ', '—ó')) and len(name) > 3: return 'dative', 'female'
    if name_lower.endswith(('—ñ—è', '–∞', '—è')) and len(name) > 2: return 'nominative', 'female'
    return 'nominative', 'male'

def is_easy_to_decline(name: str, gender: str) -> bool:
    if not name: return False
    name_lower = name.lower()
    if name_lower in PROBLEMATIC_NAMES: return False
    if re.search(r'([–∞–µ—î–∏—ñ—ó–æ—É—é—è])\1', name_lower): return False
    if len(name) < 4 or len(name) > 9: return False

    if gender == 'male':
        if name_lower.endswith(('–æ', '–∞', '–π', '—ñ–π', '—Ä', '–Ω', '–ª', '–∫', '–º', '–≤', '—Ç')):
            if name_lower in ['—ñ–ª–ª—è', '—Å–∞–≤–≤–∞', '–ª—É–∫–∞', '–∫—É–∑—å–º–∞', '—Ñ–æ–º–∞']: return False
            return True
        return False
    elif gender == 'female':
        if name_lower.endswith(('–∞', '—è', '—ñ—è')): return True
        return False
    return False

def apply_case_to_name(name: str, case: str, gender: str) -> str:
    if not name: return name
    name = name.strip()
    if case == 'nominative': return name

    if gender == 'male':
        stem = name
        if name.endswith('–æ') or name.endswith('–∞'): stem = name[:-1]
        elif name.endswith('—ñ–π'): stem = name[:-2] + '—ñ'
        elif name.endswith('–π'): stem = name[:-1]

        if case == 'genitive':
            if name.endswith('–æ') or name.endswith('–∞'): return stem + ('–∞' if name.endswith('–æ') else '–∏')
            if name.endswith('—ñ–π') or name.endswith('–π'): return stem + '—è'
            return stem + '–∞'
        elif case == 'dative':
            if name.endswith('–æ'): return stem + '—É'
            if name.endswith('–∞'): return stem + '—ñ'
            if name.endswith('—ñ–π') or name.endswith('–π'): return stem + '—é'
            return stem + '—É'
        elif case == 'instrumental':
            if name.endswith('–æ'): return stem + '–æ–º'
            if name.endswith('–∞'): return stem + '–æ—é'
            if name.endswith('—ñ–π') or name.endswith('–π'): return stem + '—î–º'
            return stem + '–æ–º'

    elif gender == 'female':
        stem = name
        if name.endswith('—ñ—è'): stem = name[:-2]
        elif name.endswith(('–∞', '—è')): stem = name[:-1]

        if case == 'genitive' or case == 'dative':
            if name.endswith('—ñ—è'): return stem + '—ñ—ó'
            return stem + '—ñ'
        elif case == 'instrumental':
            if name.endswith('—ñ—è'): return stem + '—ñ—î—é'
            return stem + '–æ—é'

    return name

def generate_easy_name(gender: str, first_letter: str, seed: int, max_attempts: int = 50) -> str:
    random.seed(seed)
    whitelist = GOOD_UKRAINIAN_NAMES_MALE if gender == 'male' else GOOD_UKRAINIAN_NAMES_FEMALE
    available = [n for n in whitelist if n[0].lower() == first_letter.lower()]
    if available:
        name = random.choice(available).capitalize()
        return name

    last_name = None
    for attempt in range(max_attempts):
        if gender == 'female': name = fake_uk.first_name_female()
        else: name = fake_uk.first_name_male()
        last_name = name
        if name[0].lower() != first_letter: continue
        if is_easy_to_decline(name, gender): return name

    if whitelist: return random.choice(whitelist).capitalize()
    return last_name if last_name else (fake_uk.first_name_female() if gender == 'female' else fake_uk.first_name_male())

# ============================================================================
# –§–£–ù–ö–¶–Ü–á –ê–ù–ê–õ–Ü–ó–£ –ö–û–ù–¢–ï–ö–°–¢–£
# ============================================================================

def analyze_number_sign_context(text: str, match: re.Match) -> Optional[Dict]:
    """–ê–Ω–∞–ª—ñ–∑—É—î –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—ñ—Å–ª—è —Å–∏–º–≤–æ–ª—É ‚Ññ"""
    pos = match.end()
    after_text = text[pos:pos+100]

    # 1. ‚Ññ–ë–†...
    if re.match(r'\s*–ë–†', after_text, re.IGNORECASE):
        br_match = re.match(r'\s*–ë–†[-\s]?(\d+(?:[/-]\d+)*(?:[/-][–ê-–Ø–∞-—èA-Za-z]+)*)', after_text, re.IGNORECASE)
        if br_match:
            full_text = text[match.start():match.end() + len(br_match.group(0))]
            return {
                'type': 'br_complex',
                'full_text': full_text,
                'number_part': br_match.group(1),
                'start': match.start(),
                'end': match.end() + len(br_match.group(0))
            }

    # 2. ‚Ññ 123...
    number_match = re.match(r'\s*(\d+(?:[/-]\d+)*(?:[/-][–ê-–Ø–∞-—èA-Za-z]+|[–ê-–Ø–∞-—èA-Za-z]+)?)', after_text)
    if not number_match:
        return None

    number_text = number_match.group(1)
    full_text = text[match.start():match.end() + len(number_match.group(0))]

    # 3. ‚Ññ 123–¥—Å–∫
    if re.search(r'(–¥—Å–∫|–ø|–∫)$', number_text, re.IGNORECASE):
        if number_text.count('/') >= 2:
            return {'type': 'br_with_slashes', 'full_text': full_text, 'number_part': number_text, 'start': match.start(), 'end': match.end() + len(number_match.group(0))}
        else:
            return {'type': 'br_with_suffix', 'full_text': full_text, 'number_part': number_text, 'start': match.start(), 'end': match.end() + len(number_match.group(0))}

    # 4. ‚Ññ 123/–û–ö–ü
    if re.search(r'[–ê-–Ø–∞-—èA-Za-z]', number_text):
        return {'type': 'order_with_letters', 'full_text': full_text, 'number_part': number_text, 'start': match.start(), 'end': match.end() + len(number_match.group(0))}

    # 5. ‚Ññ 123
    return {'type': 'order_simple', 'full_text': full_text, 'number_part': number_text, 'start': match.start(), 'end': match.end() + len(number_match.group(0))}

def analyze_br_keyword(text: str, match: re.Match) -> Optional[Dict]:
    """–ê–Ω–∞–ª—ñ–∑—É—î –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—ñ—Å–ª—è —Å–ª–æ–≤–∞ –ë–†"""
    pos = match.end()
    after_text = text[pos:pos+100]
    br_match = re.match(r'[-\s]?(\d+(?:[/-]\d+)*(?:–¥—Å–∫|–ø|–∫)?)', after_text, re.IGNORECASE)
    if br_match:
        return {
            'type': 'br_standalone',
            'full_text': match.group(0) + br_match.group(0),
            'number_part': br_match.group(1),
            'start': match.start(),
            'end': match.end() + len(br_match.group(0))
        }
    return None

def clean_line_before_parsing(line: str) -> str:
    line = re.sub(r'\d{1,2}[.!]\d{1,2}\.\d{4}', '', line)
    line = re.sub(r'\s+—Ä–æ–∫—É\s+', ' ', line, flags=re.IGNORECASE)
    line = re.sub(r'\s+', ' ', line)
    return line.strip()

def extract_identifier_from_line(line: str) -> Optional[str]:
    words = line.strip().split()
    if not words: return None
    last_word = words[-1]
    if re.match(r'^[A-Za-z–ê-–Ø–∞-—è–Ü—ñ–á—ó–Ñ—îŒê—ë]*\d+[\w\-]*$', last_word):
        return normalize_identifier(last_word)
    return None

def extract_base_rank(full_rank_text: str) -> Tuple[str, str]:
    if not full_rank_text: return full_rank_text, ""
    service_type_phrases = ['–º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏', '—é—Å—Ç–∏—Ü—ñ—ó']
    status_phrases = ['—É –≤—ñ–¥—Å—Ç–∞–≤—Ü—ñ', '–≤ –∑–∞–ø–∞—Å—ñ', '—É –∑–∞–ø–∞—Å—ñ', '–Ω–∞ –ø–µ–Ω—Å—ñ—ó', '–≤ —Ä–µ–∑–µ—Ä–≤—ñ', '—É —Ä–µ–∑–µ—Ä–≤—ñ']
    full_rank_lower = full_rank_text.lower()
    base_rank = full_rank_text
    additional_parts = []

    for phrase in service_type_phrases:
        if phrase in full_rank_lower:
            phrase_index = full_rank_lower.find(phrase)
            base_rank = full_rank_text[:phrase_index].strip()
            additional_parts.append(full_rank_text[phrase_index:phrase_index + len(phrase)])
            remaining_text = full_rank_text[phrase_index + len(phrase):].strip()
            full_rank_lower = remaining_text.lower()
            full_rank_text = remaining_text
            break

    for phrase in status_phrases:
        if phrase in full_rank_lower:
            if not additional_parts:
                phrase_index = full_rank_text.lower().find(phrase)
                base_rank = full_rank_text[:phrase_index].strip()
            additional_parts.append(full_rank_text[full_rank_text.lower().find(phrase):full_rank_text.lower().find(phrase) + len(phrase)])
            break

    additional = ' '.join(additional_parts) if additional_parts else ""
    return base_rank, additional

def looks_like_pib_line(line: str) -> bool:
    if not line or len(line.strip()) < 10: return False
    line_clean = line.strip()
    line_lower = line_clean.lower()

    if line_clean.startswith('===') or line_clean.startswith('---') or re.match(r'^[–ê-–Ø“ê–Ñ–Ü–áA-Z\s]+:\s*$', line_clean): return False

    normalized = normalize_string(line_clean)
    has_rank = any(rank in normalized for rank in RANKS_LIST)

    if not has_rank:
        if line_clean.isupper() and len(line_clean.split()) >= 3:
            if not re.search(r'\b\d{10}\b|\b\d{9}\b|[–ê-–ØA-Z]{2}\s*-?\s*\d{6}\b', line_clean): return False

    exclude_starts = ['–≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ', '–∑–≥—ñ–¥–Ω–æ', '–Ω–∞ –ø—ñ–¥—Å—Ç–∞–≤—ñ']
    for start in exclude_starts:
        if line_lower.startswith(start): return False

    if len(line_clean) < 100:
        legal_terms = ['—Å—Ç–∞—Ç—É—Ç—É', '–∫–æ–¥–µ–∫—Å—É', '–∑–∞–∫–æ–Ω—É', '—É–∫–∞–∑—É']
        for term in legal_terms:
            if term in line_lower: return False

    if has_rank: return True

    words = line_clean.split()
    capitalize_sequence = 0
    max_sequence = 0
    for word in words:
        clean_word = word.strip(',.!?;:')
        if (clean_word and len(clean_word) > 2 and clean_word[0].isupper() and looks_like_name(clean_word)):
            capitalize_sequence += 1
            max_sequence = max(max_sequence, capitalize_sequence)
        else:
            capitalize_sequence = 0

    if max_sequence >= 2: return True
    if re.search(r'\b\d{10}\b|\b\d{9}\b|[–ê-–ØA-Z]{2}\s*-?\s*\d{6}\b', line_clean): return True
    return False

def parse_hybrid_line(line: str) -> Tuple[Optional[str], Optional[str], Optional[str]]:
    line = line.strip()
    if not line: return None, None, None
    line = clean_line_before_parsing(line)
    identifier = extract_identifier_from_line(line)
    if identifier:
        words = line.split()
        line = ' '.join(words[:-1])
    parts = line.strip().split()
    if not parts: return None, None, identifier
    if parts and parts[0].isdigit(): parts = parts[1:]
    if not parts: return None, None, identifier

    normalized_line = normalize_string(line)
    pib_start_index = -1
    found_rank = None
    found_rank_original_case = None
    rank_position = -1
    rank_matches = []

    for rank_form in ALL_RANK_FORMS:
        rank_pattern = rank_form + ' '
        rank_index = normalized_line.find(rank_pattern)
        if rank_index != -1:
            words_before_rank = normalized_line[:rank_index].split()
            rank_word_count = len(rank_form.split())
            words_after = normalized_line[rank_index + len(rank_pattern):].split()
            additional_words = 0

            if len(words_after) >= 2:
                two_words = ' '.join(words_after[:2])
                if two_words == '–º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏':
                    additional_words += 2
                    words_after = words_after[2:]
            if words_after and words_after[0] == '—é—Å—Ç–∏—Ü—ñ—ó':
                additional_words += 1
                words_after = words_after[1:]
            if words_after and words_after[0] in ['—É', '–≤', '–Ω–∞']:
                if len(words_after) > 1 and words_after[1] in ['–≤—ñ–¥—Å—Ç–∞–≤—Ü—ñ', '–∑–∞–ø–∞—Å—ñ', '–ø–µ–Ω—Å—ñ—ó', '—Ä–µ–∑–µ—Ä–≤—ñ']:
                    additional_words += 2

            rank_matches.append((rank_index, rank_form, len(words_before_rank), rank_word_count + additional_words))

    if rank_matches:
        rank_matches.sort(key=lambda x: x[0])
        rank_index, found_rank, rank_position, rank_word_count = rank_matches[0]
        pib_start_index = rank_position + rank_word_count
        rank_words = line.split()[rank_position:rank_position + rank_word_count]
        found_rank_original_case = ' '.join(rank_words) if rank_words else found_rank

    if pib_start_index == -1:
        for i, part in enumerate(parts):
            if is_pib_anchor(part):
                pib_start_index = i
                break

    if pib_start_index == -1: return None, None, identifier

    if found_rank:
        rank = found_rank_original_case if found_rank_original_case else found_rank
    else:
        rank = " ".join(parts[rank_position:pib_start_index]) if 0 <= rank_position < pib_start_index else ""

    pib_words = []
    for word in parts[pib_start_index:pib_start_index + 3]:
        if looks_like_name(word):
            pib_words.append(word)
        else:
            break
    pib = " ".join(pib_words) if pib_words else None

    if rank and len(rank) > 60: return None, None, identifier
    if rank:
        rank_without_number = re.sub(r'^\d+\.\s*', '', rank)
        if re.search(r'\d{2,}', rank_without_number): return None, None, identifier
    if pib and len(pib.split()) < 2: return None, None, identifier
    if pib:
        pib_lower = pib.lower()
        bad_words = ['—Å—Ç–∞—Ç—É—Ç', '–Ω–∞–∫–∞–∑', '–≤–∏–º–æ–≥', '–ø–æ—Ä—É—à–µ–Ω–Ω—è', '—Å–ª—É–∂–±–∏', '–∑–∞–∫–æ–Ω', '—É–∫–∞–∑', '–∫–æ–¥–µ–∫—Å', '–ø–æ–ª–æ–∂–µ–Ω–Ω—è']
        for bad_word in bad_words:
            if bad_word in pib_lower: return None, None, identifier
    if rank and not pib and not identifier: return None, None, None

    return rank, pib, identifier

# ============================================================================
# –§–£–ù–ö–¶–Ü–á –ú–ê–°–ö–£–í–ê–ù–ù–Ø (–ü–ï–†–°–û–ù–ê–õ–¨–ù–Ü –î–ê–ù–Ü)
# ============================================================================
# –§—É–Ω–∫—Ü—ñ—ó –¥–ª—è –º–∞—Å–∫—É–≤–∞–Ω–Ω—è –ü–Ü–ë, –Ü–ü–ù, –ø–∞—Å–ø–æ—Ä—Ç—ñ–≤, –≤—ñ–π—Å—å–∫–æ–≤–∏—Ö ID

def mask_ipn(original: str, masking_dict: Dict, instance_counters: Dict) -> str:
    """
    –ú–∞—Å–∫—É—î –Ü–ü–ù (–Ü–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω–∏–π –ø–æ–¥–∞—Ç–∫–æ–≤–∏–π –Ω–æ–º–µ—Ä).

    –§–æ—Ä–º–∞—Ç: 10 —Ü–∏—Ñ—Ä
    –õ–æ–≥—ñ–∫–∞: –ó–±–µ—Ä—ñ–≥–∞—î –ø–µ—Ä—à—ñ 3 —Ç–∞ –æ—Å—Ç–∞–Ω–Ω—é —Ü–∏—Ñ—Ä—É, –∑–º—ñ–Ω—é—î —Å–µ—Ä–µ–¥–Ω—ñ 6 —Ü–∏—Ñ—Ä

    Args:
        original: –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π –Ü–ü–ù (10 —Ü–∏—Ñ—Ä)
        masking_dict: –°–ª–æ–≤–Ω–∏–∫ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤
        instance_counters: –õ—ñ—á–∏–ª—å–Ω–∏–∫–∏ –µ–∫–∑–µ–º–ø–ª—è—Ä—ñ–≤

    Returns:
        –ó–∞–º–∞—Å–∫–æ–≤–∞–Ω–∏–π –Ü–ü–ù —É —Ç–æ–º—É –∂ —Ñ–æ—Ä–º–∞—Ç—ñ
    """
    if original in masking_dict["mappings"]["ipn"]:
        masked = masking_dict["mappings"]["ipn"][original]["masked_as"]
    else:
        if len(original) != 10 or not original.isdigit(): return original
        seed = get_deterministic_seed(original)
        random.seed(seed)
        middle = ''.join([str(random.randint(0, 9)) for _ in range(6)])
        masked = original[:3] + middle + original[-1]
    return add_to_mapping(masking_dict, instance_counters, "ipn", original, masked)

def mask_passport_id(original: str, masking_dict: Dict, instance_counters: Dict) -> str:
    """
    –ú–∞—Å–∫—É—î ID –ø–∞—Å–ø–æ—Ä—Ç—É.

    –§–æ—Ä–º–∞—Ç: 9 —Ü–∏—Ñ—Ä
    –õ–æ–≥—ñ–∫–∞: –ó–±–µ—Ä—ñ–≥–∞—î –ø–µ—Ä—à—ñ 3 —Ç–∞ –æ—Å—Ç–∞–Ω–Ω—é —Ü–∏—Ñ—Ä—É, –∑–º—ñ–Ω—é—î —Å–µ—Ä–µ–¥–Ω—ñ 5 —Ü–∏—Ñ—Ä

    Args:
        original: –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π ID –ø–∞—Å–ø–æ—Ä—Ç—É (9 —Ü–∏—Ñ—Ä)
        masking_dict: –°–ª–æ–≤–Ω–∏–∫ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤
        instance_counters: –õ—ñ—á–∏–ª—å–Ω–∏–∫–∏ –µ–∫–∑–µ–º–ø–ª—è—Ä—ñ–≤

    Returns:
        –ó–∞–º–∞—Å–∫–æ–≤–∞–Ω–∏–π ID –ø–∞—Å–ø–æ—Ä—Ç—É —É —Ç–æ–º—É –∂ —Ñ–æ—Ä–º–∞—Ç—ñ
    """
    if original in masking_dict["mappings"]["passport_id"]:
        masked = masking_dict["mappings"]["passport_id"][original]["masked_as"]
    else:
        if len(original) != 9 or not original.isdigit(): return original
        seed = get_deterministic_seed(original)
        random.seed(seed)
        middle = ''.join([str(random.randint(0, 9)) for _ in range(5)])
        masked = original[:3] + middle + original[-1]
    return add_to_mapping(masking_dict, instance_counters, "passport_id", original, masked)

def mask_military_id(original: str, masking_dict: Dict, instance_counters: Dict) -> str:
    """
    –ú–∞—Å–∫—É—î –≤—ñ–π—Å—å–∫–æ–≤–∏–π ID.

    –§–æ—Ä–º–∞—Ç–∏:
    - ######  (6 —Ü–∏—Ñ—Ä)
    - AA ######  (2 –≤–µ–ª–∏–∫—ñ –ª—ñ—Ç–µ—Ä–∏ + –ø—Ä–æ–±—ñ–ª + 6 —Ü–∏—Ñ—Ä)
    - AA-######  (2 –≤–µ–ª–∏–∫—ñ –ª—ñ—Ç–µ—Ä–∏ + –¥–µ—Ñ—ñ—Å + 6 —Ü–∏—Ñ—Ä)

    –õ–æ–≥—ñ–∫–∞: –ó–±–µ—Ä—ñ–≥–∞—î –ø—Ä–µ—Ñ—ñ–∫—Å (–ª—ñ—Ç–µ—Ä–∏), –ø–µ—Ä—à—ñ 2 —Ç–∞ –æ—Å—Ç–∞–Ω–Ω—ñ 2 —Ü–∏—Ñ—Ä–∏, –∑–º—ñ–Ω—é—î —Å–µ—Ä–µ–¥–Ω—ñ 2

    Args:
        original: –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π –≤—ñ–π—Å—å–∫–æ–≤–∏–π ID
        masking_dict: –°–ª–æ–≤–Ω–∏–∫ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤
        instance_counters: –õ—ñ—á–∏–ª—å–Ω–∏–∫–∏ –µ–∫–∑–µ–º–ø–ª—è—Ä—ñ–≤

    Returns:
        –ó–∞–º–∞—Å–∫–æ–≤–∞–Ω–∏–π –≤—ñ–π—Å—å–∫–æ–≤–∏–π ID —É —Ç–æ–º—É –∂ —Ñ–æ—Ä–º–∞—Ç—ñ
    """
    if original in masking_dict["mappings"]["military_id"]:
        masked = masking_dict["mappings"]["military_id"][original]["masked_as"]
    else:
        normalized = normalize_identifier(original)
        prefix_match = re.match(r'^([A-Z–ê-–Ø]{2})?(\d{6})$', normalized)
        if not prefix_match: return original
        prefix = prefix_match.group(1) or ""
        digits = prefix_match.group(2)
        seed = get_deterministic_seed(original)
        random.seed(seed)
        middle = ''.join([str(random.randint(0, 9)) for _ in range(2)])
        masked_digits = digits[:2] + middle + digits[-2:]
        if " " in original: masked = f"{prefix} {masked_digits}" if prefix else masked_digits
        elif "-" in original: masked = f"{prefix}-{masked_digits}" if prefix else masked_digits
        else: masked = prefix + masked_digits
    return add_to_mapping(masking_dict, instance_counters, "military_id", original, masked)

def mask_surname(original: str, masking_dict: Dict, instance_counters: Dict) -> str:
    """
    –ú–∞—Å–∫—É—î –ø—Ä—ñ–∑–≤–∏—â–µ.

    –õ–û–ì–Ü–ö–ê –ú–ê–°–ö–£–í–ê–ù–ù–Ø:
    - –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä—ñ–∑–≤–∏—â (<5 —Å–∏–º–≤–æ–ª—ñ–≤): –≥–µ–Ω–µ—Ä—É—î –Ω–æ–≤–µ —á–µ—Ä–µ–∑ faker
    - –î–ª—è –¥–æ–≤–≥–∏—Ö –ø—Ä—ñ–∑–≤–∏—â (‚â•5 —Å–∏–º–≤–æ–ª—ñ–≤): –∑–±–µ—Ä—ñ–≥–∞—î –ø–æ—á–∞—Ç–æ–∫ (3) —Ç–∞ –∫—ñ–Ω–µ—Ü—å (2), –∑–º—ñ–Ω—é—î —Å–µ—Ä–µ–¥–∏–Ω—É

    –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø –§–û–†–ú–ê–¢–£:
    - UPPER CASE ‚Üí UPPER CASE
    - Title Case ‚Üí Title Case
    - lower case ‚Üí lower case

    –í–ò–ö–õ–Æ–ß–ï–ù–ù–Ø:
    - –ê–±—Ä–µ–≤—ñ–∞—Ç—É—Ä–∏ –∑ ABBREVIATION_WHITELIST –ù–ï –º–∞—Å–∫—É—é—Ç—å—Å—è (–ó–°–£, –ú–û–£, –°–ë–£ —Ç–æ—â–æ)

    Args:
        original: –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–µ –ø—Ä—ñ–∑–≤–∏—â–µ
        masking_dict: –°–ª–æ–≤–Ω–∏–∫ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤
        instance_counters: –õ—ñ—á–∏–ª—å–Ω–∏–∫–∏ –µ–∫–∑–µ–º–ø–ª—è—Ä—ñ–≤

    Returns:
        –ó–∞–º–∞—Å–∫–æ–≤–∞–Ω–µ –ø—Ä—ñ–∑–≤–∏—â–µ –∑—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è–º —Ä–µ–≥—ñ—Å—Ç—Ä—É

    Note:
        Bug Fix #10: –ö–æ—Ä–æ—Ç—Ü—ñ –ø—Ä—ñ–∑–≤–∏—â–∞ (<5 —Å–∏–º–≤–æ–ª—ñ–≤) —Ç–µ–ø–µ—Ä –º–∞—Å–∫—É—é—Ç—å—Å—è –∫–æ—Ä–µ–∫—Ç–Ω–æ
    """
    if original.lower() in ABBREVIATION_WHITELIST: return original
    if original in masking_dict["mappings"]["surname"]:
        masked = masking_dict["mappings"]["surname"][original]["masked_as"]
    else:
        is_upper = original.isupper()
        is_capitalize = original[0].isupper() and original[1:].islower()
        seed = get_deterministic_seed(original)
        random.seed(seed)
        fake_uk.seed_instance(seed)
        fake_surname = fake_uk.last_name()

        # –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä—ñ–∑–≤–∏—â –≥–µ–Ω–µ—Ä—É—î–º–æ –Ω–æ–≤–µ –ø–æ–≤–Ω—ñ—Å—Ç—é
        if len(original) < 5:
            target_length = random.randint(max(3, len(original) - 1), min(6, len(original) + 2))
            masked = fake_surname[:target_length] if len(fake_surname) > target_length else fake_surname
        else:
            # –î–ª—è –¥–æ–≤–≥–∏—Ö –∑–±–µ—Ä—ñ–≥–∞—î–º–æ –ø–æ—á–∞—Ç–æ–∫ —Ç–∞ –∫—ñ–Ω–µ—Ü—å
            middle_len = min(random.randint(2, 7), len(fake_surname)-2)
            middle = fake_surname[1:1+middle_len] if len(fake_surname) > 4 else fake_surname[1:-1]
            masked = original[:3] + middle + original[-2:]

        # –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ —Ä–µ–≥—ñ—Å—Ç—Ä
        if is_upper: masked = masked.upper()
        elif is_capitalize: masked = masked.capitalize()
    return add_to_mapping(masking_dict, instance_counters, "surname", original, masked)

def mask_patronymic(patronymic: str, gender: str, masking_dict: Dict, instance_counters: Dict) -> str:
    """
    –ú–∞—Å–∫—É—î –ø–æ –±–∞—Ç—å–∫–æ–≤—ñ –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º —Ä–æ–¥—É.

    –û–°–û–ë–õ–ò–í–û–°–¢–Ü:
    - –ì–µ–Ω–µ—Ä—É—î –Ω–æ–≤–µ –ø–æ –±–∞—Ç—å–∫–æ–≤—ñ —á–µ—Ä–µ–∑ faker.middle_name_male() –∞–±–æ faker.middle_name_female()
    - –†—ñ–¥ –≤–∏–∑–Ω–∞—á–∞—î—Ç—å—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É (—á–µ—Ä–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä gender)
    - –ó–±–µ—Ä—ñ–≥–∞—î —Ä–µ–≥—ñ—Å—Ç—Ä –æ—Ä–∏–≥—ñ–Ω–∞–ª—É

    –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø –§–û–†–ú–ê–¢–£:
    - UPPER CASE ‚Üí UPPER CASE
    - Title Case ‚Üí Title Case
    - lower case ‚Üí lower case

    Args:
        patronymic: –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–µ –ø–æ –±–∞—Ç—å–∫–æ–≤—ñ
        gender: –†—ñ–¥ ('male' –∞–±–æ 'female')
        masking_dict: –°–ª–æ–≤–Ω–∏–∫ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤
        instance_counters: –õ—ñ—á–∏–ª—å–Ω–∏–∫–∏ –µ–∫–∑–µ–º–ø–ª—è—Ä—ñ–≤

    Returns:
        –ó–∞–º–∞—Å–∫–æ–≤–∞–Ω–µ –ø–æ –±–∞—Ç—å–∫–æ–≤—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ–≥–æ —Ä–æ–¥—É –∑—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è–º —Ä–µ–≥—ñ—Å—Ç—Ä—É

    Note:
        –î–æ–¥–∞–Ω–æ –≤ v2.2.1 –¥–ª—è –∫–æ—Ä–µ–∫—Ç–Ω–æ–≥–æ –º–∞—Å–∫—É–≤–∞–Ω–Ω—è –ø–æ–≤–Ω–æ–≥–æ –ü–Ü–ë
    """
    if not MASK_NAMES or not patronymic: return patronymic
    is_upper = patronymic.isupper()
    is_capitalize = patronymic[0].isupper() and patronymic[1:].islower() if len(patronymic) > 1 else False
    patronymic_lower = patronymic.lower()

    if "patronymic" not in masking_dict["mappings"]: masking_dict["mappings"]["patronymic"] = {}
    if patronymic_lower in masking_dict["mappings"]["patronymic"]:
        masked = masking_dict["mappings"]["patronymic"][patronymic_lower]["masked_as"]
        masked_with_case = _apply_original_case(patronymic, masked)
        instance_num = get_next_instance(masked, instance_counters)
        masking_dict["mappings"]["patronymic"][patronymic_lower]["instances"].append(instance_num)
        return masked_with_case

    # –ì–µ–Ω–µ—Ä—É—î–º–æ –Ω–æ–≤–µ –ø–æ –±–∞—Ç—å–∫–æ–≤—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ–≥–æ —Ä–æ–¥—É
    seed = get_deterministic_seed(patronymic_lower)
    random.seed(seed)
    fake_uk.seed_instance(seed)
    fake_patronymic = fake_uk.middle_name_male() if gender == 'male' else fake_uk.middle_name_female()

    # –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ —Ä–µ–≥—ñ—Å—Ç—Ä
    if is_upper: fake_patronymic = fake_patronymic.upper()
    elif is_capitalize: fake_patronymic = fake_patronymic.capitalize()
    else: fake_patronymic = fake_patronymic.lower()

    return add_to_mapping(masking_dict, instance_counters, "patronymic", patronymic_lower, fake_patronymic)

def mask_name(original: str, masking_dict: Dict, instance_counters: Dict, gender_hint: str = None, patronymic_hint: str = None) -> str:
    """
    –ú–∞—Å–∫—É—î —ñ–º'—è –∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–º –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è–º —Ä–æ–¥—É —Ç–∞ –≤—ñ–¥–º—ñ–Ω–∫–∞.

    –ê–õ–ì–û–†–ò–¢–ú:
    1. –í–∏–∑–Ω–∞—á–∞—î —Ä—ñ–¥ –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É (—á–µ—Ä–µ–∑ patronymic_hint –∞–±–æ –∞–Ω–∞–ª—ñ–∑ –∑–∞–∫—ñ–Ω—á–µ–Ω–Ω—è)
    2. –í–∏–∑–Ω–∞—á–∞—î –≥—Ä–∞–º–∞—Ç–∏—á–Ω–∏–π –≤—ñ–¥–º—ñ–Ω–æ–∫ —ñ–º–µ–Ω—ñ
    3. –ì–µ–Ω–µ—Ä—É—î –Ω–æ–≤–µ —ñ–º'—è —Ç–æ–≥–æ –∂ —Ä–æ–¥—É –∑ —Ç—ñ—î—é –∂ –ø–µ—Ä—à–æ—é –ª—ñ—Ç–µ—Ä–æ—é
    4. –ó–∞—Å—Ç–æ—Å–æ–≤—É—î –≤—ñ–¥–º—ñ–Ω–æ–∫ –¥–æ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ–≥–æ —ñ–º–µ–Ω—ñ
    5. –ó–±–µ—Ä—ñ–≥–∞—î –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π —Ä–µ–≥—ñ—Å—Ç—Ä

    –í–ò–ó–ù–ê–ß–ï–ù–ù–Ø –†–û–î–£:
    - –ß–µ—Ä–µ–∑ gender_hint (—è–∫—â–æ –Ω–∞–¥–∞–Ω–æ)
    - –ß–µ—Ä–µ–∑ –ø–æ –±–∞—Ç—å–∫–æ–≤—ñ (patronymic_hint): "–ü–µ—Ç—Ä–æ–≤–∏—á—É" ‚Üí —á–æ–ª–æ–≤—ñ–∫, "–ü–µ—Ç—Ä—ñ–≤–Ω—ñ" ‚Üí –∂—ñ–Ω–∫–∞
    - –ß–µ—Ä–µ–∑ –∑–∞–∫—ñ–Ω—á–µ–Ω–Ω—è —ñ–º–µ–Ω—ñ: "–û–ª–µ–∫—Å–∞–Ω–¥—Ä" ‚Üí —á–æ–ª–æ–≤—ñ–∫, "–û–ª—å–≥–∞" ‚Üí –∂—ñ–Ω–∫–∞

    –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø –§–û–†–ú–ê–¢–£:
    - –ü–µ—Ä—à–∞ –ª—ñ—Ç–µ—Ä–∞ —ñ–º–µ–Ω—ñ –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è
    - –í—ñ–¥–º—ñ–Ω–æ–∫ –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è (–Ω–∞–∑–∏–≤–Ω–∏–π, —Ä–æ–¥–æ–≤–∏–π, –¥–∞–≤–∞–ª—å–Ω–∏–π, –æ—Ä—É–¥–Ω–∏–π)
    - –†–µ–≥—ñ—Å—Ç—Ä –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è (UPPER, Title, lower)

    Args:
        original: –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–µ —ñ–º'—è
        masking_dict: –°–ª–æ–≤–Ω–∏–∫ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤
        instance_counters: –õ—ñ—á–∏–ª—å–Ω–∏–∫–∏ –µ–∫–∑–µ–º–ø–ª—è—Ä—ñ–≤
        gender_hint: –ü—ñ–¥–∫–∞–∑–∫–∞ —Ä–æ–¥—É ('male' –∞–±–æ 'female'), –æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ
        patronymic_hint: –ü—ñ–¥–∫–∞–∑–∫–∞ –ø–æ –±–∞—Ç—å–∫–æ–≤—ñ –¥–ª—è –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ä–æ–¥—É, –æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ

    Returns:
        –ó–∞–º–∞—Å–∫–æ–≤–∞–Ω–µ —ñ–º'—è –∑ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–º —Ä–æ–¥–æ–º, –≤—ñ–¥–º—ñ–Ω–∫–æ–º —Ç–∞ —Ä–µ–≥—ñ—Å—Ç—Ä–æ–º

    Note:
        Bug Fix #17: –¢–µ–ø–µ—Ä –∫–æ—Ä–µ–∫—Ç–Ω–æ –∑–∞—Å—Ç–æ—Å–æ–≤—É—î —Ä–µ–≥—ñ—Å—Ç—Ä –¥–ª—è —ñ—Å–Ω—É—é—á–∏—Ö mapping –∑–∞–ø–∏—Å—ñ–≤
    """
    # –ë–ê–ì #17 FIX: –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π —Ä–µ–≥—ñ—Å—Ç—Ä –ø–µ—Ä–µ–¥ –æ–±—Ä–æ–±–∫–æ—é
    is_upper = original.isupper()
    is_capitalize = original[0].isupper() and (len(original) == 1 or original[1:].islower())
    is_lower = original.islower()

    if original in masking_dict["mappings"]["name"]:
        # –Ü–º'—è –≤–∂–µ –º–∞—Å–∫—É–≤–∞–ª–æ—Å—å —Ä–∞–Ω—ñ—à–µ - –±–µ—Ä–µ–º–æ —ñ—Å–Ω—É—é—á—É –º–∞—Å–∫—É
        masked = masking_dict["mappings"]["name"][original]["masked_as"]
    else:
        # –ü–µ—Ä—à–µ –º–∞—Å–∫—É–≤–∞–Ω–Ω—è - –≥–µ–Ω–µ—Ä—É—î–º–æ –Ω–æ–≤—É –º–∞—Å–∫—É
        if not original: return original

        # –í–∏–∑–Ω–∞—á–∞—î–º–æ –≤—ñ–¥–º—ñ–Ω–æ–∫ —Ç–∞ —Ä—ñ–¥
        case, gender_from_name = detect_name_case_and_gender(original)

        # –ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ä–æ–¥—É: gender_hint ‚Üí patronymic_hint ‚Üí gender_from_name
        if gender_hint: gender = gender_hint
        elif patronymic_hint:
            gender = detect_gender_by_patronymic(patronymic_hint)
            if gender == 'unknown': gender = gender_from_name
        else: gender = gender_from_name
        if gender == 'unknown': gender = 'male'

        # –ì–µ–Ω–µ—Ä—É—î–º–æ –Ω–æ–≤–µ —ñ–º'—è –∑ —Ç—ñ—î—é –∂ –ø–µ—Ä—à–æ—é –ª—ñ—Ç–µ—Ä–æ—é
        first_letter = original[0].lower()
        seed = get_deterministic_seed(original)
        new_name = generate_easy_name(gender, first_letter, seed, max_attempts=50)
        masked = apply_case_to_name(new_name, case, gender)

        # –£–Ω–∏–∫–∞—î–º–æ –≤–∏–ø–∞–¥–∫—ñ–≤ –∫–æ–ª–∏ —ñ–º'—è –º–∞–ø–∏—Ç—å—Å—è —Å–∞–º–µ –Ω–∞ —Å–µ–±–µ
        attempts = 0
        while masked.lower() == original.lower() and attempts < 10:
            seed = get_deterministic_seed(original + str(attempts))
            new_name = generate_easy_name(gender, first_letter, seed, max_attempts=50)
            masked = apply_case_to_name(new_name, case, gender)
            attempts += 1

    # –ë–ê–ì #17 FIX: –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ —Ä–µ–≥—ñ—Å—Ç—Ä –¥–æ masked –ü–ï–†–ï–î add_to_mapping
    # –¶–µ –≥–∞—Ä–∞–Ω—Ç—É—î –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π —Ä–µ–≥—ñ—Å—Ç—Ä –Ω–∞–≤—ñ—Ç—å –¥–ª—è —ñ—Å–Ω—É—é—á–∏—Ö –∑–∞–ø–∏—Å—ñ–≤
    if is_upper:
        masked = masked.upper()
    elif is_capitalize:
        masked = masked.capitalize()
    elif is_lower:
        masked = masked.lower()

    return add_to_mapping(masking_dict, instance_counters, "name", original, masked)

# ============================================================================
# –§–£–ù–ö–¶–Ü–á –ú–ê–°–ö–£–í–ê–ù–ù–Ø (–í–Ü–ô–°–¨–ö–û–í–Ü –î–ê–ù–Ü)
# ============================================================================
# –§—É–Ω–∫—Ü—ñ—ó –¥–ª—è –º–∞—Å–∫—É–≤–∞–Ω–Ω—è –∑–≤–∞–Ω—å, –≤—ñ–π—Å—å–∫–æ–≤–∏—Ö —á–∞—Å—Ç–∏–Ω, –Ω–æ–º–µ—Ä—ñ–≤ –Ω–∞–∫–∞–∑—ñ–≤ —Ç–∞ –ë–†

def mask_military_unit(original: str, masking_dict: Dict, instance_counters: Dict) -> str:
    """
    –ú–∞—Å–∫—É—î –≤—ñ–π—Å—å–∫–æ–≤—É —á–∞—Å—Ç–∏–Ω—É.

    –§–æ—Ä–º–∞—Ç: A#### (–æ–¥–Ω–∞ –≤–µ–ª–∏–∫–∞ –ª—ñ—Ç–µ—Ä–∞ + 4 —Ü–∏—Ñ—Ä–∏)
    –õ–æ–≥—ñ–∫–∞: –ó–±–µ—Ä—ñ–≥–∞—î –ª—ñ—Ç–µ—Ä—É, –∑–º—ñ–Ω—é—î –≤—Å—ñ 4 —Ü–∏—Ñ—Ä–∏

    –ü—Ä–∏–∫–ª–∞–¥–∏:
    - "–ê1234" ‚Üí "–ê5678"
    - "–í9876" ‚Üí "–í2345"

    Args:
        original: –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∞ –≤—ñ–π—Å—å–∫–æ–≤–∞ —á–∞—Å—Ç–∏–Ω–∞ (—Ñ–æ—Ä–º–∞—Ç: A####)
        masking_dict: –°–ª–æ–≤–Ω–∏–∫ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤
        instance_counters: –õ—ñ—á–∏–ª—å–Ω–∏–∫–∏ –µ–∫–∑–µ–º–ø–ª—è—Ä—ñ–≤

    Returns:
        –ó–∞–º–∞—Å–∫–æ–≤–∞–Ω–∞ –≤—ñ–π—Å—å–∫–æ–≤–∞ —á–∞—Å—Ç–∏–Ω–∞ —É —Ç–æ–º—É –∂ —Ñ–æ—Ä–º–∞—Ç—ñ
    """
    if original in masking_dict["mappings"]["military_unit"]:
        masked = masking_dict["mappings"]["military_unit"][original]["masked_as"]
    else:
        match = re.match(r'^([–ê-–ØA-Z])(\d{4})$', original)
        if not match: return original
        letter = match.group(1)
        seed = get_deterministic_seed(original)
        random.seed(seed)
        digits = ''.join([str(random.randint(0, 9)) for _ in range(4)])
        masked = letter + digits
    return add_to_mapping(masking_dict, instance_counters, "military_unit", original, masked)

def mask_order_number(original: str, masking_dict: Dict, instance_counters: Dict) -> str:
    """
    –ú–∞—Å–∫—É—î –Ω–æ–º–µ—Ä –Ω–∞–∫–∞–∑—É.

    –§–æ—Ä–º–∞—Ç–∏:
    - ‚Ññ #### (–∑ –ø—Ä–æ–±—ñ–ª–æ–º)
    - ‚Ññ#### (–±–µ–∑ –ø—Ä–æ–±—ñ–ª—É)
    - ####/#### (–∑ —Å–ª–µ—à–∞–º–∏)

    –õ–æ–≥—ñ–∫–∞: –ó–∞–º—ñ–Ω—é—î –≤—Å—ñ —Ü–∏—Ñ—Ä–∏, –∑–±–µ—Ä—ñ–≥–∞—î —Ñ–æ—Ä–º–∞—Ç (‚Ññ, –ø—Ä–æ–±—ñ–ª–∏, —Å–ª–µ—à—ñ)

    –ü—Ä–∏–∫–ª–∞–¥–∏:
    - "‚Ññ 123" ‚Üí "‚Ññ 456"
    - "‚Ññ456/2024" ‚Üí "‚Ññ789/2025"

    Args:
        original: –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π –Ω–æ–º–µ—Ä –Ω–∞–∫–∞–∑—É
        masking_dict: –°–ª–æ–≤–Ω–∏–∫ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤
        instance_counters: –õ—ñ—á–∏–ª—å–Ω–∏–∫–∏ –µ–∫–∑–µ–º–ø–ª—è—Ä—ñ–≤

    Returns:
        –ó–∞–º–∞—Å–∫–æ–≤–∞–Ω–∏–π –Ω–æ–º–µ—Ä –Ω–∞–∫–∞–∑—É —É —Ç–æ–º—É –∂ —Ñ–æ—Ä–º–∞—Ç—ñ
    """
    if original in masking_dict["mappings"]["order_number"]:
        masked = masking_dict["mappings"]["order_number"][original]["masked_as"]
    else:
        seed = get_deterministic_seed(original)
        random.seed(seed)
        masked = re.sub(r'\d', lambda _: str(random.randint(0, 9)), original)
    return add_to_mapping(masking_dict, instance_counters, "order_number", original, masked)

def mask_order_number_with_letters(original: str, masking_dict: Dict, instance_counters: Dict) -> str:
    if original in masking_dict["mappings"]["order_number_with_letters"]:
        masked = masking_dict["mappings"]["order_number_with_letters"][original]["masked_as"]
    else:
        seed = get_deterministic_seed(original)
        random.seed(seed)
        masked = re.sub(r'\d', lambda _: str(random.randint(0, 9)), original)
    return add_to_mapping(masking_dict, instance_counters, "order_number_with_letters", original, masked)

def mask_br_number(original: str, masking_dict: Dict, instance_counters: Dict) -> str:
    """
    –ú–∞—Å–∫—É—î –ë–† –Ω–æ–º–µ—Ä.

    –§–æ—Ä–º–∞—Ç–∏:
    - –ë–†-#### –∞–±–æ –ë–† ####
    - ‚Ññ–ë–†-#### –∞–±–æ ‚Ññ–ë–† ####
    - ####–¥—Å–∫, ####–ø, ####–∫ (–∑ —Å—É—Ñ—ñ–∫—Å–∞–º–∏)
    - ‚Ññ####/####–¥—Å–∫ (–∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω—ñ —Ñ–æ—Ä–º–∞—Ç–∏)

    –ó–±–µ—Ä—ñ–≥–∞—î:
    - –ü—Ä–µ—Ñ—ñ–∫—Å (‚Ññ, –ë–†)
    - –°—É—Ñ—ñ–∫—Å (–¥—Å–∫, –ø, –∫)
    - –§–æ—Ä–º–∞—Ç —Å–ª–µ—à—ñ–≤ (/) —è–∫—â–æ –±—É–ª–∏
    - –ü—Ä–æ–±—ñ–ª–∏ —Ç–∞ –¥–µ—Ñ—ñ—Å–∏

    –õ–æ–≥—ñ–∫–∞: –ó–∞–º—ñ–Ω—é—î –≤—Å—ñ —Ü–∏—Ñ—Ä–∏, –∑–±–µ—Ä—ñ–≥–∞—î —Å—Ç—Ä—É–∫—Ç—É—Ä—É

    –ü—Ä–∏–∫–ª–∞–¥–∏:
    - "‚Ññ123–¥—Å–∫" ‚Üí "‚Ññ456–¥—Å–∫"
    - "‚Ññ456/789–ø" ‚Üí "‚Ññ123/456–ø"

    Args:
        original: –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π –ë–† –Ω–æ–º–µ—Ä
        masking_dict: –°–ª–æ–≤–Ω–∏–∫ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤
        instance_counters: –õ—ñ—á–∏–ª—å–Ω–∏–∫–∏ –µ–∫–∑–µ–º–ø–ª—è—Ä—ñ–≤

    Returns:
        –ó–∞–º–∞—Å–∫–æ–≤–∞–Ω–∏–π –ë–† –Ω–æ–º–µ—Ä —É —Ç–æ–º—É –∂ —Ñ–æ—Ä–º–∞—Ç—ñ

    Note:
        Bug Fix #7, #8: –ö–æ—Ä–µ–∫—Ç–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –ø—Ä–µ—Ñ—ñ–∫—Å—ñ–≤ —Ç–∞ —Å—É—Ñ—ñ–∫—Å—ñ–≤
    """
    if original in masking_dict["mappings"]["br_number"]:
        masked = masking_dict["mappings"]["br_number"][original]["masked_as"]
    else:
        seed = get_deterministic_seed(original)
        random.seed(seed)

        # –í–∏—Ç—è–≥—É—î–º–æ —Å—É—Ñ—ñ–∫—Å (–¥—Å–∫, –ø, –∫)
        suffix_match = re.search(r'(–¥—Å–∫|–ø|–∫)$', original)
        suffix = suffix_match.group(1) if suffix_match else ""

        # –í–∏—Ç—è–≥—É—î–º–æ –ø—Ä–µ—Ñ—ñ–∫—Å (‚Ññ)
        prefix = ""
        number_part = original
        if original.startswith("‚Ññ"):
            match = re.match(r'(‚Ññ\s*)', original)
            if match:
                prefix = match.group(1)
                number_part = original[len(prefix):]
        if suffix: number_part = number_part[:-len(suffix)]

        # –û–±—Ä–æ–±–ª—è—î–º–æ —á–∞—Å—Ç–∏–Ω–∏ —Ä–æ–∑–¥—ñ–ª–µ–Ω—ñ —Å–ª–µ—à–∞–º–∏
        parts = re.split(r'(/)', number_part)
        masked_parts = []
        for part in parts:
            if part == '/': masked_parts.append(part)
            elif part and re.match(r'^\d', part):
                digit_match = re.match(r'(\d+)(.*)', part)
                if digit_match:
                    digits = digit_match.group(1)
                    rest = digit_match.group(2)
                    masked_digits = ''.join([str(random.randint(0, 9)) for _ in range(len(digits))])
                    masked_parts.append(masked_digits + rest)
                else: masked_parts.append(part)
            else: masked_parts.append(part)
        masked = prefix + ''.join(masked_parts) + suffix
    return add_to_mapping(masking_dict, instance_counters, "br_number", original, masked)

def mask_br_number_slash(original: str, masking_dict: Dict, instance_counters: Dict) -> str:
    if original in masking_dict["mappings"]["br_number_slash"]:
        masked = masking_dict["mappings"]["br_number_slash"][original]["masked_as"]
    else:
        seed = get_deterministic_seed(original)
        random.seed(seed)
        suffix_match = re.search(r'(–¥—Å–∫|–ø|–∫)$', original)
        suffix = suffix_match.group(1) if suffix_match else ""
        prefix = ""
        number_part = original
        if original.startswith("‚Ññ"):
            match = re.match(r'(‚Ññ\s*)', original)
            if match:
                prefix = match.group(1)
                number_part = original[len(prefix):]
        if suffix: number_part = number_part[:-len(suffix)]

        parts = number_part.split('/')
        masked_parts = []
        for part in parts:
            if part.strip().isdigit():
                masked_parts.append(''.join([str(random.randint(0, 9)) for _ in range(len(part.strip()))]))
            else:
                masked_parts.append(part)
        masked = prefix + '/'.join(masked_parts) + suffix
    return add_to_mapping(masking_dict, instance_counters, "br_number_slash", original, masked)

def mask_br_number_complex(original: str, masking_dict: Dict, instance_counters: Dict) -> str:
    if original in masking_dict["mappings"]["br_number_complex"]:
        masked = masking_dict["mappings"]["br_number_complex"][original]["masked_as"]
    else:
        seed = get_deterministic_seed(original)
        random.seed(seed)
        masked = re.sub(r'\d', lambda _: str(random.randint(0, 9)), original)
    return add_to_mapping(masking_dict, instance_counters, "br_number_complex", original, masked)

def mask_brigade_number(original: str, masking_dict: Dict, instance_counters: Dict) -> str:
    if original in masking_dict["mappings"]["brigade_number"]:
        masked = masking_dict["mappings"]["brigade_number"][original]["masked_as"]
    else:
        match = re.match(r'(\d+)\s+(.+)', original)
        if not match: return original
        brigade_name = match.group(2)
        seed = get_deterministic_seed(original)
        random.seed(seed)
        masked = f"{random.randint(1, 160)} {brigade_name}"
    return add_to_mapping(masking_dict, instance_counters, "brigade_number", original, masked)

def is_valid_date(day: int, month: int, year: int) -> bool:
    if year < 2015 or year > 2035: return False
    try:
        datetime(year, month, day)
        return True
    except ValueError: return False

def mask_date(original: str, masking_dict: Dict, instance_counters: Dict) -> str:
    """
    –ú–∞—Å–∫—É—î –¥–∞—Ç—É —É —Ñ–æ—Ä–º–∞—Ç—ñ DD.MM.YYYY.

    –õ–û–ì–Ü–ö–ê –ú–ê–°–ö–£–í–ê–ù–ù–Ø –î–ê–¢:
    - –ó–º—ñ—â—É—î –¥–∞—Ç—É –Ω–∞ –≤–∏–ø–∞–¥–∫–æ–≤—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å –¥–Ω—ñ–≤ (¬±30 –¥–Ω—ñ–≤ –≤—ñ–¥ –æ—Ä–∏–≥—ñ–Ω–∞–ª—É)
    - –û–±–º–µ–∂—É—î —Ä–æ–∫–∏ –¥—ñ–∞–ø–∞–∑–æ–Ω–æ–º 2015-2035 (¬±10 —Ä–æ–∫—ñ–≤ –≤—ñ–¥ –ø–æ—Ç–æ—á–Ω–æ–≥–æ 2025)
    - –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –¥–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω–∏–π seed –¥–ª—è unmask

    –í–ê–õ–Ü–î–ê–¶–Ü–Ø:
    - –ü–µ—Ä–µ–≤—ñ—Ä—è—î —â–æ —Ä—ñ–∫ —É –º–µ–∂–∞—Ö 2015-2035
    - –í–∏—Å–æ–∫–æ—Å–Ω—ñ —Ä–æ–∫–∏ –≤—Ä–∞—Ö–æ–≤—É—é—Ç—å—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ —á–µ—Ä–µ–∑ datetime
    - –ù–µ–∫–æ—Ä–µ–∫—Ç–Ω—ñ –¥–∞—Ç–∏ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, 31.02.2024) –ø–æ–≤–µ—Ä—Ç–∞—é—Ç—å—Å—è –±–µ–∑ –∑–º—ñ–Ω

    –û–ë–†–û–ë–ö–ê –ì–†–ê–ù–ò–ß–ù–ò–• –í–ò–ü–ê–î–ö–Ü–í:
    - –Ø–∫—â–æ –∑–º—ñ—â–µ–Ω–∞ –¥–∞—Ç–∞ < 2015 ‚Üí –≤—Å—Ç–∞–Ω–æ–≤–ª—é—î—Ç—å—Å—è –≤–∏–ø–∞–¥–∫–æ–≤–∞ –¥–∞—Ç–∞ –≤ 2015 —Ä–æ—Ü—ñ
    - –Ø–∫—â–æ –∑–º—ñ—â–µ–Ω–∞ –¥–∞—Ç–∞ > 2035 ‚Üí –≤—Å—Ç–∞–Ω–æ–≤–ª—é—î—Ç—å—Å—è –≤–∏–ø–∞–¥–∫–æ–≤–∞ –¥–∞—Ç–∞ –≤ 2035 —Ä–æ—Ü—ñ

    –ü—Ä–∏–∫–ª–∞–¥–∏:
    - "15.03.2024" ‚Üí "10.04.2024" (–∑–º—ñ—â–µ–Ω–Ω—è +26 –¥–Ω—ñ–≤)
    - "01.01.2015" ‚Üí "15.01.2015" (–Ω–µ –≤–∏—Ö–æ–¥–∏—Ç—å –∑–∞ –ª—ñ–≤—É –º–µ–∂—É)

    Args:
        original: –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∞ –¥–∞—Ç–∞ (—Ñ–æ—Ä–º–∞—Ç: DD.MM.YYYY)
        masking_dict: –°–ª–æ–≤–Ω–∏–∫ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤
        instance_counters: –õ—ñ—á–∏–ª—å–Ω–∏–∫–∏ –µ–∫–∑–µ–º–ø–ª—è—Ä—ñ–≤

    Returns:
        –ó–∞–º–∞—Å–∫–æ–≤–∞–Ω–∞ –¥–∞—Ç–∞ —É —Ñ–æ—Ä–º–∞—Ç—ñ DD.MM.YYYY

    Note:
        –î–æ–¥–∞–Ω–æ –≤ v2.1.12 –¥–ª—è –ø–æ–≤–Ω–æ—ó –∞–Ω–æ–Ω—ñ–º—ñ–∑–∞—Ü—ñ—ó –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤
    """
    if original in masking_dict["mappings"]["date"]:
        masked = masking_dict["mappings"]["date"][original]["masked_as"]
    else:
        try:
            match = re.match(r'(\d{2})\.(\d{2})\.(\d{4})', original)
            if not match: return original

            day, month, year = int(match.group(1)), int(match.group(2)), int(match.group(3))
            if not is_valid_date(day, month, year): return original

            # –°—Ç–≤–æ—Ä—é—î–º–æ –æ–±'—î–∫—Ç –¥–∞—Ç–∏ —Ç–∞ –∑–º—ñ—â—É—î–º–æ –Ω–∞ ¬±30 –¥–Ω—ñ–≤
            date_obj = datetime(year, month, day)
            seed = get_deterministic_seed(original)
            random.seed(seed)
            new_date = date_obj + timedelta(days=random.randint(-30, 30))

            # –û–±–º–µ–∂—É—î–º–æ –¥—ñ–∞–ø–∞–∑–æ–Ω —Ä–æ–∫—ñ–≤ 2015-2035
            if new_date.year < 2015:
                new_date = datetime(2015, 1, 1) + timedelta(days=random.randint(0, 365))
            elif new_date.year > 2035:
                new_date = datetime(2035, 12, 31) - timedelta(days=random.randint(0, 365))

            masked = new_date.strftime("%d.%m.%Y")
        except Exception:
            return original

    return add_to_mapping(masking_dict, instance_counters, "date", original, masked)

def get_rank_category_and_match(text: str) -> Tuple[Optional[str], Optional[str]]:
    text_lower = text.lower()
    for category, pattern in RANK_PATTERNS.items():
        match = re.search(pattern, text_lower, re.IGNORECASE)
        if match: return category, match.group(0)
    return None, None

def get_rank_info(rank_form: str) -> Tuple[Optional[str], Optional[str], Optional[str]]:
    rank_lower = rank_form.lower()
    if rank_lower in RANK_TO_NOMINATIVE:
        return RANK_TO_NOMINATIVE[rank_lower]
    return None, None, None

def get_rank_in_case(nominative_rank: str, target_case: str) -> str:
    if nominative_rank not in RANK_DECLENSIONS: return nominative_rank
    return RANK_DECLENSIONS[nominative_rank].get(target_case, nominative_rank)

def mask_rank(original: str, masking_dict: Dict, instance_counters: Dict) -> str:
    """
    –ú–∞—Å–∫—É—î –∑–≤–∞–Ω–Ω—è (–±–∞–∑–æ–≤–∞ –≤–µ—Ä—Å—ñ—è –±–µ–∑ case preservation).

    –û—Å–Ω–æ–≤–Ω–∞ –ª–æ–≥—ñ–∫–∞ –º–∞—Å–∫—É–≤–∞–Ω–Ω—è –∑–≤–∞–Ω—å:
    1. –í–∏–∑–Ω–∞—á–∞—î –∫–∞—Ç–µ–≥–æ—Ä—ñ—é –∑–≤–∞–Ω–Ω—è (army, naval, legal, medical)
    2. –ó–Ω–∞—Ö–æ–¥–∏—Ç—å –ø–æ–∑–∏—Ü—ñ—é —É –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ–π —ñ—î—Ä–∞—Ä—Ö—ñ—ó
    3. –ì–µ–Ω–µ—Ä—É—î –Ω–æ–≤–µ –∑–≤–∞–Ω–Ω—è –∑—ñ –∑—Å—É–≤–æ–º ¬±1-2 –ø–æ–∑–∏—Ü—ñ—ó
    4. –ó–±–µ—Ä—ñ–≥–∞—î –≥—Ä–∞–º–∞—Ç–∏—á–Ω–∏–π –≤—ñ–¥–º—ñ–Ω–æ–∫

    Args:
        original: –ó–≤–∞–Ω–Ω—è –¥–ª—è –º–∞—Å–∫—É–≤–∞–Ω–Ω—è
        masking_dict: –°–ª–æ–≤–Ω–∏–∫ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤
        instance_counters: –õ—ñ—á–∏–ª—å–Ω–∏–∫–∏ –µ–∫–∑–µ–º–ø–ª—è—Ä—ñ–≤

    Returns:
        –ó–∞–º–∞—Å–∫–æ–≤–∞–Ω–µ –∑–≤–∞–Ω–Ω—è

    Note:
        –î–ª—è –∫—Ä–∞—â–æ–≥–æ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∫–æ–Ω—Ç–µ–∫—Å—Ç—É —Ä–µ–∫–æ–º–µ–Ω–¥—É—î—Ç—å—Å—è –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏
        mask_rank_preserve_case() –∑–∞–º—ñ—Å—Ç—å —Ü—ñ—î—ó —Ñ—É–Ω–∫—Ü—ñ—ó
    """
    original_key = original.lower()
    detected_base, detected_case, detected_gender = get_rank_info(original_key)

    # Instance tracking: –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —Ü–µ –∑–≤–∞–Ω–Ω—è –≤–∂–µ –Ω–µ —î –º–∞—Å–∫–æ—é —ñ–Ω—à–æ–≥–æ
    if original_key in masking_dict["mappings"]["rank"]:
        is_someone_else_mask = False
        for other_original, other_data in masking_dict["mappings"]["rank"].items():
            if isinstance(other_data, dict) and "masked_as" in other_data:
                if other_data["masked_as"].lower() == original_key and other_original != original_key:
                    is_someone_else_mask = True
                    break
        if not is_someone_else_mask:
            masked = masking_dict["mappings"]["rank"][original_key]["masked_as"]
            final_masked = add_to_mapping(masking_dict, instance_counters, "rank", original_key, masked)
            if PRESERVE_CASE: return _apply_original_case(original, final_masked)
            return final_masked

    # –í–∏–∑–Ω–∞—á–∞—î–º–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ—é —Ç–∞ —ñ—î—Ä–∞—Ä—Ö—ñ—é –∑–≤–∞–Ω—å
    category_name, matched = get_rank_category_and_match(original_key)
    if not matched: return original

    if category_name == "army": hierarchy = ARMY_RANKS
    elif category_name == "naval": hierarchy = NAVAL_RANKS
    elif category_name == "legal": hierarchy = LEGAL_RANKS
    elif category_name == "medical": hierarchy = MEDICAL_RANKS
    else: return original

    try: idx = [r.lower() for r in hierarchy].index(matched.lower())
    except ValueError: return original

    # –ì–µ–Ω–µ—Ä—É—î–º–æ –Ω–æ–≤–µ –∑–≤–∞–Ω–Ω—è –∑—ñ –∑—Å—É–≤–æ–º –ø–æ–∑–∏—Ü—ñ—ó
    seed = get_deterministic_seed(original_key)
    random.seed(seed)
    shift = random.choice([-2, -1, 1, 2])
    new_idx = max(0, min(len(hierarchy) - 1, idx + shift))
    masked = hierarchy[new_idx]

    # –£–Ω–∏–∫–∞—î–º–æ –≤–∏–ø–∞–¥–∫—ñ–≤ –∫–æ–ª–∏ –∑–≤–∞–Ω–Ω—è –º–∞–ø–∏—Ç—å—Å—è —Å–∞–º–µ –Ω–∞ —Å–µ–±–µ
    attempts = 0
    while masked.lower() == original_key and attempts < 10:
        shift = random.choice([-2, -1, 1, 2])
        new_idx = max(0, min(len(hierarchy) - 1, idx + shift))
        masked = hierarchy[new_idx]
        attempts += 1

    # –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ –≥—Ä–∞–º–∞—Ç–∏—á–Ω–∏–π –≤—ñ–¥–º—ñ–Ω–æ–∫ —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ
    if detected_case and detected_case != "nominative":
        masked = get_rank_in_case(masked, detected_case)

    final_masked = add_to_mapping(masking_dict, instance_counters, "rank", original_key, masked)
    # –ë–ê–ì #16 & #18 FIX: –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ —Ä–µ–≥—ñ—Å—Ç—Ä –ü–Ü–°–õ–Ø add_to_mapping
    if PRESERVE_CASE:
        # –°–ø–µ—Ü—ñ–∞–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –¥–ª—è —Å–∫–ª–∞–¥–µ–Ω–∏—Ö –∑–≤–∞–Ω—å (–∑ –¥–µ—Ñ—ñ—Å–æ–º –∞–±–æ –ø—Ä–æ–±—ñ–ª–æ–º)
        if '-' in original and original.istitle():
            # "–®—Ç–∞–±-–°–µ—Ä–∂–∞–Ω—Ç" ‚Üí "–ú–∞–π–æ—Ä" ‚Üí "–ú–∞–π–æ—Ä".title() = "–ú–∞–π–æ—Ä"
            return final_masked.title()

        # –ë–ê–ì #18 FIX: –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –¥–ª—è –±–∞–≥–∞—Ç–æ—Å–ª—ñ–≤–Ω–∏—Ö –∑–≤–∞–Ω—å —É Title Case
        # "–°—Ç–∞—Ä—à–∏–π –õ–µ–π—Ç–µ–Ω–∞–Ω—Ç" –º–∞—î –∫–æ–∂–Ω–µ —Å–ª–æ–≤–æ –∑ –≤–µ–ª–∏–∫–æ—ó ‚Üí –∑–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ .title()
        words = original.split()
        if len(words) > 1:
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –∫–æ–∂–Ω–µ —Å–ª–æ–≤–æ –ø–æ—á–∏–Ω–∞—î—Ç—å—Å—è –∑ –≤–µ–ª–∏–∫–æ—ó –ª—ñ—Ç–µ—Ä–∏
            all_title = all(word and word[0].isupper() for word in words if word)
            if all_title:
                return final_masked.title()

        # –Ü–Ω–∞–∫—à–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É –ª–æ–≥—ñ–∫—É –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–≥—ñ—Å—Ç—Ä—É
        return _apply_original_case(original, final_masked)
    return final_masked

def mask_rank_preserve_case(original_text: str, masking_dict: Dict, instance_counters: Dict) -> str:
    """
    –ú–∞—Å–∫—É—î –∑–≤–∞–Ω–Ω—è –∑—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è–º —Ä–µ–≥—ñ—Å—Ç—Ä—É —Ç–∞ –≥—Ä–∞–º–∞—Ç–∏—á–Ω–æ–≥–æ –≤—ñ–¥–º—ñ–Ω–∫–∞ (Bug Fix #16-18).

    –û–°–û–ë–õ–ò–í–û–°–¢–Ü:
    - –ó–±–µ—Ä—ñ–≥–∞—î —Ä–µ–≥—ñ—Å—Ç—Ä –ª—ñ—Ç–µ—Ä (UPPER, Title Case, lower case)
    - –ó–±–µ—Ä—ñ–≥–∞—î –≥—Ä–∞–º–∞—Ç–∏—á–Ω–∏–π –≤—ñ–¥–º—ñ–Ω–æ–∫ (–Ω–∞–∑–∏–≤–Ω–∏–π, —Ä–æ–¥–æ–≤–∏–π, –¥–∞–≤–∞–ª—å–Ω–∏–π, –æ—Ä—É–¥–Ω–∏–π)
    - –í—Ä–∞—Ö–æ–≤—É—î —Ä—ñ–¥ –∑–≤–∞–Ω–Ω—è (—á–æ–ª–æ–≤—ñ—á–∏–π/–∂—ñ–Ω–æ—á–∏–π)
    - –ü—ñ–¥—Ç—Ä–∏–º—É—î —Å–∫–ª–∞–¥–Ω—ñ –∑–≤–∞–Ω–Ω—è: "–∫–∞–ø—ñ—Ç–∞–Ω –º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏ —É –≤—ñ–¥—Å—Ç–∞–≤—Ü—ñ"

    –í–ò–ü–†–ê–í–õ–ï–ù–Ü –ë–ê–ì–ò:

    Bug #16: –ù–µ–∫–æ—Ä–µ–∫—Ç–Ω–µ –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è .title() –Ω–∞ –≤–∂–µ Title Case —Å–ª–æ–≤–∞—Ö
    - –ë—É–ª–æ: "–°—Ç–∞—Ä—à–∏–π –°–µ—Ä–∂–∞–Ω—Ç" ‚Üí ".title()" ‚Üí "–°—Ç–∞—Ä—à–∏–π –°–µ—Ä–∂–∞–Ω—Ç" (OK)
    - –ë—É–ª–æ: "—Å—Ç–∞—Ä—à–∏–π —Å–µ—Ä–∂–∞–Ω—Ç" ‚Üí ".title()" ‚Üí "–°—Ç–∞—Ä—à–∏–π –°–µ—Ä–∂–∞–Ω—Ç" (OK)
    - –ë—É–ª–æ: "–°–¢–ê–†–®–ò–ô –°–ï–†–ñ–ê–ù–¢" ‚Üí ".title()" ‚Üí "–°—Ç–∞—Ä—à–∏–π –°–µ—Ä–∂–∞–Ω—Ç" (–ü–û–ú–ò–õ–ö–ê!)
    - –í–∏–ø—Ä–∞–≤–ª–µ–Ω–æ: –∑–±–µ—Ä—ñ–≥–∞—î–º–æ UPPER —è–∫—â–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª –±—É–≤ UPPER

    Bug #17: –í—Ç—Ä–∞—Ç–∞ case –¥–ª—è existing mappings
    - –ë—É–ª–æ: —è–∫—â–æ –∑–≤–∞–Ω–Ω—è –≤–∂–µ —î –≤ mapping, —Ä–µ–≥—ñ—Å—Ç—Ä –Ω–µ –∑–±–µ—Ä—ñ–≥–∞–≤—Å—è
    - –í–∏–ø—Ä–∞–≤–ª–µ–Ω–æ: –∑–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ _apply_original_case() –¥–ª—è –≤—Å—ñ—Ö –≤–∏–ø–∞–¥–∫—ñ–≤

    Bug #18: –ù–µ–∫–æ—Ä–µ–∫—Ç–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –±–∞–≥–∞—Ç–æ—Å–ª—ñ–≤–Ω–∏—Ö –∑–≤–∞–Ω—å —É Title Case
    - –ë—É–ª–æ: "–°—Ç–∞—Ä—à–∏–π –õ–µ–π—Ç–µ–Ω–∞–Ω—Ç" ‚Üí "—Å—Ç–∞—Ä—à–∏–π –∫–∞–ø—ñ—Ç–∞–Ω" ‚Üí "–°—Ç–∞—Ä—à–∏–π –ö–∞–ø—ñ—Ç–∞–Ω" (OK —Ç—ñ–ª—å–∫–∏ –ø–µ—Ä—à–µ —Å–ª–æ–≤–æ)
    - –í–∏–ø—Ä–∞–≤–ª–µ–Ω–æ: –ø—Ä–∞–≤–∏–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –∫–æ–∂–Ω–æ–≥–æ —Å–ª–æ–≤–∞ –æ–∫—Ä–µ–º–æ

    –ê–õ–ì–û–†–ò–¢–ú:
    1. –í–∏—Ç—è–≥—É—î –±–∞–∑–æ–≤–µ –∑–≤–∞–Ω–Ω—è —Ç–∞ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ —Å–ª–æ–≤–∞ ("—É –≤—ñ–¥—Å—Ç–∞–≤—Ü—ñ", "–º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏")
    2. –í–∏–∑–Ω–∞—á–∞—î –≥—Ä–∞–º–∞—Ç–∏—á–Ω—É —Ñ–æ—Ä–º—É —á–µ—Ä–µ–∑ RANK_TO_NOMINATIVE
    3. –ì–µ–Ω–µ—Ä—É—î –Ω–æ–≤–µ –∑–≤–∞–Ω–Ω—è –∑ —Ç–∏–º —Å–∞–º–∏–º –≤—ñ–¥–º—ñ–Ω–∫–æ–º —Ç–∞ —Ä–æ–¥–æ–º
    4. –ó–∞—Å—Ç–æ—Å–æ–≤—É—î –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π —Ä–µ–≥—ñ—Å—Ç—Ä
    5. –î–æ–¥–∞—î –Ω–∞–∑–∞–¥ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ —Å–ª–æ–≤–∞

    Args:
        original_text: –¢–µ–∫—Å—Ç –∑–≤–∞–Ω–Ω—è –¥–ª—è –º–∞—Å–∫—É–≤–∞–Ω–Ω—è (–±—É–¥—å-—è–∫–∏–π —Ä–µ–≥—ñ—Å—Ç—Ä, –±—É–¥—å-—è–∫–∏–π –≤—ñ–¥–º—ñ–Ω–æ–∫)
        masking_dict: –°–ª–æ–≤–Ω–∏–∫ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤ –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ—Å—Ç–µ–π
        instance_counters: –õ—ñ—á–∏–ª—å–Ω–∏–∫–∏ –µ–∫–∑–µ–º–ø–ª—è—Ä—ñ–≤ –¥–ª—è instance tracking

    Returns:
        –ó–∞–º–∞—Å–∫–æ–≤–∞–Ω–µ –∑–≤–∞–Ω–Ω—è –∑ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è–º —Ä–µ–≥—ñ—Å—Ç—Ä—É, –≤—ñ–¥–º—ñ–Ω–∫–∞ —Ç–∞ —Ä–æ–¥—É

    Note:
        –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î extract_base_rank() –¥–ª—è —Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –∑–≤–∞–Ω–Ω—è –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏
    """
    base_rank_text, additional_words = extract_base_rank(original_text)
    base_male_form, detected_case, gender = get_rank_info(base_rank_text)

    if not base_male_form:
        masked_result = mask_rank(base_rank_text, masking_dict, instance_counters)
        return f"{masked_result} {additional_words}" if additional_words else masked_result

    masked_base_male = mask_rank(base_male_form, masking_dict, instance_counters)
    final_rank = None

    if gender == 'female':
        if masked_base_male.lower() in RANK_FEMININE_MAP:
            masked_base_female = RANK_FEMININE_MAP[masked_base_male.lower()]
            if masked_base_female in RANK_DECLENSIONS_FEMALE and detected_case:
                final_rank = RANK_DECLENSIONS_FEMALE[masked_base_female].get(detected_case, masked_base_female)
            else: final_rank = masked_base_female
        else:
            if masked_base_male.lower() in RANK_DECLENSIONS and detected_case:
                final_rank = RANK_DECLENSIONS[masked_base_male.lower()].get(detected_case, masked_base_male)
            else: final_rank = masked_base_male
    else:
        if masked_base_male.lower() in RANK_DECLENSIONS and detected_case:
            final_rank = RANK_DECLENSIONS[masked_base_male.lower()].get(detected_case, masked_base_male)
        else: final_rank = masked_base_male

    if PRESERVE_CASE and final_rank:
        final_rank = _apply_original_case(base_rank_text, final_rank)
    result = final_rank if final_rank else masked_base_male
    return f"{result} {additional_words}" if additional_words else result

# ============================================================================
# MAIN LOGIC
# ============================================================================

def normalize_broken_ranks(text: str) -> str:
    """
    –ù–æ—Ä–º–∞–ª—ñ–∑—É—î —Ä–æ–∑—ñ—Ä–≤–∞–Ω—ñ –∑–≤–∞–Ω–Ω—è —É —Ç–µ–∫—Å—Ç—ñ (Bug Fix #15).

    –ü–†–û–ë–õ–ï–ú–ê:
    –ó–≤–∞–Ω–Ω—è –º–æ–∂–µ –±—É—Ç–∏ —Ä–æ–∑—ñ—Ä–≤–∞–Ω–µ –ø–µ—Ä–µ–Ω–æ—Å–æ–º —Ä—è–¥–∫–∞ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö:
    - "—Å—Ç–∞—Ä—à–æ–≥–æ\n—Å–µ—Ä–∂–∞–Ω—Ç–∞" ‚Üí —Ä–æ–∑–ø—ñ–∑–Ω–∞—î—Ç—å—Å—è —è–∫ –¥–≤–∞ –æ–∫—Ä–µ–º—ñ —Å–ª–æ–≤–∞
    - "–∫–∞–ø—ñ—Ç–∞–Ω—É\n–º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏" ‚Üí –≤—Ç—Ä–∞—á–∞—î—Ç—å—Å—è –∑–≤'—è–∑–æ–∫ —Å–ª—ñ–≤

    –†–Ü–®–ï–ù–ù–Ø:
    –§—É–Ω–∫—Ü—ñ—è —Å–∫–ª–µ—é—î —Ä–æ–∑—ñ—Ä–≤–∞–Ω—ñ –∑–≤–∞–Ω–Ω—è –ø–µ—Ä–µ–¥ –æ—Å–Ω–æ–≤–Ω–æ—é –æ–±—Ä–æ–±–∫–æ—é:
    - "—Å—Ç–∞—Ä—à–æ–≥–æ\n—Å–µ—Ä–∂–∞–Ω—Ç–∞" ‚Üí "—Å—Ç–∞—Ä—à–æ–≥–æ —Å–µ—Ä–∂–∞–Ω—Ç–∞"
    - "–∫–∞–ø—ñ—Ç–∞–Ω—É\n–º–µ–¥–∏—á–Ω–æ—ó\n—Å–ª—É–∂–±–∏" ‚Üí "–∫–∞–ø—ñ—Ç–∞–Ω—É –º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏"

    –ê–õ–ì–û–†–ò–¢–ú:
    1. –®—É–∫–∞—î —É —Ç–µ–∫—Å—Ç—ñ –ø–µ—Ä—à–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –∑–≤–∞–Ω–Ω—è (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "—Å—Ç–∞—Ä—à–æ–≥–æ")
    2. –ü–µ—Ä–µ–≤—ñ—Ä—è—î —á–∏ –ø—ñ—Å–ª—è \n –π–¥–µ –¥—Ä—É–≥–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç ("—Å–µ—Ä–∂–∞–Ω—Ç–∞")
    3. –Ø–∫—â–æ —Ç–∞–∫ - –≤–∏–¥–∞–ª—è—î \n –º—ñ–∂ –Ω–∏–º–∏
    4. –ü–æ–≤—Ç–æ—Ä—é—î –¥–ª—è –≤—Å—ñ—Ö –≤—ñ–¥–æ–º–∏—Ö –∑–≤–∞–Ω—å –∑ RANKS_LIST

    Args:
        text: –í—Ö—ñ–¥–Ω–∏–π —Ç–µ–∫—Å—Ç –∑ –º–æ–∂–ª–∏–≤–∏–º–∏ —Ä–æ–∑—ñ—Ä–≤–∞–Ω–∏–º–∏ –∑–≤–∞–Ω–Ω—è–º–∏

    Returns:
        –¢–µ–∫—Å—Ç –∑ –Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–º–∏ (—Å–∫–ª–µ—î–Ω–∏–º–∏) –∑–≤–∞–Ω–Ω—è–º–∏

    Note:
        –í–∏–∫–æ–Ω—É—î—Ç—å—Å—è –ü–ï–†–ï–î –æ—Å–Ω–æ–≤–Ω–∏–º –º–∞—Å–∫—É–≤–∞–Ω–Ω—è–º —É mask_text_context_aware()
    """
    # –ë–µ—Ä–µ–º–æ —Ç—ñ–ª—å–∫–∏ —Å–∫–ª–∞–¥–µ–Ω—ñ –∑–≤–∞–Ω–Ω—è (—Ç—ñ, —â–æ –º—ñ—Å—Ç—è—Ç—å –ø—Ä–æ–±—ñ–ª)
    multi_word_ranks = [r for r in ALL_RANK_FORMS if ' ' in r]

    if not multi_word_ranks:
        return text

    # –°—Ç–≤–æ—Ä—é—î–º–æ –≤–µ–ª–∏–∫–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω, –∑–∞–º—ñ–Ω—é—é—á–∏ –ø—Ä–æ–±—ñ–ª–∏ –Ω–∞ \s+ (–±—É–¥—å-—è–∫–∏–π –ø—Ä–æ–±—ñ–ª—å–Ω–∏–π —Å–∏–º–≤–æ–ª, –≤–∫–ª—é—á–Ω–æ –∑ \n)
    patterns = [re.escape(r).replace(r'\ ', r'\s+') for r in multi_word_ranks]
    full_pattern = r'(?i)\b(' + '|'.join(patterns) + r')\b'

    def replace_match(match):
        # –ó–∞–º—ñ–Ω—é—î–º–æ –≤—Å—ñ –ø—Ä–æ–±—ñ–ª—å–Ω—ñ —Å–∏–º–≤–æ–ª–∏ (–≤–∫–ª—é—á–∞—é—á–∏ \n) –Ω–∞ –æ–¥–∏–Ω –∑–≤–∏—á–∞–π–Ω–∏–π –ø—Ä–æ–±—ñ–ª
        return re.sub(r'\s+', ' ', match.group(0))

    return re.sub(full_pattern, replace_match, text)


def mask_text_context_aware(text: str, masking_dict: Dict, instance_counters: Dict) -> str:
    """
    –ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –º–∞—Å–∫—É–≤–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∏–º –∞–Ω–∞–ª—ñ–∑–æ–º.

    –¶–µ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –≤—Å—å–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—É –º–∞—Å–∫—É–≤–∞–Ω–Ω—è. –í–æ–Ω–∞ –∫–æ–æ—Ä–¥–∏–Ω—É—î —Ä–æ–±–æ—Ç—É
    –≤—Å—ñ—Ö —ñ–Ω—à–∏—Ö —Ñ—É–Ω–∫—Ü—ñ–π —Ç–∞ –∑–∞–±–µ–∑–ø–µ—á—É—î –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π –ø–æ—Ä—è–¥–æ–∫ –æ–±—Ä–æ–±–∫–∏ –¥–∞–Ω–∏—Ö.

    –ê–õ–ì–û–†–ò–¢–ú (–ø–æ–∫—Ä–æ–∫–æ–≤–æ):

    1. –ù–û–†–ú–ê–õ–Ü–ó–ê–¶–Ü–Ø:
       - –í–∏–∫–ª–∏–∫–∞—î normalize_broken_ranks() –¥–ª—è —Å–∫–ª–µ—é–≤–∞–Ω–Ω—è —Ä–æ–∑—ñ—Ä–≤–∞–Ω–∏—Ö –∑–≤–∞–Ω—å

    2. –û–ë–†–û–ë–ö–ê –†–Ø–î–ö–Ü–í:
       - –†–æ–∑–±–∏–≤–∞—î —Ç–µ–∫—Å—Ç –Ω–∞ –æ–∫—Ä–µ–º—ñ —Ä—è–¥–∫–∏
       - –î–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ä—è–¥–∫–∞:
         a) –ü–µ—Ä–µ–≤—ñ—Ä—è—î —á–∏ —Å—Ö–æ–∂–∏–π –Ω–∞ —Ä—è–¥–æ–∫ –∑ –ü–Ü–ë (looks_like_pib_line)
         b) –Ø–∫—â–æ —Ç–∞–∫ - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î parse_hybrid_line() –¥–ª—è —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –∑–≤–∞–Ω–Ω—è+–ü–Ü–ë
         c) –Ü—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ –º–∞—Å–∫—É—î –∑–≤–∞–Ω–Ω—è —Ç–∞ –ü–Ü–ë (–¥–æ 10 —ñ—Ç–µ—Ä–∞—Ü—ñ–π –Ω–∞ —Ä—è–¥–æ–∫)

    3. –Ü–¢–ï–†–ê–¢–ò–í–ù–ï –ú–ê–°–ö–£–í–ê–ù–ù–Ø (–¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ä—è–¥–∫–∞):
       –¶–∏–∫–ª –¥–æ 10 —Ä–∞–∑—ñ–≤:
       - –®—É–∫–∞—î –∑–≤–∞–Ω–Ω—è —á–µ—Ä–µ–∑ ALL_RANK_FORMS
       - –®—É–∫–∞—î –ü–Ü–ë —á–µ—Ä–µ–∑ parse_hybrid_line()
       - –Ø–∫—â–æ –Ω—ñ—á–æ–≥–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ - break
       - –Ø–∫—â–æ –∑–Ω–∞–π–¥–µ–Ω–æ —Ç—ñ–ª—å–∫–∏ –∑–≤–∞–Ω–Ω—è –±–µ–∑ –ü–Ü–ë - –ø—Ä–æ–ø—É—Å–∫–∞—î —Ç–∞ —à—É–∫–∞—î –¥–∞–ª—ñ
       - –Ø–∫—â–æ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–≤–∞–Ω–Ω—è + –ü–Ü–ë:
         * –ú–∞—Å–∫—É—î –∑–≤–∞–Ω–Ω—è —á–µ—Ä–µ–∑ mask_rank_preserve_case()
         * –ú–∞—Å–∫—É—î –ü–Ü–ë —á–µ—Ä–µ–∑ mask_surname(), mask_name(), mask_patronymic()
         * –ó–∞–º—ñ–Ω—é—î –≤ —Ä—è–¥–∫—É
       - –ü—Ä–æ–¥–æ–≤–∂—É—î –¥–æ –≤–∏—á–µ—Ä–ø–∞–Ω–Ω—è –∑–≤–∞–Ω—å/–ü–Ü–ë

    4. –ú–ê–°–ö–£–í–ê–ù–ù–Ø –Ü–ù–®–ò–• –î–ê–ù–ò–•:
       - –Ü–ü–ù (10 —Ü–∏—Ñ—Ä)
       - –ü–∞—Å–ø–æ—Ä—Ç–∏ (9 —Ü–∏—Ñ—Ä)
       - –í—ñ–π—Å—å–∫–æ–≤—ñ ID
       - –í—ñ–π—Å—å–∫–æ–≤—ñ —á–∞—Å—Ç–∏–Ω–∏
       - –ù–æ–º–µ—Ä–∏ –Ω–∞–∫–∞–∑—ñ–≤ —Ç–∞ –ë–†
       - –î–∞—Ç–∏

    5. –û–ë'–Ñ–î–ù–ê–ù–ù–Ø:
       - –ó'—î–¥–Ω—É—î –≤—Å—ñ –æ–±—Ä–æ–±–ª–µ–Ω—ñ —Ä—è–¥–∫–∏ –Ω–∞–∑–∞–¥ –≤ —Ç–µ–∫—Å—Ç

    –ß–û–ú–£ –Ü–¢–ï–†–ê–¢–ò–í–ù–ò–ô –ü–Ü–î–•–Ü–î:
    –£ –¥–µ—è–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –Ω–∞ –æ–¥–Ω–æ–º—É —Ä—è–¥–∫—É –º–æ–∂–µ –±—É—Ç–∏ –∫—ñ–ª—å–∫–∞ –∑–≤–∞–Ω—å —Ç–∞ –ü–Ü–ë:
    "–∫–∞–ø—ñ—Ç–∞–Ω –ü–µ—Ç—Ä–µ–Ω–∫–æ —Ç–∞ –º–∞–π–æ—Ä –°–∏–¥–æ—Ä–µ–Ω–∫–æ"
    –Ü—Ç–µ—Ä–∞—Ç–∏–≤–Ω–∏–π –ø—ñ–¥—Ö—ñ–¥ –∑–Ω–∞—Ö–æ–¥–∏—Ç—å —Ç–∞ –º–∞—Å–∫—É—î –∫–æ–∂–Ω—É –ø–∞—Ä—É –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ.

    –ü–û–†–Ø–î–û–ö –ú–ê–°–ö–£–í–ê–ù–ù–Ø (–∫—Ä–∏—Ç–∏—á–Ω–æ –≤–∞–∂–ª–∏–≤–∏–π):
    1. –°–ø–æ—á–∞—Ç–∫—É –∑–≤–∞–Ω–Ω—è + –ü–Ü–ë (–Ω–∞–π—Å–∫–ª–∞–¥–Ω—ñ—à–µ, –ø–æ—Ç—Ä–µ–±—É—î –∫–æ–Ω—Ç–µ–∫—Å—Ç—É)
    2. –ü–æ—Ç—ñ–º –æ–∫—Ä–µ–º—ñ —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä–∏ (–Ü–ü–ù, –ø–∞—Å–ø–æ—Ä—Ç–∏, –≤—ñ–π—Å—å–∫–æ–≤—ñ ID)
    3. –ù–∞—Ä–µ—à—Ç—ñ —ñ–Ω—à—ñ –¥–∞–Ω—ñ (–Ω–æ–º–µ—Ä–∏, –¥–∞—Ç–∏)

    Args:
        text: –í—Ö—ñ–¥–Ω–∏–π —Ç–µ–∫—Å—Ç –¥–ª—è –º–∞—Å–∫—É–≤–∞–Ω–Ω—è
        masking_dict: –°–ª–æ–≤–Ω–∏–∫ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤ –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ—Å—Ç–µ–π
        instance_counters: –õ—ñ—á–∏–ª—å–Ω–∏–∫–∏ –µ–∫–∑–µ–º–ø–ª—è—Ä—ñ–≤ –¥–ª—è instance tracking

    Returns:
        –ü–æ–≤–Ω—ñ—Å—Ç—é –∑–∞–º–∞—Å–∫–æ–≤–∞–Ω–∏–π —Ç–µ–∫—Å—Ç

    Note:
        - –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –≥–ª–æ–±–∞–ª—å–Ω—ñ —Ñ–ª–∞–≥–∏ MASK_* –¥–ª—è –≤–∏–±—ñ—Ä–∫–æ–≤–æ–≥–æ –º–∞—Å–∫—É–≤–∞–Ω–Ω—è
        - –ó–±–µ—Ä—ñ–≥–∞—î —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è —Ç–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É
        - –ü—ñ–¥—Ç—Ä–∏–º—É—î Unicode (–∫–∏—Ä–∏–ª–∏—Ü—é)
    """
    # === –®–ê–ì 0: –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–æ–∑—ñ—Ä–≤–∞–Ω–∏—Ö –∑–≤–∞–Ω—å (–©–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –¥—É–±–ª—é–≤–∞–Ω–Ω—è "—Å—Ç–∞—Ä—à–æ–≥–æ —Å—Ç–∞—Ä—à–æ–≥–æ")
    text = normalize_broken_ranks(text)

    items_to_mask = []
    items_to_skip = []

    if not MASK_DATES:
        for match in re.finditer(UKRAINIAN_DATE_PATTERN, text):
            items_to_skip.append({'start': match.start(), 'end': match.end(), 'text': match.group(0), 'reason': 'full_date', 'type': 'date'})

    legal_patterns = [
        r'(—Å—Ç–∞—Ç–µ[–π—ó]|—Å—Ç–∞—Ç—å[—ñ–µ—é—è])\s+(\d+(?:\s*,\s*\d+)*)',
        r'(–ø—É–Ω–∫—Ç[—É–∞–∏—ñ–µ—î])\s+(\d+(?:\s*,\s*\d+)*)',
        r'(—á–∞—Å—Ç–∏–Ω[–∞–∏—é—ñ–µ—î])\s+(\d+(?:\s*,\s*\d+)*)',
        r'(—Ä–æ–∑–¥—ñ–ª[—É–∞—ñ–µ—î])\s+(\d+(?:\s*,\s*\d+)*)',
    ]
    for pattern in legal_patterns:
        for match in re.finditer(pattern, text, re.IGNORECASE):
            term, numbers_text = match.group(1), match.group(2)
            base_pos = match.start(2)
            for num_match in re.finditer(r'\d+', numbers_text):
                items_to_skip.append({'start': base_pos + num_match.start(), 'end': base_pos + num_match.end(), 'text': num_match.group(0), 'reason': 'legal', 'type': 'legal_number', 'context': term})

    if MASK_ORDERS or MASK_BR_NUMBERS:
        for match in re.finditer(r'‚Ññ', text):
            result = analyze_number_sign_context(text, match)
            if result: items_to_mask.append(result)

    if MASK_BR_NUMBERS:
        for match in re.finditer(r'\b–ë–†\b', text, re.IGNORECASE):
            result = analyze_br_keyword(text, match)
            if result:
                skip = any(result['start'] < item['end'] and result['end'] > item['start'] for item in items_to_skip)
                skip = skip or any(result['start'] < item['end'] and result['end'] > item['start'] for item in items_to_mask)
                if not skip: items_to_mask.append(result)

    for item_type, flag, pattern in [
        ('ipn', MASK_IPN, r'\b\d{10}\b'),
        ('passport_id', MASK_PASSPORT, r'\b\d{9}\b'),
        ('military_id', MASK_MILITARY_ID, r'\b[A-Z–ê-–Ø]{2}[\s-]?\d{6}\b'),
        ('military_unit', MASK_UNITS, r'\b[–ê-–ØA-Z]\d{4}\b')
    ]:
        if flag:
            for match in re.finditer(pattern, text, re.IGNORECASE if item_type == 'military_id' else 0):
                skip = any(match.start() >= item['start'] and match.end() <= item['end'] for item in items_to_skip)
                skip = skip or any(match.start() < item['end'] and match.end() > item['start'] for item in items_to_mask)
                if not skip: items_to_mask.append({'type': item_type, 'full_text': match.group(0), 'number_part': match.group(0), 'start': match.start(), 'end': match.end()})

    if MASK_BRIGADES:
        for match in COMPILED_PATTERNS["brigade_number"].finditer(text):
            skip = any(match.start() >= item['start'] and match.end() <= item['end'] for item in items_to_skip)
            skip = skip or any(match.start() < item['end'] and match.end() > item['start'] for item in items_to_mask)
            if not skip: items_to_mask.append({'type': 'brigade_number', 'full_text': match.group(0), 'number_part': match.group(1), 'start': match.start(), 'end': match.end()})

    if MASK_DATES:
        for match in COMPILED_PATTERNS["date"].finditer(text):
            if is_valid_date(int(match.group(1)), int(match.group(2)), int(match.group(3))):
                skip = any(match.start() >= item['start'] and match.end() <= item['end'] for item in items_to_skip)
                skip = skip or any(match.start() < item['end'] and match.end() > item['start'] for item in items_to_mask)
                if not skip: items_to_mask.append({'type': 'date', 'full_text': match.group(0), 'number_part': match.group(0), 'start': match.start(), 'end': match.end()})

    items_to_mask.sort(key=lambda x: x['start'], reverse=True)

    for item in items_to_mask:
        masked = ""
        if text[item['start']:item['end']] != item['full_text']: continue
        if item['type'] == 'ipn': masked = mask_ipn(item['number_part'], masking_dict, instance_counters)
        elif item['type'] == 'passport_id': masked = mask_passport_id(item['number_part'], masking_dict, instance_counters)
        elif item['type'] == 'military_id': masked = mask_military_id(item['number_part'], masking_dict, instance_counters)
        elif item['type'] == 'military_unit': masked = mask_military_unit(item['number_part'], masking_dict, instance_counters)
        elif item['type'] == 'brigade_number':
            masked = mask_brigade_number(item['full_text'], masking_dict, instance_counters)
            text = text[:item['start']] + masked + text[item['end']:]
            continue
        elif item['type'] == 'date':
            masked = mask_date(item['full_text'], masking_dict, instance_counters)
            text = text[:item['start']] + masked + text[item['end']:]
            continue
        elif item['type'] == 'order_simple':
            masked = mask_order_number(item['number_part'], masking_dict, instance_counters)
            new_full = item['full_text'].replace(item['number_part'], masked, 1)
            text = text[:item['start']] + new_full + text[item['end']:]
            continue
        elif item['type'] == 'order_with_letters':
            masked = mask_order_number_with_letters(item['number_part'], masking_dict, instance_counters)
            new_full = item['full_text'].replace(item['number_part'], masked, 1)
            text = text[:item['start']] + new_full + text[item['end']:]
            continue
        elif item['type'] in ['br_complex', 'br_with_slashes', 'br_with_suffix', 'br_standalone']:
            masked = mask_br_number(item['full_text'], masking_dict, instance_counters)
            text = text[:item['start']] + masked + text[item['end']:]
            continue

        if masked: text = text[:item['start']] + masked + text[item['end']:]

    lines = text.split('\n')
    masked_lines = []
    for line in lines:
        if not looks_like_pib_line(line):
            masked_lines.append(line)
            continue

        iteration = 0
        current_line_for_parsing = line
        final_line = line

        while iteration < 10:
            rank, pib, identifier = parse_hybrid_line(current_line_for_parsing)
            if not pib: break
            if rank and not pib:
                current_line_for_parsing = current_line_for_parsing.replace(rank, "___SKIP_RANK___", 1)
                iteration += 1
                continue

            if rank and MASK_RANKS:
                masked_rank_val = mask_rank_preserve_case(rank, masking_dict, instance_counters)
                final_line = final_line.replace(rank, masked_rank_val, 1)
                current_line_for_parsing = current_line_for_parsing.replace(rank, "___RANK_MASKED___", 1)

            if pib and MASK_NAMES:
                parts = pib.split()
                if len(parts) >= 2:
                    if is_likely_surname_by_case(parts[1]):
                        name, surname = parts[0], parts[1]
                        patronymic = parts[2] if len(parts) >= 3 else ""
                        masked_surname = mask_surname(surname, masking_dict, instance_counters)
                        masked_name = mask_name(name, masking_dict, instance_counters, gender_hint=detect_gender_by_patronymic(patronymic) if patronymic else None, patronymic_hint=patronymic)
                        masked_pib_str = f"{masked_name} {masked_surname}"
                    else:
                        surname, name = parts[0], parts[1]
                        patronymic = parts[2] if len(parts) >= 3 else ""
                        masked_surname = mask_surname(surname, masking_dict, instance_counters)
                        masked_name = mask_name(name, masking_dict, instance_counters, gender_hint=detect_gender_by_patronymic(patronymic) if patronymic else None, patronymic_hint=patronymic)
                        masked_pib_str = f"{masked_surname} {masked_name}"

                    if patronymic:
                        gender = detect_gender_by_patronymic(patronymic) if patronymic else 'male'
                        masked_patronymic = mask_patronymic(patronymic, gender, masking_dict, instance_counters)
                        masked_pib_str += f" {masked_patronymic}"

                    final_line = final_line.replace(pib, masked_pib_str, 1)
                    current_line_for_parsing = current_line_for_parsing.replace(pib, "___PIB_MASKED___", 1)
            iteration += 1
        masked_lines.append(final_line)

    return '\n'.join(masked_lines)

def mask_json_recursive(data: Any, masking_dict: Dict, instance_counters: Dict) -> Any:
    if isinstance(data, dict): return {key: mask_json_recursive(value, masking_dict, instance_counters) for key, value in data.items()}
    elif isinstance(data, list): return [mask_json_recursive(item, masking_dict, instance_counters) for item in data]
    elif isinstance(data, str): return mask_text_wrapper(data, masking_dict, instance_counters)
    else: return data

def mask_text_wrapper(text: str, masking_dict: Dict, instance_counters: Dict) -> str:
    return mask_text_context_aware(text, masking_dict, instance_counters)

def main():
    parser = argparse.ArgumentParser(description=f"Data Masking Script v{__version__}", formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument("-i", "--input", default="input.txt", help="Input file")
    parser.add_argument("-o", "--output", help="Output file")
    parser.add_argument("--no-report", action="store_true", help="No report")
    parser.add_argument("--debug", action="store_true", help="Debug mode")
    args = parser.parse_args()

    global DEBUG_MODE
    if args.debug: DEBUG_MODE = True

    input_path = Path(args.input)
    if not input_path.exists():
        print(f"Error: {args.input} not found")
        return

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    random_suffix = random.randint(100, 999)
    is_json = input_path.suffix.lower() == '.json'

    if args.output: output_path = Path(args.output)
    else: output_path = Path(f"output_{timestamp}_{random_suffix}{'.json' if is_json else '.txt'}")

    map_path = Path(f"masking_map_{timestamp}_{random_suffix}.json")
    report_path = Path(f"masking_report_{timestamp}_{random_suffix}.txt")

    masking_dict = {
        "version": __version__, "timestamp": datetime.now().isoformat(), "input_file": str(input_path),
        "statistics": {},
        "mappings": {k: {} for k in ["ipn", "passport_id", "military_id", "surname", "name", "military_unit", "order_number", "order_number_with_letters", "br_number", "br_number_slash", "br_number_complex", "rank", "brigade_number", "date", "patronymic"]},
        "instance_tracking": {}
    }
    instance_counters = {}

    print(f"Processing {input_path}...")
    try:
        with open(input_path, 'r', encoding='utf-8', newline='') as f:
            if is_json: input_data = json.load(f)
            else: input_data = f.read()
    except Exception as e:
        print(f"Error reading file: {e}")
        return

    if is_json:
        masked_data = mask_json_recursive(input_data, masking_dict, instance_counters)
    else:
        masked_data = mask_text_context_aware(input_data, masking_dict, instance_counters)

    # –§–û–†–ú–£–í–ê–ù–ù–Ø –ü–û–í–ù–û–á –°–¢–†–£–ö–¢–£–†–ò JSON
    masking_dict["instance_tracking"] = instance_counters

    total_unique = 0
    for category, mappings in masking_dict["mappings"].items():
        count = len(mappings)
        masking_dict["statistics"][category] = count
        total_unique += count
    masking_dict["statistics"]["total_masked"] = total_unique

    try:
        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É
        with open(output_path, 'w', encoding='utf-8', newline='') as f:
            if is_json: json.dump(masked_data, f, ensure_ascii=False, indent=2)
            else: f.write(masked_data)

        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –º–∞–ø–∏
        with open(map_path, 'w', encoding='utf-8') as f:
            json.dump(masking_dict, f, ensure_ascii=False, indent=2)

        # –ì–ï–ù–ï–†–ê–¶–Ü–Ø –î–ï–¢–ê–õ–¨–ù–û–ì–û –ó–í–Ü–¢–£
        if not args.no_report:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("=" * 60 + "\n")
                f.write("–ó–í–Ü–¢ –ú–ê–°–ö–£–í–ê–ù–ù–Ø –î–ê–ù–ò–•\n")
                f.write("=" * 60 + "\n\n")
                f.write(f"–î–∞—Ç–∞ —Ç–∞ —á–∞—Å: {masking_dict['timestamp']}\n")
                f.write(f"–í—Ö—ñ–¥–Ω–∏–π —Ñ–∞–π–ª: {input_path}\n")
                f.write(f"–í–∏—Ö—ñ–¥–Ω–∏–π —Ñ–∞–π–ª: {output_path}\n\n")
                f.write("-" * 60 + "\n")
                f.write("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ú–ê–°–ö–£–í–ê–ù–ù–Ø\n")
                f.write("-" * 60 + "\n\n")
                f.write(f"–ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –£–ù–Ü–ö–ê–õ–¨–ù–ò–• –∑–∞–º–∞—Å–∫–æ–≤–∞–Ω–∏—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤: {total_unique}\n\n")

                for key, value in sorted(masking_dict["statistics"].items()):
                    if key != "total_masked" and value > 0:
                        f.write(f"  ‚Ä¢ {key}: {value} (—É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –æ—Ä–∏–≥—ñ–Ω–∞–ª—ñ–≤)\n")

                f.write("\n" + "=" * 60 + "\n")
                f.write("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –í–•–û–î–ñ–ï–ù–¨ (Instance Tracking)\n")
                f.write("-" * 60 + "\n\n")
                for masked_val, count in sorted(masking_dict["instance_tracking"].items()):
                    f.write(f"  ‚Ä¢ '{masked_val}': {count} –≤—Ö–æ–¥–∂–µ–Ω—å\n")
                f.write("\n" + "=" * 60 + "\n")

        # –î–ï–¢–ê–õ–¨–ù–ò–ô –í–ò–í–Ü–î –£ –ö–û–ù–°–û–õ–¨
        print()
        print("‚úÖ –ú–∞—Å–∫—É–≤–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")
        print()
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –£–ù–Ü–ö–ê–õ–¨–ù–ò–• –∑–∞–º–∞—Å–∫–æ–≤–∞–Ω–∏—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤: {total_unique}")
        for key, value in sorted(masking_dict["statistics"].items()):
            if key != "total_masked" and value > 0:
                print(f"   ‚Ä¢ {key}: {value} (—É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –æ—Ä–∏–≥—ñ–Ω–∞–ª—ñ–≤)")
        print()
        print(f"   –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—Ö–æ–¥–∂–µ–Ω—å (Instance Tracking):")
        # –í–∏–≤–æ–¥–∏–º–æ —Ç—ñ–ª—å–∫–∏ —Ç–æ–ø-10 –¥–ª—è –∫–æ–Ω—Å–æ–ª—ñ, —â–æ–± –Ω–µ –∑–∞—Å–º—ñ—á—É–≤–∞—Ç–∏
        sorted_instances = sorted(masking_dict["instance_tracking"].items(), key=lambda x: x[1], reverse=True)
        for masked_val, count in sorted_instances[:10]:
            print(f"   ‚Ä¢ '{masked_val}': {count} –≤—Ö–æ–¥–∂–µ–Ω—å")
        if len(sorted_instances) > 10:
            print(f"   ... —Ç–∞ —â–µ {len(sorted_instances) - 10} –∑–∞–ø–∏—Å—ñ–≤")

        print()
        print(f"üìÅ –§–∞–π–ª–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ:")
        print(f"   ‚Ä¢ –ó–∞–º–∞—Å–∫–æ–≤–∞–Ω—ñ –¥–∞–Ω—ñ: {output_path.absolute()}")
        print(f"   ‚Ä¢ –°–ª–æ–≤–Ω–∏–∫ –∑–∞–º—ñ–Ω: {map_path.absolute()}")
        if not args.no_report:
            print(f"   ‚Ä¢ –ó–≤—ñ—Ç: {report_path.absolute()}")

    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—ñ–≤: {e}")

if __name__ == "__main__":
    main()