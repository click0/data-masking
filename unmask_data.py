#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Data Unmasking Script v2.2.14
–í—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö –∑ –∑–∞–º–∞—Å–∫–æ–≤–∞–Ω–æ–≥–æ —Ñ–∞–π–ª—É

–¶–µ–π —Å–∫—Ä–∏–ø—Ç –≤–∏–∫–æ–Ω—É—î –∑–≤–æ—Ä–æ—Ç–Ω—É –æ–ø–µ—Ä–∞—Ü—ñ—é –¥–æ data_masking.py: –≤—ñ–¥–Ω–æ–≤–ª—é—î –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω—ñ
–¥–∞–Ω—ñ –∑ –∑–∞–º–∞—Å–∫–æ–≤–∞–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–∏–π —Å–ª–æ–≤–Ω–∏–∫ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤.

–ö–õ–Æ–ß–û–í–Ü –û–°–û–ë–õ–ò–í–û–°–¢–Ü:
    - Instance Tracking: –≤—ñ–¥–Ω–æ–≤–ª—é—î –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π –æ—Ä–∏–≥—ñ–Ω–∞–ª –ø—Ä–∏ –∫–æ–ª—ñ–∑—ñ—è—Ö –º–∞—Å–∫—É–≤–∞–Ω–Ω—è
    - Gender-aware unmask: –≤—ñ–¥–Ω–æ–≤–ª—é—î –∑–≤–∞–Ω–Ω—è –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º —Ä–æ–¥—É (—á–æ–ª–æ–≤—ñ—á–∏–π/–∂—ñ–Ω–æ—á–∏–π)
    - Case restoration: –≤—ñ–¥–Ω–æ–≤–ª—é—î –≥—Ä–∞–º–∞—Ç–∏—á–Ω–∏–π –≤—ñ–¥–º—ñ–Ω–æ–∫ –∑–≤–∞–Ω—å (–Ω–∞–∑–∏–≤–Ω–∏–π, —Ä–æ–¥–æ–≤–∏–π, –¥–∞–≤–∞–ª—å–Ω–∏–π)
    - Case preservation: –∑–±–µ—Ä—ñ–≥–∞—î —Ä–µ–≥—ñ—Å—Ç—Ä –ª—ñ—Ç–µ—Ä (UPPER, Title, lower)
    - –ü—ñ–¥—Ç—Ä–∏–º–∫–∞ —Å–∫–ª–∞–¥–Ω–∏—Ö –∑–≤–∞–Ω—å: "–∫–∞–ø—ñ—Ç–∞–Ω –º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏ —É –≤—ñ–¥—Å—Ç–∞–≤—Ü—ñ"

–û–ù–û–í–õ–ï–ù–û –í v2.2.9:
- üîß –í–∏–ø—Ä–∞–≤–ª–µ–Ω–æ —ñ–º–ø–æ—Ä—Ç–∏ (datetime)
- üî® –°–∏–Ω—Ö—Ä–æ–Ω—ñ–∑–∞—Ü—ñ—è –∑ rank_data.py
- üìÑ –î–µ—Ç–∞–ª—å–Ω—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ —Ç–∞ –ø–æ–∫—Ä–∞—â–µ–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞

–§–û–†–ú–ê–¢ –í–•–Ü–î–ù–ò–• –î–ê–ù–ò–•:
    1. –ó–∞–º–∞—Å–∫–æ–≤–∞–Ω–∏–π —Ñ–∞–π–ª (output_TIMESTAMP.txt/json)
    2. –°–ª–æ–≤–Ω–∏–∫ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤ (masking_map_TIMESTAMP.json)

–ü–†–ò–ö–õ–ê–î –í–ò–ö–û–†–ò–°–¢–ê–ù–ù–Ø:
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π —Ä–µ–∂–∏–º (—à—É–∫–∞—î –æ—Å—Ç–∞–Ω–Ω—é –ø–∞—Ä—É —Ñ–∞–π–ª—ñ–≤)
    python unmask_data.py

    # –†—É—á–Ω–∏–π —Ä–µ–∂–∏–º –∑ –≤–∫–∞–∑–∞–Ω–Ω—è–º —Ñ–∞–π–ª—ñ–≤
    python unmask_data.py output_20250101_120000_123.txt --map masking_map_20250101_120000_123.json

    # –ó –≤–∫–∞–∑–∞–Ω–Ω—è–º output —Ñ–∞–π–ª—É
    python unmask_data.py output_20250101_120000_123.txt -o recovered_input.txt

Author: Vladyslav V. Prodan
Contact: github.com/click0
Version: 2.2.9
License: BSD 3-Clause
Year: 2025
"""

import json
import argparse
import re
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any

# ============================================================================
# –Ü–ú–ü–û–†–¢ –î–ê–ù–ò–• –ó –ú–û–î–£–õ–Ø
# ============================================================================
from rank_data import (
    RANK_DECLENSIONS,          # –í—ñ–¥–º—ñ–Ω–∫–∏ —á–æ–ª–æ–≤—ñ—á–∏—Ö –∑–≤–∞–Ω—å
    RANK_FEMININE_MAP,         # –ú–∞–ø–∞ —á–æ–ª–æ–≤—ñ—á–∏—Ö ‚Üí –∂—ñ–Ω–æ—á–∏—Ö –∑–≤–∞–Ω—å
    RANK_DECLENSIONS_FEMALE,   # –í—ñ–¥–º—ñ–Ω–∫–∏ –∂—ñ–Ω–æ—á–∏—Ö –∑–≤–∞–Ω—å
    RANK_TO_NOMINATIVE,        # –ó–≤–æ—Ä–æ—Ç–Ω–∏–π —ñ–Ω–¥–µ–∫—Å —Ñ–æ—Ä–º –∑–≤–∞–Ω—å
    ALL_RANK_FORMS             # –í—ñ–¥—Å–æ—Ä—Ç–æ–≤–∞–Ω–∏–π —Å–ø–∏—Å–æ–∫ –≤—Å—ñ—Ö —Ñ–æ—Ä–º
)

# ============================================================================
# –ú–ï–¢–ê–î–ê–ù–Ü
# ============================================================================
__version__ = "2.2.9"
__author__ = "Vladyslav V. Prodan"
__contact__ = "github.com/click0"
__phone__ = "+38(099)6053340"
__license__ = "BSD 3-Clause"
__year__ = "2025"

# ============================================================================
# –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–Ø –ü–û–®–£–ö–£ –§–ê–ô–õ–Ü–í
# ============================================================================
# –î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ–≥–æ –ø–æ—à—É–∫—É –ø–∞—Ä —Ñ–∞–π–ª—ñ–≤ (output + mapping)
SEARCH_DIRECTORIES = [
    Path('.'),          # –ü–æ—Ç–æ—á–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è
    Path('./output'),   # –ü—ñ–¥—Ç–µ–∫–∞ output
    Path('./result')    # –ü—ñ–¥—Ç–µ–∫–∞ result
]

# ============================================================================
# –î–û–ü–û–ú–Ü–ñ–ù–Ü –§–£–ù–ö–¶–Ü–á - –ê–ù–ê–õ–Ü–ó –¢–ê –†–û–ó–ü–Ü–ó–ù–ê–í–ê–ù–ù–Ø
# ============================================================================

def get_rank_info(rank_form: str) -> Tuple[Optional[str], Optional[str], Optional[str]]:
    """
    –û—Ç—Ä–∏–º—É—î —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –∑–≤–∞–Ω–Ω—è –∑–∞ –π–æ–≥–æ –≥—Ä–∞–º–∞—Ç–∏—á–Ω–æ—é —Ñ–æ—Ä–º–æ—é.

    –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –∑–≤–æ—Ä–æ—Ç–Ω–∏–π —ñ–Ω–¥–µ–∫—Å RANK_TO_NOMINATIVE –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ –ø–æ—à—É–∫—É.

    Args:
        rank_form: –ë—É–¥—å-—è–∫–∞ —Ñ–æ—Ä–º–∞ –∑–≤–∞–Ω–Ω—è (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "—Å–æ–ª–¥–∞—Ç—É", "—Å–µ—Ä–∂–∞–Ω—Ç—Ü—ñ")

    Returns:
        Tuple –∑ —Ç—Ä—å–æ—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤:
            - –±–∞–∑–æ–≤–∞_—Ñ–æ—Ä–º–∞: –Ω–∞–∑–∏–≤–Ω–∏–π –≤—ñ–¥–º—ñ–Ω–æ–∫ —á–æ–ª–æ–≤—ñ—á–æ–≥–æ —Ä–æ–¥—É ("—Å–æ–ª–¥–∞—Ç", "—Å–µ—Ä–∂–∞–Ω—Ç")
            - –≤—ñ–¥–º—ñ–Ω–æ–∫: –Ω–∞–∑–≤–∞ –≤—ñ–¥–º—ñ–Ω–∫–∞ ('nominative', 'genitive', 'dative', 'instrumental')
            - —Ä—ñ–¥: 'male' –∞–±–æ 'female'

        –ê–±–æ (None, None, None) —è–∫—â–æ –∑–≤–∞–Ω–Ω—è –Ω–µ —Ä–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ

    """
    rank_lower = rank_form.lower()
    if rank_lower in RANK_TO_NOMINATIVE:
        return RANK_TO_NOMINATIVE[rank_lower]
    return None, None, None


def find_file_pairs(directories: List[Path]) -> List[Tuple[Path, Path, str]]:
    """
    –®—É–∫–∞—î –ø–∞—Ä–∏ —Ñ–∞–π–ª—ñ–≤ output + mapping –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ–≥–æ unmask.

    –ê–ª–≥–æ—Ä–∏—Ç–º:
        1. –°–∫–∞–Ω—É—î –≤–∫–∞–∑–∞–Ω—ñ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó
        2. –ó–Ω–∞—Ö–æ–¥–∏—Ç—å —Ñ–∞–π–ª–∏ –∑ —à–∞–±–ª–æ–Ω–æ–º output_TIMESTAMP.*
        3. –í–∏—Ç—è–≥—É—î timestamp –∑ –Ω–∞–∑–≤–∏ —Ñ–∞–π–ª—É
        4. –®—É–∫–∞—î –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–π masking_map_TIMESTAMP.json
        5. –ü–æ–≤–µ—Ä—Ç–∞—î –ø–∞—Ä–∏, –≤—ñ–¥—Å–æ—Ä—Ç–æ–≤–∞–Ω—ñ –∑–∞ timestamp (–Ω–∞–π–Ω–æ–≤—ñ—à—ñ –ø–µ—Ä—à–∏–º–∏)

    Args:
        directories: –°–ø–∏—Å–æ–∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ–π –¥–ª—è –ø–æ—à—É–∫—É

    Returns:
        –°–ø–∏—Å–æ–∫ tuple: (output_file_path, map_file_path, timestamp_string)
        –í—ñ–¥—Å–æ—Ä—Ç–æ–≤–∞–Ω–æ –∑–∞ timestamp —É –∑–≤–æ—Ä–æ—Ç–Ω–æ–º—É –ø–æ—Ä—è–¥–∫—É (–Ω–∞–π–Ω–æ–≤—ñ—à—ñ –ø–µ—Ä—à–∏–º–∏)

    """
    pairs = []

    for directory in directories:
        # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –Ω–µ—ñ—Å–Ω—É—é—á—ñ –∞–±–æ –Ω–µ-–¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó
        if not directory.exists() or not directory.is_dir():
            continue

        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –≤—Å—ñ output —Ñ–∞–π–ª–∏ (txt —Ç–∞ json)
        output_files = list(directory.glob('output_*.txt')) + list(directory.glob('output_*.json'))

        for output_file in output_files:
            # –í–∏—Ç—è–≥—É—î–º–æ timestamp –∑ –Ω–∞–∑–≤–∏ —Ñ–∞–π–ª—É
            # –§–æ—Ä–º–∞—Ç: output_YYYYMMDD_HHMMSS_RRR.ext
            match = re.match(r'output_(\d{8}_\d{6}_\d{3})', output_file.stem)
            if not match:
                continue

            timestamp_suffix = match.group(1)

            # –®—É–∫–∞—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–π —Ñ–∞–π–ª –º–∞–ø–ø—ñ–Ω–≥—É
            map_file = directory / f"masking_map_{timestamp_suffix}.json"

            if map_file.exists():
                pairs.append((output_file, map_file, timestamp_suffix))

    # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ timestamp —É –∑–≤–æ—Ä–æ—Ç–Ω–æ–º—É –ø–æ—Ä—è–¥–∫—É (–Ω–∞–π–Ω–æ–≤—ñ—à—ñ –ø–µ—Ä—à–∏–º–∏)
    pairs.sort(key=lambda x: x[2], reverse=True)
    return pairs


def auto_find_latest_pair() -> Optional[Tuple[Path, Path, Path]]:
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –∑–Ω–∞—Ö–æ–¥–∏—Ç—å —Ç–∞ –≤–∏–±–∏—Ä–∞—î –æ—Å—Ç–∞–Ω–Ω—é –ø–∞—Ä—É —Ñ–∞–π–ª—ñ–≤ –¥–ª—è unmask.

    –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∫–æ–ª–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á –Ω–µ –≤–∫–∞–∑–∞–≤ —Ñ–∞–π–ª–∏ –≤—Ä—É—á–Ω—É.

    Returns:
        Tuple –∑ —Ç—Ä—å–æ—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤:
            - output_file: —à–ª—è—Ö –¥–æ –∑–∞–º–∞—Å–∫–æ–≤–∞–Ω–æ–≥–æ —Ñ–∞–π–ª—É
            - map_file: —à–ª—è—Ö –¥–æ —Å–ª–æ–≤–Ω–∏–∫–∞ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤
            - recovery_file: —à–ª—è—Ö –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–æ–≥–æ —Ñ–∞–π–ª—É

        –ê–±–æ None —è–∫—â–æ —Ñ–∞–π–ª–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ

    Output:
        –í–∏–≤–æ–¥–∏—Ç—å —É –∫–æ–Ω—Å–æ–ª—å —Å—Ç–∞—Ç—É—Å –ø–æ—à—É–∫—É —Ç–∞ –∑–Ω–∞–π–¥–µ–Ω—ñ —Ñ–∞–π–ª–∏
    """
    print("‚ùó –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π —Ä–µ–∂–∏–º")
    print("üîç –®—É–∫–∞—é –ø–∞—Ä–∏ —Ñ–∞–π–ª—ñ–≤...\n")

    pairs = find_file_pairs(SEARCH_DIRECTORIES)

    if not pairs:
        print("‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª—ñ–≤!")
        return None

    print(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ {len(pairs)} –ø–∞—Ä")

    # –ë–µ—Ä–µ–º–æ –Ω–∞–π–Ω–æ–≤—ñ—à–∏–π (–ø–µ—Ä—à–∏–π —É —Å–ø–∏—Å–∫—É –ø—ñ—Å–ª—è —Å–æ—Ä—Ç—É–≤–∞–Ω–Ω—è)
    output_file, map_file, timestamp_suffix = pairs[0]
    print(f"\n‚è∞ –í–∏–±—Ä–∞–Ω–æ: {output_file.name}\n")

    # –§–æ—Ä–º—É—î–º–æ —ñ–º'—è –¥–ª—è –≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–æ–≥–æ —Ñ–∞–π–ª—É
    extension = output_file.suffix
    recovery_file = output_file.parent / f"input_recovery_{timestamp_suffix}{extension}"

    return output_file, map_file, recovery_file


def check_mapping_version(masking_map: Dict) -> str:
    """
    –í–∏–∑–Ω–∞—á–∞—î –≤–µ—Ä—Å—ñ—é —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ mapping —Ñ–∞–π–ª—É.

    –†—ñ–∑–Ω—ñ –≤–µ—Ä—Å—ñ—ó data_masking.py –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å —Ä—ñ–∑–Ω—ñ —Ñ–æ—Ä–º–∞—Ç–∏ —Å–ª–æ–≤–Ω–∏–∫—ñ–≤.
    Unmask –º–∞—î –∞–¥–∞–ø—Ç—É–≤–∞—Ç–∏—Å—è –¥–æ –≤–µ—Ä—Å—ñ—ó –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è.

    Args:
        masking_map: –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∏–π —Å–ª–æ–≤–Ω–∏–∫ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤

    Returns:
        –í–µ—Ä—Å—ñ—è –ª–æ–≥—ñ–∫–∏: 'v2.1', 'v2.0' –∞–±–æ 'v1'

    Version differences:
        - v2.1+: –ü–æ–≤–Ω–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∞ instance tracking, gender-aware ranks
        - v2.0: –ë–∞–∑–æ–≤–∏–π instance tracking
        - v1: –ü—Ä–æ—Å—Ç–∞ –∑–∞–º—ñ–Ω–∞ —Ä—è–¥–∫—ñ–≤ (–±–µ–∑ instance tracking)
    """
    version = masking_map.get("version", "1.0.0")

    if version.startswith("2.2") or version.startswith("2.1"):
        return "v2.1"
    elif version.startswith("2.0"):
        return "v2.0"
    else:
        return "v1"


def find_all_occurrences(text: str, pattern: str) -> List[Tuple[int, int]]:
    """
    –ó–Ω–∞—Ö–æ–¥–∏—Ç—å –≤—Å—ñ –≤—Ö–æ–¥–∂–µ–Ω–Ω—è —à–∞–±–ª–æ–Ω—É –≤ —Ç–µ–∫—Å—Ç—ñ (case-insensitive).

    –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î word boundaries –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ—à—É–∫—É —Ü—ñ–ª–∏—Ö —Å–ª—ñ–≤.

    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –ø–æ—à—É–∫—É
        pattern: –®–∞–±–ª–æ–Ω –¥–ª—è –ø–æ—à—É–∫—É (–±—É–¥–µ –µ–∫—Ä–∞–Ω–æ–≤–∞–Ω–æ)

    Returns:
        –°–ø–∏—Å–æ–∫ tuple (start_position, end_position) –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –≤—Ö–æ–¥–∂–µ–Ω–Ω—è

    Note:
        –ü–æ—à—É–∫ —Ä–µ–≥—ñ—Å—Ç—Ä–æ–Ω–µ–∑–∞–ª–µ–∂–Ω–∏–π (case-insensitive) –¥–ª—è –∑—Ä—É—á–Ω–æ—Å—Ç—ñ
        –ú–∞—î fallback –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤, —è–∫—ñ –º–æ–∂—É—Ç—å –≤–∏–∫–ª–∏–∫–∞—Ç–∏ regex –ø–æ–º–∏–ª–∫–∏

    """
    occurrences = []

    # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ word boundaries (\b) –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ—à—É–∫—É —Å–ª—ñ–≤
    try:
        regex_pattern = r'(?<!\w)' + re.escape(pattern) + r'(?!\w)'
        for match in re.finditer(regex_pattern, text, re.IGNORECASE):
            occurrences.append((match.start(), match.end()))
    except re.error:
        # Fallback –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤, —â–æ –º–æ–∂—É—Ç—å —Å–ø—Ä–∏—á–∏–Ω–∏—Ç–∏ –ø–æ–º–∏–ª–∫–∏ regex
        pass

    return occurrences


def build_instance_map(masking_map: Dict) -> Dict[str, Dict[int, str]]:
    """
    –°—Ç–≤–æ—Ä—é—î –º–∞–ø—É –¥–ª—è instance tracking –ø—Ä–∏ unmask.

    Instance tracking –¥–æ–∑–≤–æ–ª—è—î –≤—ñ–¥–Ω–æ–≤–∏—Ç–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π –æ—Ä–∏–≥—ñ–Ω–∞–ª –ø—Ä–∏ –∫–æ–ª—ñ–∑—ñ—è—Ö,
    –∫–æ–ª–∏ —Ä—ñ–∑–Ω—ñ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –±—É–ª–∏ –∑–∞–º–∞—Å–∫–æ–≤–∞–Ω—ñ –≤ –æ–¥–Ω–µ —ñ —Ç–µ —Å–∞–º–µ –∑–Ω–∞—á–µ–Ω–Ω—è.

    –ü–†–û–ë–õ–ï–ú–ê –ë–ï–ó INSTANCE TRACKING:
        Original1: "–ü–µ—Ç—Ä–µ–Ω–∫–æ" ‚Üí Masked: "–Ü–≤–∞–Ω–µ–Ω–∫–æ" (instance 1)
        Original2: "–°–∏–¥–æ—Ä–µ–Ω–∫–æ" ‚Üí Masked: "–Ü–≤–∞–Ω–µ–Ω–∫–æ" (instance 2)

        –ü—Ä–∏ unmask –±–µ–∑ tracking: –≤—Å—ñ "–Ü–≤–∞–Ω–µ–Ω–∫–æ" ‚Üí "–ü–µ—Ç—Ä–µ–Ω–∫–æ" (–ü–û–ú–ò–õ–ö–ê!)
        –ó instance tracking: –ø–µ—Ä—à–∏–π "–Ü–≤–∞–Ω–µ–Ω–∫–æ" ‚Üí "–ü–µ—Ç—Ä–µ–Ω–∫–æ", –¥—Ä—É–≥–∏–π ‚Üí "–°–∏–¥–æ—Ä–µ–Ω–∫–æ" ‚úì

    –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –º–∞–ø–∏:
        {
            '–Ü–≤–∞–Ω–µ–Ω–∫–æ': {
                1: '–ü–µ—Ç—Ä–µ–Ω–∫–æ',   # –ø–µ—Ä—à–µ –≤—Ö–æ–¥–∂–µ–Ω–Ω—è
                2: '–°–∏–¥–æ—Ä–µ–Ω–∫–æ'   # –¥—Ä—É–≥–µ –≤—Ö–æ–¥–∂–µ–Ω–Ω—è
            },
            '–ö–æ–≤–∞–ª–µ–Ω–∫–æ': {
                1: '–®–µ–≤—á–µ–Ω–∫–æ'
            }
        }

    Args:
        masking_map: –°–ª–æ–≤–Ω–∏–∫ –º–∞—Å–∫—É–≤–∞–Ω–Ω—è —É —Ñ–æ—Ä–º–∞—Ç—ñ v2.x

    Returns:
        –°–ª–æ–≤–Ω–∏–∫ {masked_value: {instance_num: original_value}}

    """
    instance_map = {}
    mappings_data = masking_map.get("mappings", {})

    # –ü–µ—Ä–µ–±–∏—Ä–∞—î–º–æ –≤—Å—ñ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó (surname, name, rank, ipn —Ç–æ—â–æ)
    for category, mappings in mappings_data.items():
        for original, mask_info in mappings.items():
            # –§–æ—Ä–º–∞—Ç v2.x: {"masked_as": "...", "instances": [1, 2, ...]}
            if isinstance(mask_info, dict) and "masked_as" in mask_info:
                masked_value = mask_info["masked_as"]
                instances = mask_info.get("instances", [])

                # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ –ø—ñ–¥—Å–ª–æ–≤–Ω–∏–∫ –¥–ª—è —Ü—ñ—î—ó –º–∞—Å–∫–∏
                if masked_value not in instance_map:
                    instance_map[masked_value] = {}

                # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∑–≤'—è–∑–æ–∫: instance_num ‚Üí original_value
                for instance_num in instances:
                    instance_map[masked_value][instance_num] = original

    return instance_map


def _apply_original_case(original: str, masked: str) -> str:
    """
    –í—ñ–¥–Ω–æ–≤–ª—é—î —Ä–µ–≥—ñ—Å—Ç—Ä –ª—ñ—Ç–µ—Ä –æ—Ä–∏–≥—ñ–Ω–∞–ª—É –Ω–∞ –º–∞—Å–∫–æ–≤–∞–Ω–æ–º—É –∑–Ω–∞—á–µ–Ω–Ω—ñ.

    –ó–±–µ—Ä—ñ–≥–∞—î —Ç—Ä–∏ —Ç–∏–ø–∏ —Ä–µ–≥—ñ—Å—Ç—Ä—É:
        - UPPER CASE (–≤—Å—ñ –≤–µ–ª–∏–∫—ñ)
        - Title Case (–ø–µ—Ä—à–∞ –≤–µ–ª–∏–∫–∞)
        - lower case (–≤—Å—ñ –º–∞–ª—ñ)

    Args:
        original: –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π —Ç–µ–∫—Å—Ç –∑ —Ä–µ–≥—ñ—Å—Ç—Ä–æ–º –¥–ª—è –≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è
        masked: –¢–µ–∫—Å—Ç –¥–ª—è –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è —Ä–µ–≥—ñ—Å—Ç—Ä—É

    Returns:
        –¢–µ–∫—Å—Ç –∑ –≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–∏–º —Ä–µ–≥—ñ—Å—Ç—Ä–æ–º

    """
    if not original or not masked:
        return masked

    # –í—Å—ñ –≤–µ–ª–∏–∫—ñ
    if original.isupper():
        return masked.upper()
    # –ü–µ—Ä—à–∞ –≤–µ–ª–∏–∫–∞, —Ä–µ—à—Ç–∞ –º–∞–ª—ñ (Title Case)
    elif len(original) > 1 and original[0].isupper() and original[1:].islower():
        return masked.capitalize()
    # –í—Å—ñ –º–∞–ª—ñ
    else:
        return masked.lower()


def is_real_mask(value: str, masking_map: Dict, all_masked_values: set = None) -> bool:
    """
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î, —á–∏ —î —Å–ª–æ–≤–æ —Ä–µ–∞–ª—å–Ω–æ—é –º–∞—Å–∫–æ—é (–∞ –Ω–µ –≤–∏–ø–∞–¥–∫–æ–≤–∏–º –∑–±—ñ–≥–æ–º –∑ –æ—Ä–∏–≥—ñ–Ω–∞–ª–æ–º).

    –ü–†–û–ë–õ–ï–ú–ê:
        –Ø–∫—â–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª "–Ü–≤–∞–Ω–µ–Ω–∫–æ" –±—É–≤ –∑–∞–º–∞—Å–∫–æ–≤–∞–Ω–∏–π —è–∫ "–ü–µ—Ç—Ä–µ–Ω–∫–æ",
        –∞ –≤ —Ç–µ–∫—Å—Ç—ñ —î —Ä–µ–∞–ª—å–Ω–µ —ñ–º'—è "–ü–µ—Ç—Ä–µ–Ω–∫–æ" (–Ω–µ –º–∞—Å–∫–∞), —Ç–æ unmask –º–æ–∂–µ
        –ø–æ–º–∏–ª–∫–æ–≤–æ —Å–ø—Ä–æ–±—É–≤–∞—Ç–∏ –π–æ–≥–æ —Ä–æ–∑–º–∞—Å–∫—É–≤–∞—Ç–∏.

    –†–Ü–®–ï–ù–ù–Ø:
        –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –∑–Ω–∞—á–µ–Ω–Ω—è —Å–ø—Ä–∞–≤–¥—ñ —î –º–∞—Å–∫–æ—é –∑—ñ —Å–ª–æ–≤–Ω–∏–∫–∞, –∞ –Ω–µ –æ—Ä–∏–≥—ñ–Ω–∞–ª–æ–º.

    Args:
        value: –ó–Ω–∞—á–µ–Ω–Ω—è –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏
        masking_map: –°–ª–æ–≤–Ω–∏–∫ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤
        all_masked_values: –û–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ, –Ω–∞–±—ñ—Ä –≤—Å—ñ—Ö –º–∞—Å–æ–∫ –¥–ª—è —à–≤–∏–¥–∫–æ—ó –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏

    Returns:
        True —è–∫—â–æ value —î –º–∞—Å–∫–æ—é, False —è–∫—â–æ —Ü–µ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è
    """
    value_lower = value.lower()

    # –®–≤–∏–¥–∫–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ —á–µ—Ä–µ–∑ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ —Å—Ç–≤–æ—Ä–µ–Ω–∏–π –Ω–∞–±—ñ—Ä
    if all_masked_values is not None:
        return value_lower in all_masked_values

    # –ü–æ–≤—ñ–ª—å–Ω–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ —á–µ—Ä–µ–∑ –≤–µ—Å—å —Å–ª–æ–≤–Ω–∏–∫
    mappings = masking_map.get("mappings", {})
    for category, items in mappings.items():
        for original, mask_info in items.items():
            if isinstance(mask_info, dict) and "masked_as" in mask_info:
                if mask_info["masked_as"].lower() == value_lower:
                    return True

    return False


def extract_base_rank(full_rank_text: str) -> tuple:
    """
    –í–∏–¥—ñ–ª—è—î –±–∞–∑–æ–≤–µ –∑–≤–∞–Ω–Ω—è —Ç–∞ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ —Å–ª–æ–≤–∞ –∑—ñ —Å–∫–ª–∞–¥–µ–Ω–æ–≥–æ –∑–≤–∞–Ω–Ω—è.

    –°–∫–ª–∞–¥–µ–Ω—ñ –∑–≤–∞–Ω–Ω—è –º–æ–∂—É—Ç—å –º—ñ—Å—Ç–∏—Ç–∏:
        - –¢–∏–ø —Å–ª—É–∂–±–∏: "–º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏", "—é—Å—Ç–∏—Ü—ñ—ó"
        - –°—Ç–∞—Ç—É—Å: "—É –≤—ñ–¥—Å—Ç–∞–≤—Ü—ñ", "–≤ –∑–∞–ø–∞—Å—ñ", "—É –∑–∞–ø–∞—Å—ñ"

    –§—É–Ω–∫—Ü—ñ—è —Ä–æ–∑–¥—ñ–ª—è—î –∑–≤–∞–Ω–Ω—è –Ω–∞:
        - –ë–∞–∑–æ–≤–µ –∑–≤–∞–Ω–Ω—è (–¥–ª—è unmask —á–µ—Ä–µ–∑ —Å–ª–æ–≤–Ω–∏–∫)
        - –î–æ–¥–∞—Ç–∫–æ–≤—ñ —Å–ª–æ–≤–∞ (–¥–ª—è –¥–æ–¥–∞–≤–∞–Ω–Ω—è –Ω–∞–∑–∞–¥ –ø—ñ—Å–ª—è unmask)

    Args:
        full_rank_text: –ü–æ–≤–Ω–∏–π —Ç–µ–∫—Å—Ç –∑–≤–∞–Ω–Ω—è –∑ –º–æ–∂–ª–∏–≤–∏–º–∏ –¥–æ–¥–∞—Ç–∫–æ–≤–∏–º–∏ —Å–ª–æ–≤–∞–º–∏

    Returns:
        Tuple (–±–∞–∑–æ–≤–µ_–∑–≤–∞–Ω–Ω—è, –¥–æ–¥–∞—Ç–∫–æ–≤—ñ_—Å–ª–æ–≤–∞)

    Algorithm:
        1. –°–ø–æ—á–∞—Ç–∫—É —à—É–∫–∞—î —Ç–∏–ø —Å–ª—É–∂–±–∏ (–º–µ–¥–∏—á–Ω–∞, —é—Å—Ç–∏—Ü—ñ—è)
        2. –ü–æ—Ç—ñ–º —à—É–∫–∞—î —Å—Ç–∞—Ç—É—Å (–≤—ñ–¥—Å—Ç–∞–≤–∫–∞, –∑–∞–ø–∞—Å)
        3. –ó–±–µ—Ä—ñ–≥–∞—î –æ–±–∏–¥–≤—ñ —á–∞—Å—Ç–∏–Ω–∏ —è–∫ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ —Å–ª–æ–≤–∞
        4. –ë–∞–∑–æ–≤–µ –∑–≤–∞–Ω–Ω—è = –≤—Å–µ —â–æ –∑–∞–ª–∏—à–∏–ª–æ—Å—è
    """
    if not full_rank_text:
        return full_rank_text, ""

    # –ú–æ–∂–ª–∏–≤—ñ —Ç–∏–ø–∏ —Å–ª—É–∂–±
    service_type_phrases = ['–º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏', '—é—Å—Ç–∏—Ü—ñ—ó']

    # –ú–æ–∂–ª–∏–≤—ñ —Å—Ç–∞—Ç—É—Å–∏ –≤—ñ–π—Å—å–∫–æ–≤–æ—Å–ª—É–∂–±–æ–≤—Ü—è
    status_phrases = [
        '—É –≤—ñ–¥—Å—Ç–∞–≤—Ü—ñ', '–≤ –∑–∞–ø–∞—Å—ñ', '—É –∑–∞–ø–∞—Å—ñ',
        '–Ω–∞ –ø–µ–Ω—Å—ñ—ó', '–≤ —Ä–µ–∑–µ—Ä–≤—ñ', '—É —Ä–µ–∑–µ—Ä–≤—ñ'
    ]

    full_rank_lower = full_rank_text.lower()
    base_rank = full_rank_text
    additional_parts = []

    # 1. –®—É–∫–∞—î–º–æ —Ç–∞ –≤–∏–¥—ñ–ª—è—î–º–æ —Ç–∏–ø —Å–ª—É–∂–±–∏
    for phrase in service_type_phrases:
        if phrase in full_rank_lower:
            phrase_index = full_rank_lower.find(phrase)
            # –ë–∞–∑–æ–≤–µ –∑–≤–∞–Ω–Ω—è = –≤—Å–µ –¥–æ —Ç–∏–ø—É —Å–ª—É–∂–±–∏
            base_rank = full_rank_text[:phrase_index].strip()
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ç–∏–ø —Å–ª—É–∂–±–∏ –∑—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è–º —Ä–µ–≥—ñ—Å—Ç—Ä—É –æ—Ä–∏–≥—ñ–Ω–∞–ª—É
            additional_parts.append(full_rank_text[phrase_index:phrase_index + len(phrase)])

            # –í–∏–¥–∞–ª—è—î–º–æ –∑–Ω–∞–π–¥–µ–Ω–µ –¥–ª—è –ø–æ–¥–∞–ª—å—à–æ–≥–æ –ø–æ—à—É–∫—É —Å—Ç–∞—Ç—É—Å—É
            remaining_text = full_rank_text[phrase_index + len(phrase):].strip()
            full_rank_lower = remaining_text.lower()
            full_rank_text = remaining_text
            break

    # 2. –®—É–∫–∞—î–º–æ —Ç–∞ –≤–∏–¥—ñ–ª—è—î–º–æ —Å—Ç–∞—Ç—É—Å
    for phrase in status_phrases:
        if phrase in full_rank_lower:
            # –Ø–∫—â–æ —â–µ –Ω–µ –∑–Ω–∞–π—à–ª–∏ —Ç–∏–ø —Å–ª—É–∂–±–∏, –æ–Ω–æ–≤–ª—é—î–º–æ –±–∞–∑–æ–≤–µ –∑–≤–∞–Ω–Ω—è
            if not additional_parts:
                phrase_index = full_rank_text.lower().find(phrase)
                base_rank = full_rank_text[:phrase_index].strip()

            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Å—Ç–∞—Ç—É—Å –∑—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è–º —Ä–µ–≥—ñ—Å—Ç—Ä—É
            phrase_start = full_rank_text.lower().find(phrase)
            additional_parts.append(full_rank_text[phrase_start:phrase_start + len(phrase)])
            break

    # –û–±'—î–¥–Ω—É—î–º–æ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ —á–∞—Å—Ç–∏–Ω–∏ —á–µ—Ä–µ–∑ –ø—Ä–æ–±—ñ–ª
    additional = ' '.join(additional_parts) if additional_parts else ""
    return base_rank, additional

# ============================================================================
# –ì–û–õ–û–í–ù–Ü –§–£–ù–ö–¶–Ü–á UNMASK
# ============================================================================

def unmask_ranks_gender_aware(masked_text: str, masking_map: Dict) -> Tuple[str, Dict]:
    """
    –í—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è –∑–≤–∞–Ω—å –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º –≥–µ–Ω–¥–µ—Ä—É —Ç–∞ –≥—Ä–∞–º–∞—Ç–∏—á–Ω–∏—Ö –≤—ñ–¥–º—ñ–Ω–∫—ñ–≤.

    –¶–µ –Ω–∞–π—Å–∫–ª–∞–¥–Ω—ñ—à–∞ —Ñ—É–Ω–∫—Ü—ñ—è unmask, —è–∫–∞ –≤—Ä–∞—Ö–æ–≤—É—î:
        1. Instance tracking (–∫–æ–ª—ñ–∑—ñ—ó –º–∞—Å–∫—É–≤–∞–Ω–Ω—è)
        2. –ì–µ–Ω–¥–µ—Ä–Ω—É —É–∑–≥–æ–¥–∂–µ–Ω—ñ—Å—Ç—å (—á–æ–ª–æ–≤—ñ—á—ñ/–∂—ñ–Ω–æ—á—ñ —Ñ–æ—Ä–º–∏)
        3. –ì—Ä–∞–º–∞—Ç–∏—á–Ω—ñ –≤—ñ–¥–º—ñ–Ω–∫–∏ (–Ω–∞–∑–∏–≤–Ω–∏–π, —Ä–æ–¥–æ–≤–∏–π, –¥–∞–≤–∞–ª—å–Ω–∏–π, –æ—Ä—É–¥–Ω–∏–π)
        4. –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–≥—ñ—Å—Ç—Ä—É –ª—ñ—Ç–µ—Ä (UPPER, Title, lower)
        5. –î–æ–¥–∞—Ç–∫–æ–≤—ñ —Å–ª–æ–≤–∞ ("—É –≤—ñ–¥—Å—Ç–∞–≤—Ü—ñ", "–º–µ–¥–∏—á–Ω–æ—ó —Å–ª—É–∂–±–∏")

    –ê–ª–≥–æ—Ä–∏—Ç–º:
        1. –ó–Ω–∞—Ö–æ–¥–∏—Ç—å –≤—Å—ñ –≤—Ö–æ–¥–∂–µ–Ω–Ω—è –∑–≤–∞–Ω—å —É —Ç–µ–∫—Å—Ç—ñ (–∑—ñ —Å–ª–æ–≤–Ω–∏–∫–∞ ALL_RANK_FORMS)
        2. –î–æ–¥–∞—î fallback –ø–æ—à—É–∫ –¥–ª—è –∑–≤–∞–Ω—å, —è–∫–∏—Ö –Ω–µ–º–∞—î —É —Å–ª–æ–≤–Ω–∏–∫—É
        3. –°–æ—Ä—Ç—É—î –∑–Ω–∞–π–¥–µ–Ω—ñ –∑–≤–∞–Ω–Ω—è –∑–∞ –ø–æ—Ä—è–¥–∫–æ–º —É —Ç–µ–∫—Å—Ç—ñ
        4. –î–ª—è –∫–æ–∂–Ω–æ–≥–æ –∑–≤–∞–Ω–Ω—è:
           a) –í–∏—Ç—è–≥—É—î –±–∞–∑–æ–≤–µ –∑–≤–∞–Ω–Ω—è —Ç–∞ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ —Å–ª–æ–≤–∞
           b) –í–∏–∑–Ω–∞—á–∞—î –≤—ñ–¥–º—ñ–Ω–æ–∫ —Ç–∞ —Ä—ñ–¥ —á–µ—Ä–µ–∑ RANK_TO_NOMINATIVE
           c) –ó–Ω–∞—Ö–æ–¥–∏—î –æ—Ä–∏–≥—ñ–Ω–∞–ª —á–µ—Ä–µ–∑ instance tracking
           d) –í—ñ–¥–Ω–æ–≤–ª—é—î –≥—Ä–∞–º–∞—Ç–∏—á–Ω—É —Ñ–æ—Ä–º—É —á–µ—Ä–µ–∑ RANK_DECLENSIONS
           e) –ó–∞—Å—Ç–æ—Å–æ–≤—É—î –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π —Ä–µ–≥—ñ—Å—Ç—Ä
        5. –í–∏–∫–æ–Ω—É—î –∑–∞–º—ñ–Ω–∏ –∑ –∫—ñ–Ω—Ü—è —Ç–µ–∫—Å—Ç—É –¥–æ –ø–æ—á–∞—Ç–∫—É (—â–æ–± –Ω–µ –∑–±–∏—Ç–∏ —ñ–Ω–¥–µ–∫—Å–∏)

    Args:
        masked_text: –ó–∞–º–∞—Å–∫–æ–≤–∞–Ω–∏–π —Ç–µ–∫—Å—Ç
        masking_map: –°–ª–æ–≤–Ω–∏–∫ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤ –∑ data_masking.py

    Returns:
        Tuple (–≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–∏–π_—Ç–µ–∫—Å—Ç, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)
        –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {"restored_count": int, "skipped_count": int}

    """
    restored_text = masked_text
    stats = {"restored_count": 0, "skipped_count": 0}

    # –ë—É–¥—É—î–º–æ –º–∞–ø—É —Ç—ñ–ª—å–∫–∏ –¥–ª—è –∑–≤–∞–Ω—å (–æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è)
    temp_map_for_ranks = {"mappings": {"rank": masking_map["mappings"].get("rank", {})}}
    rank_instance_map = build_instance_map(temp_map_for_ranks)

    # –°—Ç–≤–æ—Ä—é—î–º–æ –Ω–∞–±—ñ—Ä –≤—Å—ñ—Ö –∑–∞–º–∞—Å–∫–æ–≤–∞–Ω–∏—Ö –∑–≤–∞–Ω—å –¥–ª—è —à–≤–∏–¥–∫–æ—ó –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ is_real_mask
    all_masked_ranks = set()
    for original, mask_info in masking_map["mappings"].get("rank", {}).items():
        if isinstance(mask_info, dict) and "masked_as" in mask_info:
            all_masked_ranks.add(mask_info["masked_as"].lower())

    # ========================================================================
    # –ö–†–û–ö 1: –ü–û–®–£–ö –í–°–Ü–• –ó–í–ê–ù–¨ –£ –¢–ï–ö–°–¢–Ü
    # ========================================================================

    # 1.A. –ó–Ω–∞—Ö–æ–¥–∏–º–æ –∑–≤–∞–Ω–Ω—è –∑—ñ —Å–ª–æ–≤–Ω–∏–∫–∞ (–Ω–∞–π—Ç–æ—á–Ω—ñ—à–∏–π –º–µ—Ç–æ–¥)
    all_found_ranks = []
    for rank_form in ALL_RANK_FORMS:
        pattern = r'\b' + re.escape(rank_form) + r'\b'
        for match in re.finditer(pattern, restored_text, re.IGNORECASE):
            all_found_ranks.append({
                "start": match.start(),
                "end": match.end(),
                "text": match.group(0)
            })

    # 1.B. Fallback: –∑–Ω–∞—Ö–æ–¥–∏–º–æ –∑–≤–∞–Ω–Ω—è, —è–∫—ñ —î –º–∞—Å–∫–∞–º–∏, –∞–ª–µ –Ω–µ –≤ —Å–ª–æ–≤–Ω–∏–∫—É
    # (–º–æ–∂–µ —Å—Ç–∞—Ç–∏—Å—è —è–∫—â–æ –∑–≤–∞–Ω–Ω—è –±—É–ª–æ –∑–∞–º–∞—Å–∫–æ–≤–∞–Ω–µ, –∞–ª–µ –Ω–µ–º–∞—î —É RANK_DECLENSIONS)
    for masked_rank in all_masked_ranks:
        pattern = r'\b' + re.escape(masked_rank) + r'\b'
        for match in re.finditer(pattern, restored_text, re.IGNORECASE):
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ –Ω–µ –ø–µ—Ä–µ–∫—Ä–∏–≤–∞—î—Ç—å—Å—è –∑ –≤–∂–µ –∑–Ω–∞–π–¥–µ–Ω–∏–º –∑–≤–∞–Ω–Ω—è
            overlaps = any(
                match.start() < found["end"] and match.end() > found["start"]
                for found in all_found_ranks
            )

            if not overlaps:
                all_found_ranks.append({
                    "start": match.start(),
                    "end": match.end(),
                    "text": match.group(0),
                    "simple": True  # –ü–æ–∑–Ω–∞—á–∫–∞ –¥–ª—è –ø—Ä–æ—Å—Ç–æ—ó –∑–∞–º—ñ–Ω–∏
                })

    # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ –ø–æ—Ä—è–¥–∫–æ–º —É —Ç–µ–∫—Å—Ç—ñ (–∑–ª—ñ–≤–∞ –Ω–∞–ø—Ä–∞–≤–æ)
    all_found_ranks.sort(key=lambda x: x['start'])

    # ========================================================================
    # –ö–†–û–ö 2: –û–ë–†–û–ë–ö–ê –ö–û–ñ–ù–û–ì–û –ó–ù–ê–ô–î–ï–ù–û–ì–û –ó–í–ê–ù–ù–Ø
    # ========================================================================

    replacements_to_do = []  # –°–ø–∏—Å–æ–∫ –∑–∞–º—ñ–Ω (start, end, replacement_text)
    instance_counters = {}    # –õ—ñ—á–∏–ª—å–Ω–∏–∫–∏ –¥–ª—è instance tracking

    for found in all_found_ranks:
        # ====================================================================
        # –õ–û–ì–Ü–ö–ê A: –ü–†–û–°–¢–ê –ó–ê–ú–Ü–ù–ê (–±–µ–∑ –≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è –≤—ñ–¥–º—ñ–Ω–∫–∞)
        # ====================================================================
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –¥–ª—è –∑–≤–∞–Ω—å, —è–∫–∏—Ö –Ω–µ–º–∞—î —É —Å–ª–æ–≤–Ω–∏–∫—É RANK_DECLENSIONS

        if found.get("simple", False):
            full_rank_text = found["text"]
            base_rank, additional_words = extract_base_rank(full_rank_text)
            masked_rank_lower = base_rank.lower()

            # Instance tracking: —Ä–∞—Ö—É—î–º–æ, —è–∫–µ —Ü–µ –≤—Ö–æ–¥–∂–µ–Ω–Ω—è —Ü—ñ—î—ó –º–∞—Å–∫–∏
            instance_counters.setdefault(masked_rank_lower, 0)
            instance_counters[masked_rank_lower] += 1
            instance_num = instance_counters[masked_rank_lower]

            # –®—É–∫–∞—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª –¥–ª—è —Ü—å–æ–≥–æ –µ–∫–∑–µ–º–ø–ª—è—Ä–∞
            if masked_rank_lower in rank_instance_map and instance_num in rank_instance_map[masked_rank_lower]:
                original_rank = rank_instance_map[masked_rank_lower][instance_num]

                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —â–æ —Ü–µ —Å–ø—Ä–∞–≤–¥—ñ –º–∞—Å–∫–∞ (–Ω–µ –≤–∏–ø–∞–¥–∫–æ–≤–∏–π –∑–±—ñ–≥)
                if not is_real_mask(masked_rank_lower, masking_map, all_masked_ranks):
                    stats["skipped_count"] += 1
                    continue

                # –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π —Ä–µ–≥—ñ—Å—Ç—Ä
                original_rank = _apply_original_case(base_rank, original_rank)

                # –î–æ–¥–∞—î–º–æ –Ω–∞–∑–∞–¥ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ —Å–ª–æ–≤–∞ ("—É –≤—ñ–¥—Å—Ç–∞–≤—Ü—ñ" —Ç–æ—â–æ)
                restored_full_rank = f"{original_rank} {additional_words}" if additional_words else original_rank

                replacements_to_do.append((found["start"], found["end"], restored_full_rank))
                stats["restored_count"] += 1
            else:
                stats["skipped_count"] += 1
            continue

        # ====================================================================
        # –õ–û–ì–Ü–ö–ê B: –†–û–ó–£–ú–ù–ê –ó–ê–ú–Ü–ù–ê (–∑ –≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è–º –≤—ñ–¥–º—ñ–Ω–∫—É —Ç–∞ —Ä–æ–¥—É)
        # ====================================================================
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –¥–ª—è –∑–≤–∞–Ω—å –∑—ñ —Å–ª–æ–≤–Ω–∏–∫–∞ RANK_DECLENSIONS

        full_rank_text = found["text"]
        base_rank_text, additional_words = extract_base_rank(full_rank_text)

        # –í–∏–∑–Ω–∞—á–∞—î–º–æ –±–∞–∑–æ–≤—É —Ñ–æ—Ä–º—É, –≤—ñ–¥–º—ñ–Ω–æ–∫ —Ç–∞ —Ä—ñ–¥ —á–µ—Ä–µ–∑ —Å–ª–æ–≤–Ω–∏–∫
        base_masked_form, case, gender = get_rank_info(base_rank_text)

        if not base_masked_form:
            continue  # –ó–≤–∞–Ω–Ω—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ —É —Å–ª–æ–≤–Ω–∏–∫—É

        # Instance tracking
        instance_counters.setdefault(base_masked_form, 0)
        instance_counters[base_masked_form] += 1
        instance_num = instance_counters[base_masked_form]

        # –®—É–∫–∞—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª –¥–ª—è —Ü—å–æ–≥–æ –µ–∫–∑–µ–º–ø–ª—è—Ä–∞
        if base_masked_form in rank_instance_map and instance_num in rank_instance_map[base_masked_form]:
            original_base_form = rank_instance_map[base_masked_form][instance_num]

            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —â–æ —Ü–µ —Å–ø—Ä–∞–≤–¥—ñ –º–∞—Å–∫–∞
            if not is_real_mask(base_masked_form, masking_map, all_masked_ranks):
                stats["skipped_count"] += 1
                continue

            # –í—ñ–¥–Ω–æ–≤–ª—é—î–º–æ –≥—Ä–∞–º–∞—Ç–∏—á–Ω—É —Ñ–æ—Ä–º—É –æ—Ä–∏–≥—ñ–Ω–∞–ª—É
            reconstructed_form = original_base_form

            # –ñ—ñ–Ω–æ—á–∞ —Ñ–æ—Ä–º–∞: —à—É–∫–∞—î–º–æ —É RANK_DECLENSIONS_FEMALE
            if gender == 'female':
                if original_base_form in RANK_FEMININE_MAP:
                    base_female = RANK_FEMININE_MAP[original_base_form]
                    if base_female in RANK_DECLENSIONS_FEMALE:
                        # –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ –ø–æ—Ç—Ä—ñ–±–Ω–∏–π –≤—ñ–¥–º—ñ–Ω–æ–∫
                        reconstructed_form = RANK_DECLENSIONS_FEMALE[base_female].get(case, base_female)

            # –ß–æ–ª–æ–≤—ñ—á–∞ —Ñ–æ—Ä–º–∞: —à—É–∫–∞—î–º–æ —É RANK_DECLENSIONS
            else:
                if original_base_form in RANK_DECLENSIONS:
                    # –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ –ø–æ—Ç—Ä—ñ–±–Ω–∏–π –≤—ñ–¥–º—ñ–Ω–æ–∫
                    reconstructed_form = RANK_DECLENSIONS[original_base_form].get(case, original_base_form)

            # –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π —Ä–µ–≥—ñ—Å—Ç—Ä
            reconstructed_form = _apply_original_case(base_rank_text, reconstructed_form)

            # –î–æ–¥–∞—î–º–æ –Ω–∞–∑–∞–¥ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ —Å–ª–æ–≤–∞
            restored_full_rank = f"{reconstructed_form} {additional_words}" if additional_words else reconstructed_form

            replacements_to_do.append((found["start"], found["end"], restored_full_rank))
            stats["restored_count"] += 1
        else:
            stats["skipped_count"] += 1

    # ========================================================================
    # –ö–†–û–ö 3: –í–ò–ö–û–ù–ê–ù–ù–Ø –ó–ê–ú–Ü–ù
    # ========================================================================
    # –ó–∞–º—ñ–Ω–∏ –≤–∏–∫–æ–Ω—É—é—Ç—å—Å—è –∑ –∫—ñ–Ω—Ü—è –¥–æ –ø–æ—á–∞—Ç–∫—É, —â–æ–± –Ω–µ –∑–±–∏–≤–∞—Ç–∏ —ñ–Ω–¥–µ–∫—Å–∏ –ø–æ–∑–∏—Ü—ñ–π

    replacements_to_do.sort(key=lambda x: x[0], reverse=True)
    for start, end, original in replacements_to_do:
        restored_text = restored_text[:start] + original + restored_text[end:]

    return restored_text, stats


def unmask_other_data(masked_text: str, masking_map: Dict) -> Tuple[str, Dict]:
    """
    –í—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è —ñ–Ω—à–∏—Ö —Ç–∏–ø—ñ–≤ –¥–∞–Ω–∏—Ö (–æ–∫—Ä—ñ–º –∑–≤–∞–Ω—å).

    –û–±—Ä–æ–±–ª—è—î –≤—Å—ñ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó –¥–∞–Ω–∏—Ö: –Ü–ü–ù, –ø–∞—Å–ø–æ—Ä—Ç–∏, –ø—Ä—ñ–∑–≤–∏—â–∞, —ñ–º–µ–Ω–∞, –≤—ñ–π—Å—å–∫–æ–≤—ñ ID,
    –Ω–æ–º–µ—Ä–∏ –Ω–∞–∫–∞–∑—ñ–≤, –ë–† –Ω–æ–º–µ—Ä–∏, –¥–∞—Ç–∏ —Ç–æ—â–æ.

    –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –ø—Ä–æ—Å—Ç—É –ª–æ–≥—ñ–∫—É instance tracking –±–µ–∑ –≥—Ä–∞–º–∞—Ç–∏—á–Ω–∏—Ö –≤—ñ–¥–º—ñ–Ω–∫—ñ–≤.

    Args:
        masked_text: –ó–∞–º–∞—Å–∫–æ–≤–∞–Ω–∏–π —Ç–µ–∫—Å—Ç
        masking_map: –°–ª–æ–≤–Ω–∏–∫ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤ (–±–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó "rank")

    Returns:
        Tuple (–≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–∏–π_—Ç–µ–∫—Å—Ç, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)

    Algorithm:
        1. –°—Ç–≤–æ—Ä—é—î instance map –¥–ª—è –≤—Å—ñ—Ö –∫–∞—Ç–µ–≥–æ—Ä—ñ–π –æ–∫—Ä—ñ–º –∑–≤–∞–Ω—å
        2. –î–ª—è –∫–æ–∂–Ω–æ—ó –º–∞—Å–∫–∏ –∑–Ω–∞—Ö–æ–¥–∏—Ç—å –≤—Å—ñ –≤—Ö–æ–¥–∂–µ–Ω–Ω—è –≤ —Ç–µ–∫—Å—Ç—ñ
        3. –ó–∞—Å—Ç–æ—Å–æ–≤—É—î instance tracking –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è
        4. –ó–±–µ—Ä—ñ–≥–∞—î –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π —Ä–µ–≥—ñ—Å—Ç—Ä –ª—ñ—Ç–µ—Ä
        5. –í–∏–∫–æ–Ω—É—î –∑–∞–º—ñ–Ω–∏ –∑ –∫—ñ–Ω—Ü—è —Ç–µ–∫—Å—Ç—É
    """
    restored_text = masked_text

    # –ö–æ–ø—ñ—é—î–º–æ –º–∞–ø–ø—ñ–Ω–≥ –±–µ–∑ –∑–≤–∞–Ω—å (–∑–≤–∞–Ω–Ω—è –æ–±—Ä–æ–±–ª—è—é—Ç—å—Å—è –æ–∫—Ä–µ–º–æ)
    mappings_copy = masking_map["mappings"].copy()
    if "rank" in mappings_copy:
        del mappings_copy["rank"]

    # –ë—É–¥—É—î–º–æ instance map –¥–ª—è –≤—Å—ñ—Ö –∫–∞—Ç–µ–≥–æ—Ä—ñ–π –æ–∫—Ä—ñ–º –∑–≤–∞–Ω—å
    instance_map = build_instance_map({"mappings": mappings_copy})

    stats = {"restored_count": 0, "skipped_count": 0}
    replacements_to_do = []

    # –û–±—Ä–æ–±–ª—è—î–º–æ –∫–æ–∂–Ω—É –º–∞—Å–∫—É
    for masked_value, instance_to_original in instance_map.items():
        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –≤—Å—ñ –≤—Ö–æ–¥–∂–µ–Ω–Ω—è —Ü—ñ—î—ó –º–∞—Å–∫–∏ –≤ —Ç–µ–∫—Å—Ç—ñ
        occurrences = find_all_occurrences(restored_text, masked_value)

        # –î–ª—è –∫–æ–∂–Ω–æ–≥–æ –≤—Ö–æ–¥–∂–µ–Ω–Ω—è –≤–∏–∑–Ω–∞—á–∞—î–º–æ –Ω–æ–º–µ—Ä –µ–∫–∑–µ–º–ø–ª—è—Ä–∞
        for instance_num, (start_pos, end_pos) in enumerate(occurrences, 1):
            if instance_num in instance_to_original:
                original_value = instance_to_original[instance_num]
                replacements_to_do.append((start_pos, end_pos, original_value, masked_value))
                stats["restored_count"] += 1
            else:
                stats["skipped_count"] += 1

    # –í–∏–∫–æ–Ω—É—î–º–æ –∑–∞–º—ñ–Ω–∏ –∑ –∫—ñ–Ω—Ü—è –¥–æ –ø–æ—á–∞—Ç–∫—É
    replacements_to_do.sort(key=lambda x: x[0], reverse=True)
    for start_pos, end_pos, original_value, masked_value in replacements_to_do:
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —â–æ –º–∞—Å–∫–∞ –Ω–∞ —Å–≤–æ—î–º—É –º—ñ—Å—Ü—ñ (case-insensitive)
        if restored_text[start_pos:end_pos].lower() == masked_value.lower():
            masked_segment = restored_text[start_pos:end_pos]
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π —Ä–µ–≥—ñ—Å—Ç—Ä
            original_value = _apply_original_case(masked_segment, original_value)
            restored_text = restored_text[:start_pos] + original_value + restored_text[end_pos:]

    return restored_text, stats


def unmask_text_v2(masked_text: str, masking_map: Dict, map_version: str) -> Tuple[str, Dict]:
    """
    –û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è unmask –¥–ª—è –≤–µ—Ä—Å—ñ–π 2.x –º–∞–ø–ø—ñ–Ω–≥—ñ–≤.

    –ö–æ–æ—Ä–¥–∏–Ω—É—î –ø—Ä–æ—Ü–µ—Å unmask —É –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º—É –ø–æ—Ä—è–¥–∫—É:
        1. –°–ø–æ—á–∞—Ç–∫—É –∑–≤–∞–Ω–Ω—è (–Ω–∞–π—Å–∫–ª–∞–¥–Ω—ñ—à—ñ, –∑ –≥—Ä–∞–º–∞—Ç–∏–∫–æ—é)
        2. –ü–æ—Ç—ñ–º –≤—Å–µ —ñ–Ω—à–µ (–ø—Ä—ñ–∑–≤–∏—â–∞, —ñ–º–µ–Ω–∞, –Ü–ü–ù —Ç–æ—â–æ)

    Args:
        masked_text: –ó–∞–º–∞—Å–∫–æ–≤–∞–Ω–∏–π —Ç–µ–∫—Å—Ç
        masking_map: –°–ª–æ–≤–Ω–∏–∫ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤
        map_version: –í–µ—Ä—Å—ñ—è –ª–æ–≥—ñ–∫–∏ ('v2.1', 'v2.0')

    Returns:
        Tuple (–≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–∏–π_—Ç–µ–∫—Å—Ç, –æ–±'—î–¥–Ω–∞–Ω–∞_—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)
    """
    if map_version == "v2.1":
        # –ö—Ä–æ–∫ 1: –í—ñ–¥–Ω–æ–≤–ª—é—î–º–æ –∑–≤–∞–Ω–Ω—è (–∑ –≥—Ä–∞–º–∞—Ç–∏–∫–æ—é —Ç–∞ –≥–µ–Ω–¥–µ—Ä–æ–º)
        text_after_ranks, rank_stats = unmask_ranks_gender_aware(masked_text, masking_map)

        # –ö—Ä–æ–∫ 2: –í—ñ–¥–Ω–æ–≤–ª—é—î–º–æ –≤—Å–µ —ñ–Ω—à–µ
        final_text, other_stats = unmask_other_data(text_after_ranks, masking_map)

        # –û–±'—î–¥–Ω—É—î–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        return final_text, {
            "restored_count": rank_stats["restored_count"] + other_stats["restored_count"],
            "skipped_count": rank_stats["skipped_count"] + other_stats["skipped_count"]
        }
    else:
        # –î–ª—è v2.0 –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø—Ä–æ—Å—Ç—É –ª–æ–≥—ñ–∫—É –±–µ–∑ –∑–≤–∞–Ω—å
        return unmask_other_data(masked_text, masking_map)


def unmask_text_v1(masked_text: str, masking_map: Dict) -> Tuple[str, Dict]:
    """
    Unmask –¥–ª—è —Å—Ç–∞—Ä–∏—Ö –≤–µ—Ä—Å—ñ–π 1.x (–ø—Ä–æ—Å—Ç–∞ –∑–∞–º—ñ–Ω–∞ —Ä—è–¥–∫—ñ–≤).

    –°—Ç–∞—Ä–∞ –ª–æ–≥—ñ–∫–∞ –±–µ–∑ instance tracking - –ø—Ä–æ—Å—Ç–æ –∑–∞–º—ñ–Ω–∞ —É—Å—ñ—Ö –≤—Ö–æ–¥–∂–µ–Ω—å.
    –ú–æ–∂–µ –¥–∞–≤–∞—Ç–∏ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø—Ä–∏ –∫–æ–ª—ñ–∑—ñ—è—Ö –º–∞—Å–∫—É–≤–∞–Ω–Ω—è.

    Args:
        masked_text: –ó–∞–º–∞—Å–∫–æ–≤–∞–Ω–∏–π —Ç–µ–∫—Å—Ç
        masking_map: –°–ª–æ–≤–Ω–∏–∫ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤ v1.x

    Returns:
        Tuple (–≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–∏–π_—Ç–µ–∫—Å—Ç, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)
    """
    restored_text = masked_text
    stats = {"restored_count": 0, "skipped_count": 0}
    all_replacements = []

    # –ó–±–∏—Ä–∞—î–º–æ –≤—Å—ñ –ø–∞—Ä–∏ (–º–∞—Å–∫–∞, –æ—Ä–∏–≥—ñ–Ω–∞–ª)
    for category, cat_mappings in masking_map.get("mappings", {}).items():
        for original, masked in cat_mappings.items():
            if isinstance(masked, str):
                all_replacements.append((masked, original))

    # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ –¥–æ–≤–∂–∏–Ω–æ—é (–¥–æ–≤—à—ñ –ø–µ—Ä—à–∏–º–∏, —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ —á–∞—Å—Ç–∫–æ–≤–∏—Ö –∑–∞–º—ñ–Ω)
    all_replacements.sort(key=lambda x: len(x[0]), reverse=True)

    # –í–∏–∫–æ–Ω—É—î–º–æ –∑–∞–º—ñ–Ω–∏
    for masked, original in all_replacements:
        if masked in restored_text:
            stats["restored_count"] += restored_text.count(masked)
            restored_text = restored_text.replace(masked, original)

    return restored_text, stats


def unmask_json_recursive(masked_data: Any, masking_map: Dict, map_version: str) -> Any:
    """
    –†–µ–∫—É—Ä—Å–∏–≤–Ω–∏–π unmask –¥–ª—è JSON —Å—Ç—Ä—É–∫—Ç—É—Ä.

    –û–±—Ä–æ–±–ª—è—î –≤–∫–ª–∞–¥–µ–Ω—ñ —Å–ª–æ–≤–Ω–∏–∫–∏ —Ç–∞ —Å–ø–∏—Å–∫–∏, –∑–∞—Å—Ç–æ—Å–æ–≤—É—é—á–∏ unmask –¥–æ –≤—Å—ñ—Ö —Ä—è–¥–∫—ñ–≤.

    Args:
        masked_data: –ó–∞–º–∞—Å–∫–æ–≤–∞–Ω—ñ –¥–∞–Ω—ñ (dict, list, str –∞–±–æ —ñ–Ω—à–µ)
        masking_map: –°–ª–æ–≤–Ω–∏–∫ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤
        map_version: –í–µ—Ä—Å—ñ—è –ª–æ–≥—ñ–∫–∏ unmask

    Returns:
        –í—ñ–¥–Ω–æ–≤–ª–µ–Ω—ñ –¥–∞–Ω—ñ –∑ —Ç—ñ—î—é –∂ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ—é

    """
    if isinstance(masked_data, dict):
        # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ä–æ–±–ª—è—î–º–æ –≤—Å—ñ –∑–Ω–∞—á–µ–Ω–Ω—è —Å–ª–æ–≤–Ω–∏–∫–∞
        return {k: unmask_json_recursive(v, masking_map, map_version) for k, v in masked_data.items()}

    elif isinstance(masked_data, list):
        # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ä–æ–±–ª—è—î–º–æ –≤—Å—ñ –µ–ª–µ–º–µ–Ω—Ç–∏ —Å–ø–∏—Å–∫—É
        return [unmask_json_recursive(item, masking_map, map_version) for item in masked_data]

    elif isinstance(masked_data, str):
        # –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ unmask –¥–æ —Ä—è–¥–∫—ñ–≤
        if map_version.startswith("v2"):
            restored, _ = unmask_text_v2(masked_data, masking_map, map_version)
        else:
            restored, _ = unmask_text_v1(masked_data, masking_map)
        return restored

    else:
        # –Ü–Ω—à—ñ —Ç–∏–ø–∏ (int, bool, None) –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ –±–µ–∑ –∑–º—ñ–Ω
        return masked_data

# ============================================================================
# –ì–û–õ–û–í–ù–ê –§–£–ù–ö–¶–Ü–Ø (ENTRY POINT)
# ============================================================================

def main():
    """
    –ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è CLI –¥–ª—è unmask.

    –ü—ñ–¥—Ç—Ä–∏–º—É—î –¥–≤–∞ —Ä–µ–∂–∏–º–∏:
        1. –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π: —à—É–∫–∞—î –æ—Å—Ç–∞–Ω–Ω—é –ø–∞—Ä—É —Ñ–∞–π–ª—ñ–≤
        2. –†—É—á–Ω–∏–π: –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á –≤–∫–∞–∑—É—î —Ñ–∞–π–ª–∏
    """
    parser = argparse.ArgumentParser(
        description=f'Data Unmasking Script v{__version__}',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument('masked_file', nargs='?', help='Masked file path')
    parser.add_argument('--map', '-m', dest='map_file', help='Mapping JSON file')
    parser.add_argument('--output', '-o', help='Output file path')
    args = parser.parse_args()

    # ========================================================================
    # –õ–û–ì–Ü–ö–ê –ü–û–®–£–ö–£ –¢–ê –í–ò–ë–û–†–£ –§–ê–ô–õ–Ü–í
    # ========================================================================

    if not args.masked_file:
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π —Ä–µ–∂–∏–º
        result = auto_find_latest_pair()
        if result is None:
            return
        masked_path, map_path, output_path = result
    else:
        # –†—É—á–Ω–∏–π —Ä–µ–∂–∏–º
        masked_path = Path(args.masked_file)
        if not masked_path.exists():
            print(f"‚ùå –§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {masked_path}")
            return

        # –í–∏–∑–Ω–∞—á–∞—î–º–æ —à–ª—è—Ö –¥–æ mapping —Ñ–∞–π–ª—É
        if args.map_file:
            map_path = Path(args.map_file)
        else:
            # –°–ø—Ä–æ–±–∞ –≤–≥–∞–¥–∞—Ç–∏ —ñ–º'—è –º–∞–ø–∏ –∑–∞ —ñ–º'—è–º output —Ñ–∞–π–ª—É
            filename = masked_path.stem
            if filename.startswith('output_'):
                # output_20250101_120000_123 ‚Üí masking_map_20250101_120000_123
                map_path = masked_path.parent / f"masking_map_{filename[7:]}.json"
            else:
                print("‚ùå –ë—É–¥—å –ª–∞—Å–∫–∞, –≤–∫–∞–∂—ñ—Ç—å —Ñ–∞–π–ª –º–∞–ø–ø—ñ–Ω–≥—É —á–µ—Ä–µ–∑ --map")
                return

        if not map_path.exists():
            print(f"‚ùå –§–∞–π–ª –º–∞–ø–ø—ñ–Ω–≥—É –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {map_path}")
            return

        # –í–∏–∑–Ω–∞—á–∞—î–º–æ —à–ª—è—Ö –¥–ª—è output —Ñ–∞–π–ª—É
        if args.output:
            output_path = Path(args.output)
        else:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_path = masked_path.parent / f"input_recovery_{timestamp}{masked_path.suffix}"

    # ========================================================================
    # –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –§–ê–ô–õ–Ü–í
    # ========================================================================

    try:
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —Å–ª–æ–≤–Ω–∏–∫ –º–∞–ø–ø—ñ–Ω–≥—ñ–≤
        with open(map_path, 'r', encoding='utf-8') as f:
            masking_map = json.load(f)

        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∑–∞–º–∞—Å–∫–æ–≤–∞–Ω—ñ –¥–∞–Ω—ñ (JSON –∞–±–æ —Ç–µ–∫—Å—Ç)
        with open(masked_path, 'r', encoding='utf-8') as f:
            if masked_path.suffix == '.json':
                masked_data = json.load(f)
            else:
                masked_data = f.read()
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è: {e}")
        return

    # ========================================================================
    # –ü–†–û–¶–ï–° UNMASK
    # ========================================================================

    # –í–∏–∑–Ω–∞—á–∞—î–º–æ –≤–µ—Ä—Å—ñ—é –º–∞–ø–ø—ñ–Ω–≥—É
    map_version = check_mapping_version(masking_map)
    print(f"üîÑ –†–æ–∑–º–∞—Å–∫—É–≤–∞–Ω–Ω—è {masked_path.name} (–ª–æ–≥—ñ–∫–∞ {map_version})...")

    start_time = time.time()

    # –ó–∞–ø—É—Å–∫–∞—î–º–æ unmask
    if masked_path.suffix == '.json':
        # JSON unmask (—Ä–µ–∫—É—Ä—Å–∏–≤–Ω–∞ –æ–±—Ä–æ–±–∫–∞)
        restored_data = unmask_json_recursive(masked_data, masking_map, map_version)
    else:
        # –¢–µ–∫—Å—Ç–æ–≤–∏–π unmask
        if map_version.startswith("v2"):
            restored_data, stats = unmask_text_v2(masked_data, masking_map, map_version)
        else:
            restored_data, stats = unmask_text_v1(masked_data, masking_map)

    # ========================================================================
    # –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–£
    # ========================================================================

    try:
        with open(output_path, 'w', encoding='utf-8', newline='') as f:
            if masked_path.suffix == '.json':
                json.dump(restored_data, f, ensure_ascii=False, indent=2)
            else:
                f.write(restored_data)

        print(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –ó–±–µ—Ä–µ–∂–µ–Ω–æ —É: {output_path}")
        print(f"‚è±Ô∏è –ß–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è: {time.time() - start_time:.2f} —Å–µ–∫")

    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è: {e}")


if __name__ == "__main__":
    main()
